{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "patch_sklearn()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ipynb_path = os.getcwd()\n",
    "src_path = os.path.join(ipynb_path, 'src/')\n",
    "input_path = os.path.join(ipynb_path,\"input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import scipy.stats as spst\n",
    "\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from windpowerlib.wind_speed import logarithmic_profile\n",
    "from src.utils import uv_to_wsd # 윈도우에서는 앞에 src를 뺄것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power:  (155528, 29)\n",
      "train_y:  (52608, 4)\n",
      "LDAPS:  (235818, 15)\n"
     ]
    }
   ],
   "source": [
    "power_2020 = pd.read_parquet(input_path + \"dynamic_report_ewp02_2020_10min.parquet\").rename({'Date/Time': 'dt', 'WTG.Name': 'turbine_id'}, axis=1)[:-3]\n",
    "power_2021 = pd.read_parquet(input_path + \"dynamic_report_ewp02_2021_10min.parquet\").rename({'Date/Time': 'dt', 'WTG.Name': 'turbine_id'}, axis=1)[:-3]\n",
    "power_2022 = pd.read_parquet(input_path + \"dynamic_report_ewp02_2022_10min.parquet\").rename({'Date/Time': 'dt', 'WTG.Name': 'turbine_id'}, axis=1)[:-3]\n",
    "power = pd.concat([power_2020, power_2021, power_2022], ignore_index=True)\n",
    "\n",
    "gj_y = pd.read_parquet(input_path + \"train_y.parquet\").rename({'end_datetime': 'dt'}, axis=1)\n",
    "ldaps = pd.read_parquet(input_path + \"train_ldaps_gyeongju.parquet\")\n",
    "\n",
    "print(\"Power: \", power.shape)\n",
    "print(\"train_y: \", gj_y.shape)\n",
    "print(\"LDAPS: \", ldaps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# yongmin's functions\n",
    "from src.utils import DataConnector\n",
    "from src.metric import NMAE\n",
    "from src.data_processor import *\n",
    "\n",
    "# model import\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235818, 23)\n"
     ]
    }
   ],
   "source": [
    "# 파이프라인 구성 및 적용\n",
    "DataPipeline = Pipeline([\n",
    "    ('uv_transform', UVTransformer('wind_u_10m', 'wind_v_10m')),\n",
    "    ('wind_transform', WindTransformer('wind_speed', 10, 100, ldaps['surf_rough'].mean())),\n",
    "    ('feature_engineering', FeatureTransformer()),\n",
    "])\n",
    "\n",
    "# 파이프라인을 이용하여 ldaps 데이터 변환\n",
    "ldaps_transformed = DataPipeline.fit_transform(ldaps)\n",
    "\n",
    "print(ldaps_transformed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ldaps = ldaps_transformed.drop('turbine_id', axis=1).groupby('dt').mean()\n",
    "average_ldaps.columns = average_ldaps.columns.str.replace(r'[<>\\[\\]]', '_', regex=True)\n",
    "average_ldaps.columns = average_ldaps.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "average_ldaps.columns = average_ldaps.columns.str.replace(r'__+', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ldaps.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ldaps['dt'] = pd.to_datetime(average_ldaps['dt']).dt.tz_localize(None)\n",
    "gj_y['dt'] = pd.to_datetime(gj_y['dt']).dt.tz_localize(None)\n",
    "avg_data = pd.merge(average_ldaps, gj_y, on='dt', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data_sorted = avg_data.sort_values(['dt', 'plant_name', 'energy_kwh'], ascending=[True, True, False])\n",
    "avg_data_cleaned = avg_data_sorted.drop_duplicates(subset=['dt', 'plant_name'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data_cleaned = avg_data.drop_duplicates(subset=['dt'], keep='first')\n",
    "avg_data = avg_data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "def get_trasforms_datas(merged_data, numeric_columns, target):\n",
    "    z_scaler = StandardScaler()\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    \n",
    "    x_train = merged_data.loc[merged_data['dt'].between('2020-01-01', '2020-12-31', inclusive='left'), numeric_columns]\n",
    "    x_test = merged_data.loc[merged_data['dt'].between('2021-01-01', '2022-12-31', inclusive='left'), numeric_columns]\n",
    "\n",
    "    y_train = merged_data.loc[merged_data['dt'].between('2020-01-01', '2020-12-31', inclusive='left'), target]\n",
    "    y_test = merged_data.loc[merged_data['dt'].between('2021-01-01', '2022-12-31', inclusive='left'), target]\n",
    "    #y_train = y_train.dropna()\n",
    "    #y_test = y_test.dropna()\n",
    "\n",
    "    # Min-Max Scaling\n",
    "    x_train_m = minmax_scaler.fit_transform(x_train)\n",
    "    x_train_m = pd.DataFrame(x_train_m, columns=x_train.columns)\n",
    "    x_test_m = minmax_scaler.transform(x_test)\n",
    "    x_test_m = pd.DataFrame(x_test_m, columns=x_train.columns)\n",
    "\n",
    "    # Standard Scaling\n",
    "    x_train_z = z_scaler.fit_transform(x_train)\n",
    "    x_train_z = pd.DataFrame(x_train_z, columns=x_train.columns)\n",
    "    x_test_z = z_scaler.transform(x_test)\n",
    "    x_test_z = pd.DataFrame(x_test_z, columns=x_train.columns)\n",
    "\n",
    "    return x_train, x_test, x_train_m, x_test_m, x_train_z, x_test_z, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 이제 특징 생성에 클러스터링 결과는 보지 않을 예정.\n",
    "def addKmeansFeature(train_data, test_data):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    for n_clusters in range(2, 7):  # 2부터 6까지 클러스터 생성\n",
    "        kmeans = KMeans(n_clusters=n_clusters, n_init=10)\n",
    "\n",
    "        train_data[f'cluster_{n_clusters}'] = kmeans.fit_predict(train_data[['wind_speed', 'wind_direction']])\n",
    "        \n",
    "        test_data[f'cluster_{n_clusters}'] = kmeans.predict(test_data[['wind_speed', 'wind_direction']])\n",
    "\n",
    "    return train_data, test_data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def addPCAFeature(train_data, test_data):\n",
    "    # PCA 적용할 특징 열 선택 (u, v 성분)\n",
    "    wind_features = ['storm_u_5m', 'storm_v_5m', 'wind_u_10m', 'wind_v_10m', \n",
    "                     'wind_speed', 'wind_direction']\n",
    "    \n",
    "    # 훈련 데이터에서 PCA 학습\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_train = pca.fit_transform(train_data[wind_features])\n",
    "    \n",
    "    # 훈련 데이터에 주성분 추가\n",
    "    train_data['PC1'] = pca_train[:, 0]\n",
    "    train_data['PC2'] = pca_train[:, 1]\n",
    "    \n",
    "    # 테스트 데이터에 PCA 적용\n",
    "    pca_test = pca.transform(test_data[wind_features])\n",
    "    test_data['PC1'] = pca_test[:, 0]\n",
    "    test_data['PC2'] = pca_test[:, 1]\n",
    "\n",
    "    # PCA 설명력 확인\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(f\"PC1 설명력: {explained_variance[0]}\")\n",
    "    print(f\"PC2 설명력: {explained_variance[1]}\")\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "def addKMedoidsFeature(train_data, test_data):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "\n",
    "    for n_clusters in range(2, 7):  # 2부터 6까지 클러스터 생성\n",
    "        kmedoids = KMedoids(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "        # 훈련 데이터에 K-Medoids 클러스터링 적용\n",
    "        train_data[f'medoid_cluster_{n_clusters}'] = kmedoids.fit_predict(train_data[['wind_speed', 'wind_direction']])\n",
    "\n",
    "        # 테스트 데이터에 학습된 K-Medoids 모델 적용\n",
    "        test_data[f'medoid_cluster_{n_clusters}'] = kmedoids.predict(test_data[['wind_speed', 'wind_direction']])\n",
    "\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = avg_data.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, x_train_m, x_test_m, x_train_z, x_test_z, y_train, y_test = get_trasforms_datas(avg_data, numeric_columns, 'energy_kwh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmean 적용 완료\n",
      "PC1 설명력: 0.9982665777206421\n",
      "PC2 설명력: 0.000830549921374768\n",
      "PC1 설명력: 0.7499995755457655\n",
      "PC2 설명력: 0.11854411387391413\n",
      "PC1 설명력: 0.33917607071751443\n",
      "PC2 설명력: 0.32569090287750574\n",
      "pca 적용 완료\n",
      "kmedoid 적용 완료\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = addKmeansFeature(x_train, x_test)\n",
    "x_train_m, x_test_m = addKmeansFeature(x_train_m, x_test_m)\n",
    "x_train_z, x_test_z = addKmeansFeature(x_train_z, x_test_z)\n",
    "print('kmean 적용 완료')\n",
    "x_train, x_test = addPCAFeature(x_train, x_test)\n",
    "x_train_m, x_test_m = addPCAFeature(x_train_m, x_test_m)\n",
    "x_train_z, x_test_z = addPCAFeature(x_train_z, x_test_z)\n",
    "print('pca 적용 완료')\n",
    "\n",
    "x_train, x_test = addKMedoidsFeature(x_train, x_test)\n",
    "x_train_m, x_test_m = addKMedoidsFeature(x_train_m, x_test_m)\n",
    "x_train_z, x_test_z = addKMedoidsFeature(x_train_z, x_test_z)\n",
    "print('kmedoid 적용 완료')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict = {\n",
    "    # 원본 데이터만 사용\n",
    "    'original': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                 'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                 'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m'],\n",
    "\n",
    "    # PCA 추가\n",
    "    'pca_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                 'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                 'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'PC1', 'PC2'],\n",
    "\n",
    "    # 클러스터(2~6) 추가\n",
    "    'cluster_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                     'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                     'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', \n",
    "                     'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5', 'cluster_6'],\n",
    "\n",
    "    # PCA + 클러스터(2~6) 추가\n",
    "    'pca_and_cluster': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                        'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                        'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', \n",
    "                        'PC1', 'PC2', 'cluster_2', 'cluster_3', 'cluster_4', 'cluster_5', 'cluster_6'],\n",
    "\n",
    "    # 클러스터 개수에 따른 경우\n",
    "    'cluster_2_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_2'],\n",
    "    \n",
    "    'cluster_3_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_3'],\n",
    "    \n",
    "    'cluster_4_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_4'],\n",
    "    \n",
    "    'cluster_5_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_5'],\n",
    "    \n",
    "    'cluster_6_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                       'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                       'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'cluster_6'],\n",
    "\n",
    "    # KMedoids 추가\n",
    "    'kmedoids_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                      'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                      'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', \n",
    "                      'medoid_cluster_2', 'medoid_cluster_3', 'medoid_cluster_4', 'medoid_cluster_5', 'medoid_cluster_6'],\n",
    "\n",
    "    # PCA + KMedoids 추가\n",
    "    'pca_and_kmedoids': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                         'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                         'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', \n",
    "                         'PC1', 'PC2', 'medoid_cluster_2', 'medoid_cluster_3', 'medoid_cluster_4', 'medoid_cluster_5', 'medoid_cluster_6'],\n",
    "\n",
    "    # KMedoids 클러스터 개수에 따른 경우\n",
    "    'medoid_cluster_2_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                              'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                              'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'medoid_cluster_2'],\n",
    "\n",
    "    'medoid_cluster_3_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                              'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                              'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'medoid_cluster_3'],\n",
    "\n",
    "    'medoid_cluster_4_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                              'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                              'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'medoid_cluster_4'],\n",
    "\n",
    "    'medoid_cluster_5_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                              'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                              'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'medoid_cluster_5'],\n",
    "\n",
    "    'medoid_cluster_6_only': ['elevation', 'land_cover', 'surf_rough', 'frictional_vmax_50m', 'frictional_vmin_50m', \n",
    "                              'pressure', 'relative_humid', 'specific_humid', 'temp_air', 'storm_u_5m', 'storm_v_5m', \n",
    "                              'wind_u_10m', 'wind_v_10m', 'wind_speed', 'wind_direction', 'wind_speed_100m', 'medoid_cluster_6']\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.deepTrain_roughVer.Analysis_WindTurbine.Model.RNNs import RNN,LSTM,GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ㅇmake window\n",
    "def create_sequences(data, seq_len):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_len + 1):\n",
    "        seq = data[i:i+seq_len]\n",
    "        sequences.append(seq)\n",
    "    return torch.tensor(sequences, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "def NMAE(y_true, y_pred):\n",
    "    \"\"\"NMAE 계산 함수.\"\"\"\n",
    "    return mean_absolute_error(y_true, y_pred) / (sum(abs(y_true)) / len(y_true)) * 100\n",
    "\n",
    "# general model test batch : test 30\n",
    "# decomp model test batch : 16\n",
    "# need test 24,28\n",
    "def train_model(save_dir, model, x_train, y_train, x_test, y_test, epochs=200, batch_size=24, lr=0.001, criterion_type = 'MSE', early_n=None):\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"cuda is not available. exiting...\")\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    model = model.cuda()\n",
    "\n",
    "    x_train_tensor = torch.tensor(x_train.values, dtype=torch.float32).cuda()\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1).cuda()\n",
    "    #print(x_train_tensor.shape)\n",
    "    x_test_tensor = torch.tensor(x_test.values, dtype=torch.float32).cuda()\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1).cuda()\n",
    "\n",
    "    # data loaders\n",
    "    train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    # set\n",
    "    if criterion_type == 'MSE':\n",
    "        criterion = nn.MSELoss()\n",
    "    else:\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # losses\n",
    "    best_val_loss = float('inf')\n",
    "    best_y_pred_list = []\n",
    "    best_y_true_list = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    csv_data = []\n",
    "\n",
    "    # train\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            #print(inputs.shape)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        y_pred_list = []\n",
    "        y_true_list = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, targets).item()\n",
    "                y_pred_list.extend(outputs.cpu().numpy())\n",
    "                y_true_list.extend(targets.cpu().numpy())\n",
    "\n",
    "        y_pred_list = np.array(y_pred_list).flatten()\n",
    "        y_true_list = np.array(y_true_list).flatten()\n",
    "\n",
    "        mae = mean_absolute_error(y_true_list, y_pred_list)\n",
    "        nmae = NMAE(y_true_list, y_pred_list)\n",
    "        r2 = r2_score(y_true_list, y_pred_list)\n",
    "\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        val_losses.append(val_loss / len(test_loader))\n",
    "\n",
    "        csv_data.append([epoch + 1, train_loss / len(train_loader), val_loss / len(test_loader), mae, nmae, r2])\n",
    "\n",
    "        # overfiting 방지\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_y_pred_list = y_pred_list\n",
    "            best_y_true_list = y_true_list\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, f\"{model.__class__.__name__}_best_model.pth\"))\n",
    "            early_stop_counter = 0  # Reset early stopping counter\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        print(f\"Train Loss: {train_loss/len(train_loader):.4f}\")\n",
    "        print(f\"Val Loss: {val_loss/len(test_loader):.4f}, MAE: {mae:.4f}, NMAE: {nmae:.4f}, R^2: {r2:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if early_n is not None and early_stop_counter >= early_n:\n",
    "            print(f\"early stopping at epoch {epoch+1}. Best epoch: {best_epoch} with val Loss: {best_val_loss:.4f}\")\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(csv_data, columns=[\"Epoch\", \"Train Loss\", \"Val Loss\", \"MAE\", \"NMAE\", \"R2\"])\n",
    "    df.to_csv(os.path.join(save_dir, \"training_log.csv\"), index=False)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(train_losses)), train_losses, label=\"Train Loss\")\n",
    "    plt.plot(range(len(val_losses)), val_losses, label=\"Val Loss\")\n",
    "    #plt.scatter(best_epoch - 1, best_val_loss, color=\"red\", label=f\"Best Val Loss: {best_val_loss:.4f}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Loss plot (Best Val Loss at epoch {best_epoch}: {(best_val_loss/1000):.2f}k)\")\n",
    "    plt.savefig(os.path.join(save_dir, \"loss_plot.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(best_y_true_list, label=\"ground truth\")\n",
    "    plt.plot(best_y_pred_list, label=\"Pred\")\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Values\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Pred and Truth Compare\")\n",
    "    plt.savefig(os.path.join(save_dir, \"best_pred_plot.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    with open(os.path.join(save_dir, \"training_log.txt\"), \"w\") as f:\n",
    "        f.write(f\"Final Validation Loss: {best_val_loss:.4f}\\n\")\n",
    "        f.write(f\"MAE: {mae:.4f}, NMAE: {nmae:.4f}, R^2: {r2:.4f}\\n\")\n",
    "        f.write(f\"devide capacity => MAE/20700: {(mae/20700):.4f}, MAE/79600: {(mae/79600):.4f}\")\n",
    "\n",
    "    print(f\"Final Model saved with best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}, NMAE: {nmae:.4f}, R^2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key in x_dict.keys():\n",
    "#    # ====================\n",
    "#    # Min-Max 정규화 데이터\n",
    "#    # ====================\n",
    "#    x_train_m_selected = x_train_m[x_dict[key]]\n",
    "#    x_test_m_selected = x_test_m[x_dict[key]]\n",
    "\n",
    "##    # RNN 모델 학습\n",
    "##    rnn_model = RNN(input_dim=x_train_m_selected.shape[1], hidden_dim=128)\n",
    "##    save_dir = os.path.join(ipynb_path, f'notebooks/test_basicRecurrent/{key}_RNN_m/')\n",
    "##    train_model(save_dir, rnn_model, x_train_m_selected, y_train, x_test_m_selected, y_test,1500)\n",
    "\n",
    "#    # LSTM 모델 학습\n",
    "#    lstm_model = LSTM(input_dim=x_train_m_selected.shape[1], hidden_dim=128, bidirectional=True)\n",
    "#    save_dir = os.path.join(ipynb_path, f'notebooks/test_bidirectional_lstm/{key}_LSTM_m/')\n",
    "#    train_model(save_dir, lstm_model, x_train_m_selected, y_train, x_test_m_selected, y_test,1500)\n",
    "\n",
    "##    # GRU 모델 학습\n",
    "##    gru_model = GRU(input_dim=x_train_m_selected.shape[1], hidden_dim=128)\n",
    "##    save_dir = os.path.join(ipynb_path, f'notebooks/test_basicRecurrent/{key}_GRU_m/')\n",
    "##    train_model(save_dir, gru_model, x_train_m_selected, y_train, x_test_m_selected, y_test,1500)\n",
    "\n",
    "##    # ====================\n",
    "##    # z-정규화 데이터\n",
    "##    # ====================\n",
    "#    x_train_z_selected = x_train_z[x_dict[key]]\n",
    "#    x_test_z_selected = x_test_z[x_dict[key]]\n",
    "\n",
    "##    # RNN 모델 학습\n",
    "##    rnn_model = RNN(input_dim=x_train_z_selected.shape[1], hidden_dim=128)\n",
    "##    save_dir = os.path.join(ipynb_path, f'notebooks/test_basicRecurrent/{key}_RNN_z/')\n",
    "##    train_model(save_dir, rnn_model, x_train_z_selected, y_train, x_test_z_selected, y_test,1500)\n",
    "\n",
    "#    # LSTM 모델 학습\n",
    "#    lstm_model = LSTM(input_dim=x_train_z_selected.shape[1], hidden_dim=128)\n",
    "#    save_dir = os.path.join(ipynb_path, f'notebooks/test_bidirectional_lstm/{key}_LSTM_z/')\n",
    "#    train_model(save_dir, lstm_model, x_train_z_selected, y_train, x_test_z_selected, y_test,1500)\n",
    "\n",
    "##    # GRU 모델 학습\n",
    "##    gru_model = GRU(input_dim=x_train_z_selected.shape[1], hidden_dim=128)\n",
    "##    save_dir = os.path.join(ipynb_path, f'notebooks/test_basicRecurrent/{key}_GRU_z/')\n",
    "##    train_model(save_dir, gru_model, x_train_z_selected, y_train, x_test_z_selected, y_test,1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가망 없을 것 같아서 임의로 학습 중단함. 모든 val_los가 1500에폭 기준 3 * 1e7 근처를 돌고 있음. \n",
    "# 그나마 GRU마서 하하 더 더리면 될거 거긴 한데, model 다시짜는게 better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.deepTrain_roughVer.Analysis_WindTurbine.Model.RNNs import LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class LSTMModule(nn.Module):\n",
    "    \n",
    "#    def __init__(self, input_dim, hidden_dim, rec_dropout=0.4, num_layers=1, bidirectional=False):\n",
    "#        super(LSTMModule, self).__init__()\n",
    "#        self.rnn = nn.LSTM(input_dim, hidden_dim, bidirectional=bidirectional, batch_first=True,\n",
    "#                           dropout=rec_dropout, num_layers=num_layers)\n",
    "\n",
    "#    def save(self, filename):\n",
    "#        torch.save(self.state_dict(), filename)\n",
    "\n",
    "#    def load(self, filename=None, parameters=None):\n",
    "#        if filename is not None:\n",
    "#            self.load_state_dict(torch.load(filename))\n",
    "#        elif parameters is not None:\n",
    "#            self.load_state_dict(parameters)\n",
    "#        else:\n",
    "#            raise NotImplementedError(\"load is a filename or a list of parameters (state_dict)\")\n",
    "\n",
    "#    def forward(self, x):\n",
    "#        recurrent, _ = self.rnn(x)\n",
    "#        return recurrent\n",
    "\n",
    "#class GRUModule(nn.Module):\n",
    "#    def __init__(self, input_dim, hidden_dim, rec_dropout=0.4, num_layers=1, bidirectional=False):\n",
    "#        super(GRUModule, self).__init__()\n",
    "#        self.rnn = nn.GRU(input_dim, hidden_dim, bidirectional=bidirectional, batch_first=True,\n",
    "#                          dropout=rec_dropout, num_layers=num_layers)\n",
    "\n",
    "#    def save(self, filename):\n",
    "#        torch.save(self.state_dict(), filename)\n",
    "\n",
    "#    def load(self, filename=None, parameters=None):\n",
    "#        if filename is not None:\n",
    "#            self.load_state_dict(torch.load(filename))\n",
    "#        elif parameters is not None:\n",
    "#            self.load_state_dict(parameters)\n",
    "#        else:\n",
    "#            raise NotImplementedError(\"load is a filename or a list of parameters (state_dict)\")\n",
    "\n",
    "#    def forward(self, x):\n",
    "#        recurrent, _ = self.rnn(x)\n",
    "#        return recurrent\n",
    "\n",
    "## Models\n",
    "#class RNN(nn.Module):\n",
    "#    def __init__(self, input_dim, hidden_dim, rec_dropout=0.4, num_layers=1, bidirectional=False):\n",
    "#        super(RNN, self).__init__()\n",
    "#        self.rnn_module = RNNModule(input_dim, hidden_dim, rec_dropout, num_layers, bidirectional)\n",
    "#        self.fc1 = nn.Linear(hidden_dim, hidden_dim/2)\n",
    "#        self.fc2 = nn.Linear(hidden_dim/2, 1)\n",
    "\n",
    "#    def forward(self, x):\n",
    "#        recurrent = self.rnn_module(x)\n",
    "#        out = self.fc1(recurrent)\n",
    "#        out = self.fc2(out)\n",
    "#        return out\n",
    "\n",
    "#class LSTM(nn.Module):\n",
    "#    def __init__(self, input_dim, hidden_dim, rec_dropout=0.4, num_layers=1, bidirectional=False):\n",
    "#        super(LSTM, self).__init__()\n",
    "#        self.lstm_module = LSTMModule(input_dim, hidden_dim, rec_dropout, num_layers, bidirectional)\n",
    "#        self.bidirectional = bidirectional\n",
    "#        if self.bidirectional:\n",
    "#            self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "#        else:\n",
    "#            self.fc1 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "#        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "#    def forward(self, x):\n",
    "#        recurrent = self.lstm_module(x)\n",
    "#        out = self.fc1(recurrent)\n",
    "#        out = self.fc2(out)\n",
    "#        return out\n",
    "\n",
    "\n",
    "#class GRU(nn.Module):\n",
    "#    def __init__(self, input_dim, hidden_dim, rec_dropout=0.4, num_layers=1, bidirectional=False):\n",
    "#        super(GRU, self).__init__()\n",
    "#        self.gru_module = GRUModule(input_dim, hidden_dim, rec_dropout, num_layers, bidirectional)\n",
    "#        self.bidirectional = bidirectional\n",
    "#        if self.bidirectional:\n",
    "#            self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "#        else:\n",
    "#            self.fc1 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "#        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "#    def forward(self, x):\n",
    "#        recurrent = self.gru_module(x)\n",
    "#        out = self.fc1(recurrent)\n",
    "#        out = self.fc2(out)\n",
    "#        return out\n",
    "    \n",
    "class LSTMModule(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, rec_dropout=0.4, num_layers=1, bidirectional=False):\n",
    "        super(LSTMModule, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, bidirectional=bidirectional, batch_first=True,\n",
    "                           dropout=rec_dropout, num_layers=num_layers)\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save(self.state_dict(), filename)\n",
    "\n",
    "    def load(self, filename=None, parameters=None):\n",
    "        if filename is not None:\n",
    "            self.load_state_dict(torch.load(filename))\n",
    "        elif parameters is not None:\n",
    "            self.load_state_dict(parameters)\n",
    "        else:\n",
    "            raise NotImplementedError(\"load is a filename or a list of parameters (state_dict)\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        recurrent, _ = self.rnn(x)\n",
    "        return recurrent\n",
    "\n",
    "class GRUModule(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, rec_dropout=0.4, num_layers=1, bidirectional=False):\n",
    "        super(GRUModule, self).__init__()\n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, bidirectional=bidirectional, batch_first=True,\n",
    "                          dropout=rec_dropout, num_layers=num_layers)\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save(self.state_dict(), filename)\n",
    "\n",
    "    def load(self, filename=None, parameters=None):\n",
    "        if filename is not None:\n",
    "            self.load_state_dict(torch.load(filename))\n",
    "        elif parameters is not None:\n",
    "            self.load_state_dict(parameters)\n",
    "        else:\n",
    "            raise NotImplementedError(\"load is a filename or a list of parameters (state_dict)\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        recurrent, _ = self.rnn(x)\n",
    "        return recurrent\n",
    "\n",
    "# Models\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, rec_dropout=0.4, num_layers=1, bidirectional=False):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn_module = RNNModule(input_dim, hidden_dim, rec_dropout, num_layers, bidirectional)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim/2)\n",
    "        self.fc2 = nn.Linear(hidden_dim/2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        recurrent = self.rnn_module(x)\n",
    "        out = self.fc1(recurrent)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, rec_dropout=0.4, num_layers=1, bidirectional=False):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm_module = LSTMModule(input_dim, hidden_dim, rec_dropout, num_layers, bidirectional)\n",
    "        self.bidirectional = bidirectional\n",
    "        if self.bidirectional:\n",
    "            self.fc1 = nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.fc1 = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        recurrent = self.lstm_module(x)\n",
    "        out = self.fc1(recurrent)\n",
    "        out = self.fc2(out)\n",
    "        # out = torch.clamp(out, min=0) # capacity write later\n",
    "        return out\n",
    "\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, rec_dropout=0.4, num_layers=1, bidirectional=False):\n",
    "        super(GRU, self).__init__()\n",
    "        self.gru_module = GRUModule(input_dim, hidden_dim, rec_dropout, num_layers, bidirectional)\n",
    "        self.bidirectional = bidirectional\n",
    "        if self.bidirectional:\n",
    "            self.fc1 = nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.fc1 = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        recurrent = self.gru_module(x)\n",
    "        out = self.fc1(recurrent)\n",
    "        out = self.fc2(out)\n",
    "        # out = torch.clamp(out, min=0) # capacity write later\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y:  (52608, 4)\n",
      "LDAPS:  (917070, 15)\n",
      "(917070, 23)\n",
      "kmean 적용 완료\n",
      "PC1 설명력: 0.9969626069068909\n",
      "PC2 설명력: 0.001954863080754876\n",
      "PC1 설명력: 0.7320484617797179\n",
      "PC2 설명력: 0.14104104431898426\n",
      "PC1 설명력: 0.46370585375874857\n",
      "PC2 설명력: 0.23818530022354453\n",
      "pca 적용 완료\n",
      "kmedoid 적용 완료\n"
     ]
    }
   ],
   "source": [
    "# yg data load.\n",
    "# it is dump before dataframes. plz check.\n",
    "yg_y = pd.read_parquet(input_path + \"train_y.parquet\").rename({'end_datetime': 'dt'}, axis=1)\n",
    "ldaps = pd.read_parquet(input_path + \"train_ldaps_yeonggwang.parquet\")\n",
    "\n",
    "print(\"train_y: \", yg_y.shape)\n",
    "print(\"LDAPS: \", ldaps.shape)\n",
    "\n",
    "# 파이프라인 구성 및 적용\n",
    "DataPipeline = Pipeline([\n",
    "    ('uv_transform', UVTransformer('wind_u_10m', 'wind_v_10m')),\n",
    "    ('wind_transform', WindTransformer('wind_speed', 10, 100, ldaps['surf_rough'].mean())),\n",
    "    ('feature_engineering', FeatureTransformer()),\n",
    "])\n",
    "\n",
    "# 파이프라인을 이용하여 ldaps 데이터 변환\n",
    "ldaps_transformed = DataPipeline.fit_transform(ldaps)\n",
    "\n",
    "print(ldaps_transformed.shape)\n",
    "\n",
    "\n",
    "average_ldaps = ldaps_transformed.drop('turbine_id', axis=1).groupby('dt').mean()\n",
    "average_ldaps.columns = average_ldaps.columns.str.replace(r'[<>\\[\\]]', '_', regex=True)\n",
    "average_ldaps.columns = average_ldaps.columns.str.replace(r'[^\\w]', '_', regex=True)\n",
    "average_ldaps.columns = average_ldaps.columns.str.replace(r'__+', '_', regex=True)\n",
    "\n",
    "average_ldaps.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "average_ldaps['dt'] = pd.to_datetime(average_ldaps['dt']).dt.tz_localize(None)\n",
    "yg_y['dt'] = pd.to_datetime(yg_y['dt']).dt.tz_localize(None)\n",
    "avg_data = pd.merge(average_ldaps, yg_y, on='dt', how='inner')\n",
    "\n",
    "yg_y = yg_y.loc[yg_y['plant_name'] == '영광풍력']\n",
    "\n",
    "avg_data_sorted = avg_data.sort_values(['dt', 'plant_name', 'energy_kwh'], ascending=[True, True, False])\n",
    "avg_data_cleaned = avg_data_sorted.drop_duplicates(subset=['dt', 'plant_name'], keep='first')\n",
    "\n",
    "avg_data_cleaned = avg_data.drop_duplicates(subset=['dt'], keep='first')\n",
    "avg_data = avg_data_cleaned\n",
    "numeric_columns = avg_data.select_dtypes(include=['number']).columns.tolist()\n",
    "x_train, x_test, x_train_m, x_test_m, x_train_z, x_test_z, y_train, y_test = get_trasforms_datas(avg_data, numeric_columns, 'energy_kwh')\n",
    "\n",
    "x_train, x_test = addKmeansFeature(x_train, x_test)\n",
    "x_train_m, x_test_m = addKmeansFeature(x_train_m, x_test_m)\n",
    "x_train_z, x_test_z = addKmeansFeature(x_train_z, x_test_z)\n",
    "print('kmean 적용 완료')\n",
    "x_train, x_test = addPCAFeature(x_train, x_test)\n",
    "x_train_m, x_test_m = addPCAFeature(x_train_m, x_test_m)\n",
    "x_train_z, x_test_z = addPCAFeature(x_train_z, x_test_z)\n",
    "print('pca 적용 완료')\n",
    "\n",
    "x_train, x_test = addKMedoidsFeature(x_train, x_test)\n",
    "x_train_m, x_test_m = addKMedoidsFeature(x_train_m, x_test_m)\n",
    "x_train_z, x_test_z = addKMedoidsFeature(x_train_z, x_test_z)\n",
    "print('kmedoid 적용 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code is changed for each use. PLZ check the usage model and the file path where it is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1500]\n",
      "Train Loss: 6071.4587\n",
      "Val Loss: 5043.3819, MAE: 5043.8823, NMAE: 76.7848, R^2: -0.2772\n",
      "Epoch [2/1500]\n",
      "Train Loss: 5108.1324\n",
      "Val Loss: 5063.6149, MAE: 5064.1147, NMAE: 77.0928, R^2: 0.0560\n",
      "Epoch [3/1500]\n",
      "Train Loss: 5123.0711\n",
      "Val Loss: 5140.3450, MAE: 5140.8447, NMAE: 78.2609, R^2: 0.0261\n",
      "Epoch [4/1500]\n",
      "Train Loss: 4912.4775\n",
      "Val Loss: 4747.6062, MAE: 4748.1064, NMAE: 72.2821, R^2: 0.1175\n",
      "Epoch [5/1500]\n",
      "Train Loss: 4826.7614\n",
      "Val Loss: 4711.8739, MAE: 4712.3740, NMAE: 71.7381, R^2: 0.1303\n",
      "Epoch [6/1500]\n",
      "Train Loss: 5004.1586\n",
      "Val Loss: 4671.6545, MAE: 4672.1543, NMAE: 71.1258, R^2: 0.0646\n",
      "Epoch [7/1500]\n",
      "Train Loss: 4822.1141\n",
      "Val Loss: 4623.1643, MAE: 4623.6636, NMAE: 70.3877, R^2: 0.1257\n",
      "Epoch [8/1500]\n",
      "Train Loss: 4786.3711\n",
      "Val Loss: 4514.7624, MAE: 4515.2622, NMAE: 68.7374, R^2: 0.1531\n",
      "Epoch [9/1500]\n",
      "Train Loss: 4804.9356\n",
      "Val Loss: 4589.7368, MAE: 4590.2363, NMAE: 69.8788, R^2: 0.1192\n",
      "Epoch [10/1500]\n",
      "Train Loss: 4799.4115\n",
      "Val Loss: 4590.9498, MAE: 4591.4497, NMAE: 69.8973, R^2: 0.1083\n",
      "Epoch [11/1500]\n",
      "Train Loss: 4815.6574\n",
      "Val Loss: 4589.2617, MAE: 4589.7612, NMAE: 69.8716, R^2: 0.1119\n",
      "Epoch [12/1500]\n",
      "Train Loss: 4811.7857\n",
      "Val Loss: 4595.8714, MAE: 4596.3711, NMAE: 69.9722, R^2: 0.1064\n",
      "Epoch [13/1500]\n",
      "Train Loss: 4816.6588\n",
      "Val Loss: 4597.7092, MAE: 4598.2085, NMAE: 70.0001, R^2: 0.1080\n",
      "Epoch [14/1500]\n",
      "Train Loss: 4815.3879\n",
      "Val Loss: 4606.7853, MAE: 4607.2852, NMAE: 70.1383, R^2: 0.0952\n",
      "Epoch [15/1500]\n",
      "Train Loss: 4803.0811\n",
      "Val Loss: 4611.2766, MAE: 4611.7759, NMAE: 70.2067, R^2: 0.0983\n",
      "Epoch [16/1500]\n",
      "Train Loss: 4994.2134\n",
      "Val Loss: 4734.6677, MAE: 4735.1675, NMAE: 72.0851, R^2: 0.1172\n",
      "Epoch [17/1500]\n",
      "Train Loss: 4794.9304\n",
      "Val Loss: 4597.0360, MAE: 4597.5361, NMAE: 69.9899, R^2: 0.1261\n",
      "Epoch [18/1500]\n",
      "Train Loss: 4731.2114\n",
      "Val Loss: 4587.4169, MAE: 4587.9175, NMAE: 69.8435, R^2: 0.1119\n",
      "Epoch [19/1500]\n",
      "Train Loss: 4752.5219\n",
      "Val Loss: 4498.8268, MAE: 4499.3267, NMAE: 68.4948, R^2: 0.1322\n",
      "Epoch [20/1500]\n",
      "Train Loss: 4621.8471\n",
      "Val Loss: 4612.4813, MAE: 4612.9810, NMAE: 70.2250, R^2: 0.1035\n",
      "Epoch [21/1500]\n",
      "Train Loss: 4647.4094\n",
      "Val Loss: 4583.3915, MAE: 4583.8921, NMAE: 69.7822, R^2: 0.1195\n",
      "Epoch [22/1500]\n",
      "Train Loss: 4636.2687\n",
      "Val Loss: 4514.4504, MAE: 4514.9502, NMAE: 68.7327, R^2: 0.1339\n",
      "Epoch [23/1500]\n",
      "Train Loss: 4404.5704\n",
      "Val Loss: 4389.9614, MAE: 4390.4614, NMAE: 66.8375, R^2: 0.1613\n",
      "Epoch [24/1500]\n",
      "Train Loss: 4637.9828\n",
      "Val Loss: 4790.4058, MAE: 4790.9058, NMAE: 72.9336, R^2: 0.1138\n",
      "Epoch [25/1500]\n",
      "Train Loss: 4661.1913\n",
      "Val Loss: 4508.7919, MAE: 4509.2915, NMAE: 68.6465, R^2: 0.1139\n",
      "Epoch [26/1500]\n",
      "Train Loss: 4396.3570\n",
      "Val Loss: 4439.0336, MAE: 4439.5332, NMAE: 67.5846, R^2: 0.1540\n",
      "Epoch [27/1500]\n",
      "Train Loss: 4203.3063\n",
      "Val Loss: 4392.4554, MAE: 4392.9551, NMAE: 66.8755, R^2: 0.0993\n",
      "Epoch [28/1500]\n",
      "Train Loss: 4266.6876\n",
      "Val Loss: 4411.4566, MAE: 4411.9565, NMAE: 67.1648, R^2: 0.1563\n",
      "Epoch [29/1500]\n",
      "Train Loss: 4230.2043\n",
      "Val Loss: 4439.6506, MAE: 4440.1504, NMAE: 67.5940, R^2: 0.1383\n",
      "Epoch [30/1500]\n",
      "Train Loss: 4322.5504\n",
      "Val Loss: 4422.6403, MAE: 4423.1401, NMAE: 67.3350, R^2: 0.1192\n",
      "Epoch [31/1500]\n",
      "Train Loss: 4207.0851\n",
      "Val Loss: 4241.2195, MAE: 4241.7192, NMAE: 64.5732, R^2: 0.1843\n",
      "Epoch [32/1500]\n",
      "Train Loss: 4029.1089\n",
      "Val Loss: 4623.0449, MAE: 4623.5444, NMAE: 70.3858, R^2: 0.0291\n",
      "Epoch [33/1500]\n",
      "Train Loss: 4236.5702\n",
      "Val Loss: 4395.4051, MAE: 4395.9048, NMAE: 66.9204, R^2: 0.1331\n",
      "Epoch [34/1500]\n",
      "Train Loss: 4184.2682\n",
      "Val Loss: 4603.9738, MAE: 4604.4736, NMAE: 70.0955, R^2: 0.0938\n",
      "Epoch [35/1500]\n",
      "Train Loss: 4253.6798\n",
      "Val Loss: 4316.3976, MAE: 4316.8975, NMAE: 65.7176, R^2: 0.1536\n",
      "Epoch [36/1500]\n",
      "Train Loss: 4146.4475\n",
      "Val Loss: 4370.1682, MAE: 4370.6680, NMAE: 66.5362, R^2: 0.1871\n",
      "Epoch [37/1500]\n",
      "Train Loss: 4039.4465\n",
      "Val Loss: 4223.1275, MAE: 4223.6274, NMAE: 64.2978, R^2: 0.2302\n",
      "Epoch [38/1500]\n",
      "Train Loss: 3959.5810\n",
      "Val Loss: 4344.5692, MAE: 4345.0693, NMAE: 66.1465, R^2: 0.2132\n",
      "Epoch [39/1500]\n",
      "Train Loss: 3920.9455\n",
      "Val Loss: 4047.5683, MAE: 4048.0681, NMAE: 61.6252, R^2: 0.2264\n",
      "Epoch [40/1500]\n",
      "Train Loss: 3933.4304\n",
      "Val Loss: 4170.4997, MAE: 4171.0000, NMAE: 63.4966, R^2: 0.1931\n",
      "Epoch [41/1500]\n",
      "Train Loss: 3747.4926\n",
      "Val Loss: 4336.0866, MAE: 4336.5864, NMAE: 66.0174, R^2: 0.1552\n",
      "Epoch [42/1500]\n",
      "Train Loss: 3763.1149\n",
      "Val Loss: 4266.6602, MAE: 4267.1602, NMAE: 64.9605, R^2: 0.1952\n",
      "Epoch [43/1500]\n",
      "Train Loss: 3585.5523\n",
      "Val Loss: 4130.8125, MAE: 4131.3120, NMAE: 62.8924, R^2: 0.2186\n",
      "Epoch [44/1500]\n",
      "Train Loss: 3499.5414\n",
      "Val Loss: 4274.2179, MAE: 4274.7178, NMAE: 65.0755, R^2: 0.1791\n",
      "Epoch [45/1500]\n",
      "Train Loss: 3481.9781\n",
      "Val Loss: 4266.1364, MAE: 4266.6362, NMAE: 64.9525, R^2: 0.1507\n",
      "Epoch [46/1500]\n",
      "Train Loss: 3366.8385\n",
      "Val Loss: 4485.5304, MAE: 4486.0303, NMAE: 68.2924, R^2: 0.1208\n",
      "Epoch [47/1500]\n",
      "Train Loss: 3334.6824\n",
      "Val Loss: 4330.2626, MAE: 4330.7622, NMAE: 65.9287, R^2: 0.1234\n",
      "Epoch [48/1500]\n",
      "Train Loss: 3365.1597\n",
      "Val Loss: 4218.5868, MAE: 4219.0869, NMAE: 64.2286, R^2: 0.1900\n",
      "Epoch [49/1500]\n",
      "Train Loss: 3338.7371\n",
      "Val Loss: 4141.7570, MAE: 4142.2563, NMAE: 63.0590, R^2: 0.2269\n",
      "Epoch [50/1500]\n",
      "Train Loss: 3329.0672\n",
      "Val Loss: 4599.4178, MAE: 4599.9175, NMAE: 70.0262, R^2: 0.0800\n",
      "Epoch [51/1500]\n",
      "Train Loss: 3315.0720\n",
      "Val Loss: 4585.6517, MAE: 4586.1514, NMAE: 69.8166, R^2: 0.0697\n",
      "Epoch [52/1500]\n",
      "Train Loss: 3248.3168\n",
      "Val Loss: 4622.9389, MAE: 4623.4390, NMAE: 70.3842, R^2: -0.0174\n",
      "Epoch [53/1500]\n",
      "Train Loss: 3203.0134\n",
      "Val Loss: 4161.4632, MAE: 4161.9629, NMAE: 63.3590, R^2: 0.1615\n",
      "Epoch [54/1500]\n",
      "Train Loss: 3246.8501\n",
      "Val Loss: 4151.3762, MAE: 4151.8765, NMAE: 63.2055, R^2: 0.1439\n",
      "Epoch [55/1500]\n",
      "Train Loss: 3063.4835\n",
      "Val Loss: 4065.4443, MAE: 4065.9438, NMAE: 61.8973, R^2: 0.1724\n",
      "Epoch [56/1500]\n",
      "Train Loss: 3065.3279\n",
      "Val Loss: 3948.5045, MAE: 3949.0042, NMAE: 60.1171, R^2: 0.2298\n",
      "Epoch [57/1500]\n",
      "Train Loss: 2973.2119\n",
      "Val Loss: 3906.8933, MAE: 3907.3931, NMAE: 59.4836, R^2: 0.2240\n",
      "Epoch [58/1500]\n",
      "Train Loss: 3072.4571\n",
      "Val Loss: 3881.8302, MAE: 3882.3301, NMAE: 59.1021, R^2: 0.2169\n",
      "Epoch [59/1500]\n",
      "Train Loss: 2920.7314\n",
      "Val Loss: 3929.6420, MAE: 3930.1421, NMAE: 59.8299, R^2: 0.2126\n",
      "Epoch [60/1500]\n",
      "Train Loss: 2869.2506\n",
      "Val Loss: 3784.4804, MAE: 3784.9802, NMAE: 57.6201, R^2: 0.2555\n",
      "Epoch [61/1500]\n",
      "Train Loss: 2959.3551\n",
      "Val Loss: 3906.4495, MAE: 3906.9495, NMAE: 59.4769, R^2: 0.2405\n",
      "Epoch [62/1500]\n",
      "Train Loss: 2901.7721\n",
      "Val Loss: 4097.8064, MAE: 4098.3062, NMAE: 62.3900, R^2: 0.1901\n",
      "Epoch [63/1500]\n",
      "Train Loss: 2898.1626\n",
      "Val Loss: 3972.7657, MAE: 3973.2659, NMAE: 60.4864, R^2: 0.2003\n",
      "Epoch [64/1500]\n",
      "Train Loss: 2821.3270\n",
      "Val Loss: 3881.1793, MAE: 3881.6792, NMAE: 59.0922, R^2: 0.2282\n",
      "Epoch [65/1500]\n",
      "Train Loss: 2784.6019\n",
      "Val Loss: 4101.8952, MAE: 4102.3950, NMAE: 62.4522, R^2: 0.1795\n",
      "Epoch [66/1500]\n",
      "Train Loss: 2730.6328\n",
      "Val Loss: 3980.6885, MAE: 3981.1885, NMAE: 60.6070, R^2: 0.2206\n",
      "Epoch [67/1500]\n",
      "Train Loss: 2661.9068\n",
      "Val Loss: 4122.8934, MAE: 4123.3931, NMAE: 62.7719, R^2: 0.1603\n",
      "Epoch [68/1500]\n",
      "Train Loss: 2672.1657\n",
      "Val Loss: 3874.5513, MAE: 3875.0510, NMAE: 58.9913, R^2: 0.2386\n",
      "Epoch [69/1500]\n",
      "Train Loss: 2652.3594\n",
      "Val Loss: 3965.5686, MAE: 3966.0686, NMAE: 60.3769, R^2: 0.2232\n",
      "Epoch [70/1500]\n",
      "Train Loss: 2657.7478\n",
      "Val Loss: 4029.8984, MAE: 4030.3982, NMAE: 61.3562, R^2: 0.2134\n",
      "Epoch [71/1500]\n",
      "Train Loss: 2598.5935\n",
      "Val Loss: 4142.2111, MAE: 4142.7109, NMAE: 63.0659, R^2: 0.1632\n",
      "Epoch [72/1500]\n",
      "Train Loss: 2643.0098\n",
      "Val Loss: 3925.7003, MAE: 3926.2004, NMAE: 59.7699, R^2: 0.2023\n",
      "Epoch [73/1500]\n",
      "Train Loss: 2604.7260\n",
      "Val Loss: 3965.4479, MAE: 3965.9475, NMAE: 60.3750, R^2: 0.2038\n",
      "Epoch [74/1500]\n",
      "Train Loss: 2550.2794\n",
      "Val Loss: 4026.6142, MAE: 4027.1140, NMAE: 61.3062, R^2: 0.2203\n",
      "Epoch [75/1500]\n",
      "Train Loss: 2519.2335\n",
      "Val Loss: 3874.5609, MAE: 3875.0608, NMAE: 58.9914, R^2: 0.2469\n",
      "Epoch [76/1500]\n",
      "Train Loss: 2521.6050\n",
      "Val Loss: 3897.2903, MAE: 3897.7898, NMAE: 59.3374, R^2: 0.2375\n",
      "Epoch [77/1500]\n",
      "Train Loss: 2491.7843\n",
      "Val Loss: 3847.2368, MAE: 3847.7368, NMAE: 58.5755, R^2: 0.2325\n",
      "Epoch [78/1500]\n",
      "Train Loss: 2413.8546\n",
      "Val Loss: 4109.2053, MAE: 4109.7051, NMAE: 62.5635, R^2: 0.1726\n",
      "Epoch [79/1500]\n",
      "Train Loss: 2417.5572\n",
      "Val Loss: 4205.7593, MAE: 4206.2588, NMAE: 64.0334, R^2: 0.1445\n",
      "Epoch [80/1500]\n",
      "Train Loss: 2554.3158\n",
      "Val Loss: 4055.7908, MAE: 4056.2905, NMAE: 61.7503, R^2: 0.2004\n",
      "Epoch [81/1500]\n",
      "Train Loss: 2555.9267\n",
      "Val Loss: 3810.1519, MAE: 3810.6519, NMAE: 58.0109, R^2: 0.2711\n",
      "Epoch [82/1500]\n",
      "Train Loss: 2411.9509\n",
      "Val Loss: 3764.5961, MAE: 3765.0959, NMAE: 57.3174, R^2: 0.2636\n",
      "Epoch [83/1500]\n",
      "Train Loss: 2486.1885\n",
      "Val Loss: 3773.4323, MAE: 3773.9321, NMAE: 57.4519, R^2: 0.2658\n",
      "Epoch [84/1500]\n",
      "Train Loss: 2438.4738\n",
      "Val Loss: 3709.3524, MAE: 3709.8523, NMAE: 56.4764, R^2: 0.2868\n",
      "Epoch [85/1500]\n",
      "Train Loss: 2373.1192\n",
      "Val Loss: 3885.8318, MAE: 3886.3315, NMAE: 59.1630, R^2: 0.2253\n",
      "Epoch [86/1500]\n",
      "Train Loss: 2278.7543\n",
      "Val Loss: 3738.9214, MAE: 3739.4216, NMAE: 56.9265, R^2: 0.2611\n",
      "Epoch [87/1500]\n",
      "Train Loss: 2288.9043\n",
      "Val Loss: 3756.2413, MAE: 3756.7415, NMAE: 57.1902, R^2: 0.2639\n",
      "Epoch [88/1500]\n",
      "Train Loss: 2274.7603\n",
      "Val Loss: 3770.8571, MAE: 3771.3567, NMAE: 57.4127, R^2: 0.2622\n",
      "Epoch [89/1500]\n",
      "Train Loss: 2271.3185\n",
      "Val Loss: 3783.5886, MAE: 3784.0881, NMAE: 57.6065, R^2: 0.2370\n",
      "Epoch [90/1500]\n",
      "Train Loss: 2273.7605\n",
      "Val Loss: 3796.4362, MAE: 3796.9360, NMAE: 57.8021, R^2: 0.2489\n",
      "Epoch [91/1500]\n",
      "Train Loss: 2257.9836\n",
      "Val Loss: 3735.1324, MAE: 3735.6323, NMAE: 56.8688, R^2: 0.2838\n",
      "Epoch [92/1500]\n",
      "Train Loss: 2209.3838\n",
      "Val Loss: 3798.6289, MAE: 3799.1287, NMAE: 57.8355, R^2: 0.2493\n",
      "Epoch [93/1500]\n",
      "Train Loss: 2169.7129\n",
      "Val Loss: 3830.6195, MAE: 3831.1194, NMAE: 58.3225, R^2: 0.2272\n",
      "Epoch [94/1500]\n",
      "Train Loss: 2169.9262\n",
      "Val Loss: 3831.5329, MAE: 3832.0327, NMAE: 58.3364, R^2: 0.2441\n",
      "Epoch [95/1500]\n",
      "Train Loss: 2175.2271\n",
      "Val Loss: 3781.5332, MAE: 3782.0330, NMAE: 57.5752, R^2: 0.2751\n",
      "Epoch [96/1500]\n",
      "Train Loss: 2147.9984\n",
      "Val Loss: 3832.4608, MAE: 3832.9607, NMAE: 58.3505, R^2: 0.2494\n",
      "Epoch [97/1500]\n",
      "Train Loss: 2099.6495\n",
      "Val Loss: 3784.9169, MAE: 3785.4167, NMAE: 57.6267, R^2: 0.2663\n",
      "Epoch [98/1500]\n",
      "Train Loss: 2089.8969\n",
      "Val Loss: 3893.9873, MAE: 3894.4868, NMAE: 59.2871, R^2: 0.2136\n",
      "Epoch [99/1500]\n",
      "Train Loss: 2134.7750\n",
      "Val Loss: 3772.1718, MAE: 3772.6716, NMAE: 57.4327, R^2: 0.2588\n",
      "Epoch [100/1500]\n",
      "Train Loss: 2133.8662\n",
      "Val Loss: 3807.1585, MAE: 3807.6582, NMAE: 57.9653, R^2: 0.2513\n",
      "Epoch [101/1500]\n",
      "Train Loss: 2097.6755\n",
      "Val Loss: 3655.9917, MAE: 3656.4915, NMAE: 55.6641, R^2: 0.3035\n",
      "Epoch [102/1500]\n",
      "Train Loss: 2042.0540\n",
      "Val Loss: 3769.0965, MAE: 3769.5964, NMAE: 57.3859, R^2: 0.2630\n",
      "Epoch [103/1500]\n",
      "Train Loss: 2062.6760\n",
      "Val Loss: 3695.0240, MAE: 3695.5239, NMAE: 56.2583, R^2: 0.2806\n",
      "Epoch [104/1500]\n",
      "Train Loss: 2054.7739\n",
      "Val Loss: 3701.3884, MAE: 3701.8882, NMAE: 56.3551, R^2: 0.2654\n",
      "Epoch [105/1500]\n",
      "Train Loss: 1979.1536\n",
      "Val Loss: 3726.5484, MAE: 3727.0483, NMAE: 56.7382, R^2: 0.2646\n",
      "Epoch [106/1500]\n",
      "Train Loss: 1975.2437\n",
      "Val Loss: 3734.3254, MAE: 3734.8252, NMAE: 56.8566, R^2: 0.2817\n",
      "Epoch [107/1500]\n",
      "Train Loss: 1974.5447\n",
      "Val Loss: 3717.8006, MAE: 3718.3005, NMAE: 56.6050, R^2: 0.2769\n",
      "Epoch [108/1500]\n",
      "Train Loss: 1998.3674\n",
      "Val Loss: 3782.6430, MAE: 3783.1426, NMAE: 57.5921, R^2: 0.2415\n",
      "Epoch [109/1500]\n",
      "Train Loss: 2063.4860\n",
      "Val Loss: 3639.7350, MAE: 3640.2349, NMAE: 55.4166, R^2: 0.3018\n",
      "Epoch [110/1500]\n",
      "Train Loss: 1945.2813\n",
      "Val Loss: 3752.5367, MAE: 3753.0366, NMAE: 57.1338, R^2: 0.2526\n",
      "Epoch [111/1500]\n",
      "Train Loss: 1959.9923\n",
      "Val Loss: 3697.4537, MAE: 3697.9536, NMAE: 56.2952, R^2: 0.2766\n",
      "Epoch [112/1500]\n",
      "Train Loss: 1950.1889\n",
      "Val Loss: 3720.0539, MAE: 3720.5540, NMAE: 56.6393, R^2: 0.2885\n",
      "Epoch [113/1500]\n",
      "Train Loss: 1955.5893\n",
      "Val Loss: 3733.1241, MAE: 3733.6240, NMAE: 56.8383, R^2: 0.2642\n",
      "Epoch [114/1500]\n",
      "Train Loss: 1883.4192\n",
      "Val Loss: 3847.3071, MAE: 3847.8069, NMAE: 58.5765, R^2: 0.2571\n",
      "Epoch [115/1500]\n",
      "Train Loss: 1907.3214\n",
      "Val Loss: 3846.9251, MAE: 3847.4250, NMAE: 58.5707, R^2: 0.2534\n",
      "Epoch [116/1500]\n",
      "Train Loss: 1912.7480\n",
      "Val Loss: 3747.1603, MAE: 3747.6599, NMAE: 57.0519, R^2: 0.2803\n",
      "Epoch [117/1500]\n",
      "Train Loss: 1914.3116\n",
      "Val Loss: 3823.3404, MAE: 3823.8403, NMAE: 58.2117, R^2: 0.2761\n",
      "Epoch [118/1500]\n",
      "Train Loss: 1867.7117\n",
      "Val Loss: 3814.2419, MAE: 3814.7419, NMAE: 58.0732, R^2: 0.2706\n",
      "Epoch [119/1500]\n",
      "Train Loss: 1930.0471\n",
      "Val Loss: 3761.5164, MAE: 3762.0164, NMAE: 57.2705, R^2: 0.2574\n",
      "Epoch [120/1500]\n",
      "Train Loss: 1935.0148\n",
      "Val Loss: 3684.4432, MAE: 3684.9429, NMAE: 56.0972, R^2: 0.2828\n",
      "Epoch [121/1500]\n",
      "Train Loss: 1879.8811\n",
      "Val Loss: 3709.7045, MAE: 3710.2043, NMAE: 56.4817, R^2: 0.2659\n",
      "Epoch [122/1500]\n",
      "Train Loss: 1888.0238\n",
      "Val Loss: 3649.9762, MAE: 3650.4758, NMAE: 55.5725, R^2: 0.2904\n",
      "Epoch [123/1500]\n",
      "Train Loss: 1848.9764\n",
      "Val Loss: 3600.9589, MAE: 3601.4587, NMAE: 54.8263, R^2: 0.3233\n",
      "Epoch [124/1500]\n",
      "Train Loss: 1894.5963\n",
      "Val Loss: 3661.6558, MAE: 3662.1555, NMAE: 55.7503, R^2: 0.2879\n",
      "Epoch [125/1500]\n",
      "Train Loss: 1846.5746\n",
      "Val Loss: 3687.0609, MAE: 3687.5608, NMAE: 56.1370, R^2: 0.2872\n",
      "Epoch [126/1500]\n",
      "Train Loss: 1865.1360\n",
      "Val Loss: 3704.8834, MAE: 3705.3831, NMAE: 56.4084, R^2: 0.2801\n",
      "Epoch [127/1500]\n",
      "Train Loss: 1842.0304\n",
      "Val Loss: 3690.0545, MAE: 3690.5544, NMAE: 56.1826, R^2: 0.2949\n",
      "Epoch [128/1500]\n",
      "Train Loss: 1859.7656\n",
      "Val Loss: 3724.5345, MAE: 3725.0344, NMAE: 56.7075, R^2: 0.2790\n",
      "Epoch [129/1500]\n",
      "Train Loss: 1872.8428\n",
      "Val Loss: 3760.0617, MAE: 3760.5615, NMAE: 57.2484, R^2: 0.2963\n",
      "Epoch [130/1500]\n",
      "Train Loss: 1804.0942\n",
      "Val Loss: 3707.1371, MAE: 3707.6370, NMAE: 56.4427, R^2: 0.3105\n",
      "Epoch [131/1500]\n",
      "Train Loss: 1810.2670\n",
      "Val Loss: 3733.6010, MAE: 3734.1006, NMAE: 56.8455, R^2: 0.2975\n",
      "Epoch [132/1500]\n",
      "Train Loss: 1843.8680\n",
      "Val Loss: 3708.0830, MAE: 3708.5830, NMAE: 56.4571, R^2: 0.2956\n",
      "Epoch [133/1500]\n",
      "Train Loss: 1780.1970\n",
      "Val Loss: 3652.3974, MAE: 3652.8972, NMAE: 55.6093, R^2: 0.2915\n",
      "Epoch [134/1500]\n",
      "Train Loss: 1757.5700\n",
      "Val Loss: 3655.9480, MAE: 3656.4478, NMAE: 55.6634, R^2: 0.2928\n",
      "Epoch [135/1500]\n",
      "Train Loss: 1860.7516\n",
      "Val Loss: 3660.9817, MAE: 3661.4814, NMAE: 55.7400, R^2: 0.2963\n",
      "Epoch [136/1500]\n",
      "Train Loss: 1801.1528\n",
      "Val Loss: 3639.2800, MAE: 3639.7800, NMAE: 55.4097, R^2: 0.3148\n",
      "Epoch [137/1500]\n",
      "Train Loss: 1766.1223\n",
      "Val Loss: 3770.5676, MAE: 3771.0674, NMAE: 57.4083, R^2: 0.2833\n",
      "Epoch [138/1500]\n",
      "Train Loss: 1776.4761\n",
      "Val Loss: 3568.9177, MAE: 3569.4177, NMAE: 54.3385, R^2: 0.3329\n",
      "Epoch [139/1500]\n",
      "Train Loss: 1811.5898\n",
      "Val Loss: 3685.3590, MAE: 3685.8586, NMAE: 56.1111, R^2: 0.2957\n",
      "Epoch [140/1500]\n",
      "Train Loss: 1785.5435\n",
      "Val Loss: 3627.7279, MAE: 3628.2275, NMAE: 55.2338, R^2: 0.3127\n",
      "Epoch [141/1500]\n",
      "Train Loss: 1739.1323\n",
      "Val Loss: 3606.7475, MAE: 3607.2473, NMAE: 54.9144, R^2: 0.3250\n",
      "Epoch [142/1500]\n",
      "Train Loss: 1741.5909\n",
      "Val Loss: 3698.1645, MAE: 3698.6643, NMAE: 56.3061, R^2: 0.3184\n",
      "Epoch [143/1500]\n",
      "Train Loss: 1734.9817\n",
      "Val Loss: 3623.9119, MAE: 3624.4116, NMAE: 55.1757, R^2: 0.3109\n",
      "Epoch [144/1500]\n",
      "Train Loss: 1785.7126\n",
      "Val Loss: 3602.7072, MAE: 3603.2070, NMAE: 54.8529, R^2: 0.3339\n",
      "Epoch [145/1500]\n",
      "Train Loss: 1711.7764\n",
      "Val Loss: 3783.6500, MAE: 3784.1499, NMAE: 57.6074, R^2: 0.2875\n",
      "Epoch [146/1500]\n",
      "Train Loss: 1819.0592\n",
      "Val Loss: 3681.6369, MAE: 3682.1367, NMAE: 56.0545, R^2: 0.3015\n",
      "Epoch [147/1500]\n",
      "Train Loss: 1803.7625\n",
      "Val Loss: 3640.5965, MAE: 3641.0964, NMAE: 55.4297, R^2: 0.3071\n",
      "Epoch [148/1500]\n",
      "Train Loss: 1770.5871\n",
      "Val Loss: 3648.6419, MAE: 3649.1416, NMAE: 55.5522, R^2: 0.3088\n",
      "Epoch [149/1500]\n",
      "Train Loss: 1781.3134\n",
      "Val Loss: 3649.4286, MAE: 3649.9285, NMAE: 55.5641, R^2: 0.3183\n",
      "Epoch [150/1500]\n",
      "Train Loss: 1730.0261\n",
      "Val Loss: 3667.4604, MAE: 3667.9600, NMAE: 55.8386, R^2: 0.3111\n",
      "Epoch [151/1500]\n",
      "Train Loss: 1734.4814\n",
      "Val Loss: 3678.4091, MAE: 3678.9084, NMAE: 56.0053, R^2: 0.2920\n",
      "Epoch [152/1500]\n",
      "Train Loss: 1697.7451\n",
      "Val Loss: 3638.6096, MAE: 3639.1094, NMAE: 55.3994, R^2: 0.3182\n",
      "Epoch [153/1500]\n",
      "Train Loss: 1676.8074\n",
      "Val Loss: 3600.6172, MAE: 3601.1172, NMAE: 54.8211, R^2: 0.3410\n",
      "Epoch [154/1500]\n",
      "Train Loss: 1681.5971\n",
      "Val Loss: 3714.5694, MAE: 3715.0691, NMAE: 56.5558, R^2: 0.2884\n",
      "Epoch [155/1500]\n",
      "Train Loss: 1684.2238\n",
      "Val Loss: 3654.2860, MAE: 3654.7859, NMAE: 55.6381, R^2: 0.3015\n",
      "Epoch [156/1500]\n",
      "Train Loss: 1756.6272\n",
      "Val Loss: 3661.2718, MAE: 3661.7715, NMAE: 55.7444, R^2: 0.3186\n",
      "Epoch [157/1500]\n",
      "Train Loss: 1735.6671\n",
      "Val Loss: 3673.0060, MAE: 3673.5059, NMAE: 55.9231, R^2: 0.2823\n",
      "Epoch [158/1500]\n",
      "Train Loss: 1749.3126\n",
      "Val Loss: 3645.6364, MAE: 3646.1362, NMAE: 55.5064, R^2: 0.3041\n",
      "Epoch [159/1500]\n",
      "Train Loss: 1765.6931\n",
      "Val Loss: 3641.7213, MAE: 3642.2212, NMAE: 55.4468, R^2: 0.3104\n",
      "Epoch [160/1500]\n",
      "Train Loss: 1758.3834\n",
      "Val Loss: 3752.6345, MAE: 3753.1343, NMAE: 57.1353, R^2: 0.2788\n",
      "Epoch [161/1500]\n",
      "Train Loss: 1793.9524\n",
      "Val Loss: 3636.6446, MAE: 3637.1443, NMAE: 55.3695, R^2: 0.3159\n",
      "Epoch [162/1500]\n",
      "Train Loss: 1713.3727\n",
      "Val Loss: 3699.7661, MAE: 3700.2659, NMAE: 56.3304, R^2: 0.2995\n",
      "Epoch [163/1500]\n",
      "Train Loss: 1749.2245\n",
      "Val Loss: 3649.4438, MAE: 3649.9438, NMAE: 55.5644, R^2: 0.3051\n",
      "Epoch [164/1500]\n",
      "Train Loss: 1754.3177\n",
      "Val Loss: 3618.6658, MAE: 3619.1658, NMAE: 55.0958, R^2: 0.3082\n",
      "Epoch [165/1500]\n",
      "Train Loss: 1736.7131\n",
      "Val Loss: 3595.2382, MAE: 3595.7383, NMAE: 54.7392, R^2: 0.3313\n",
      "Epoch [166/1500]\n",
      "Train Loss: 1681.3254\n",
      "Val Loss: 3624.2498, MAE: 3624.7500, NMAE: 55.1808, R^2: 0.3185\n",
      "Epoch [167/1500]\n",
      "Train Loss: 1719.6584\n",
      "Val Loss: 3615.4927, MAE: 3615.9924, NMAE: 55.0475, R^2: 0.3325\n",
      "Epoch [168/1500]\n",
      "Train Loss: 1767.1831\n",
      "Val Loss: 3615.1168, MAE: 3615.6165, NMAE: 55.0418, R^2: 0.3192\n",
      "Epoch [169/1500]\n",
      "Train Loss: 1772.9121\n",
      "Val Loss: 3674.8927, MAE: 3675.3926, NMAE: 55.9518, R^2: 0.3112\n",
      "Epoch [170/1500]\n",
      "Train Loss: 1725.3965\n",
      "Val Loss: 3716.6382, MAE: 3717.1382, NMAE: 56.5873, R^2: 0.2880\n",
      "Epoch [171/1500]\n",
      "Train Loss: 1694.6087\n",
      "Val Loss: 3657.7231, MAE: 3658.2229, NMAE: 55.6904, R^2: 0.3024\n",
      "Epoch [172/1500]\n",
      "Train Loss: 1708.4005\n",
      "Val Loss: 3659.1889, MAE: 3659.6887, NMAE: 55.7127, R^2: 0.3196\n",
      "Epoch [173/1500]\n",
      "Train Loss: 1693.9965\n",
      "Val Loss: 3697.1717, MAE: 3697.6714, NMAE: 56.2910, R^2: 0.3021\n",
      "Epoch [174/1500]\n",
      "Train Loss: 1660.9506\n",
      "Val Loss: 3576.1265, MAE: 3576.6262, NMAE: 54.4482, R^2: 0.3353\n",
      "Epoch [175/1500]\n",
      "Train Loss: 1662.2168\n",
      "Val Loss: 3652.6337, MAE: 3653.1335, NMAE: 55.6129, R^2: 0.3168\n",
      "Epoch [176/1500]\n",
      "Train Loss: 1698.1110\n",
      "Val Loss: 3625.0843, MAE: 3625.5840, NMAE: 55.1935, R^2: 0.2952\n",
      "Epoch [177/1500]\n",
      "Train Loss: 1659.9714\n",
      "Val Loss: 3547.1562, MAE: 3547.6560, NMAE: 54.0072, R^2: 0.3410\n",
      "Epoch [178/1500]\n",
      "Train Loss: 1648.2595\n",
      "Val Loss: 3566.0717, MAE: 3566.5715, NMAE: 54.2952, R^2: 0.3383\n",
      "Epoch [179/1500]\n",
      "Train Loss: 1623.8077\n",
      "Val Loss: 3579.2208, MAE: 3579.7205, NMAE: 54.4953, R^2: 0.3342\n",
      "Epoch [180/1500]\n",
      "Train Loss: 1618.6142\n",
      "Val Loss: 3564.0234, MAE: 3564.5232, NMAE: 54.2640, R^2: 0.3454\n",
      "Epoch [181/1500]\n",
      "Train Loss: 1644.0928\n",
      "Val Loss: 3586.6937, MAE: 3587.1936, NMAE: 54.6091, R^2: 0.3379\n",
      "Epoch [182/1500]\n",
      "Train Loss: 1618.4563\n",
      "Val Loss: 3582.7373, MAE: 3583.2373, NMAE: 54.5489, R^2: 0.3139\n",
      "Epoch [183/1500]\n",
      "Train Loss: 1613.9681\n",
      "Val Loss: 3636.4425, MAE: 3636.9426, NMAE: 55.3665, R^2: 0.3126\n",
      "Epoch [184/1500]\n",
      "Train Loss: 1700.6001\n",
      "Val Loss: 3670.5671, MAE: 3671.0669, NMAE: 55.8859, R^2: 0.3070\n",
      "Epoch [185/1500]\n",
      "Train Loss: 1653.7678\n",
      "Val Loss: 3657.8411, MAE: 3658.3408, NMAE: 55.6922, R^2: 0.3265\n",
      "Epoch [186/1500]\n",
      "Train Loss: 1635.1241\n",
      "Val Loss: 3656.6745, MAE: 3657.1743, NMAE: 55.6745, R^2: 0.3252\n",
      "Epoch [187/1500]\n",
      "Train Loss: 1619.5475\n",
      "Val Loss: 3617.9284, MAE: 3618.4280, NMAE: 55.0846, R^2: 0.3195\n",
      "Epoch [188/1500]\n",
      "Train Loss: 1714.2166\n",
      "Val Loss: 3739.7517, MAE: 3740.2515, NMAE: 56.9392, R^2: 0.3037\n",
      "Epoch [189/1500]\n",
      "Train Loss: 1638.0588\n",
      "Val Loss: 3703.4769, MAE: 3703.9766, NMAE: 56.3869, R^2: 0.3075\n",
      "Epoch [190/1500]\n",
      "Train Loss: 1596.7302\n",
      "Val Loss: 3649.4344, MAE: 3649.9341, NMAE: 55.5642, R^2: 0.3146\n",
      "Epoch [191/1500]\n",
      "Train Loss: 1642.7639\n",
      "Val Loss: 3753.8914, MAE: 3754.3914, NMAE: 57.1544, R^2: 0.2832\n",
      "Epoch [192/1500]\n",
      "Train Loss: 1579.0617\n",
      "Val Loss: 3673.3114, MAE: 3673.8115, NMAE: 55.9277, R^2: 0.3063\n",
      "Epoch [193/1500]\n",
      "Train Loss: 1614.8765\n",
      "Val Loss: 3600.1601, MAE: 3600.6599, NMAE: 54.8141, R^2: 0.3216\n",
      "Epoch [194/1500]\n",
      "Train Loss: 1590.1053\n",
      "Val Loss: 3641.6907, MAE: 3642.1909, NMAE: 55.4464, R^2: 0.3031\n",
      "Epoch [195/1500]\n",
      "Train Loss: 1622.7678\n",
      "Val Loss: 3667.7422, MAE: 3668.2422, NMAE: 55.8429, R^2: 0.3136\n",
      "Epoch [196/1500]\n",
      "Train Loss: 1600.7301\n",
      "Val Loss: 3702.4436, MAE: 3702.9434, NMAE: 56.3712, R^2: 0.2895\n",
      "Epoch [197/1500]\n",
      "Train Loss: 1637.2286\n",
      "Val Loss: 3638.0857, MAE: 3638.5854, NMAE: 55.3915, R^2: 0.3240\n",
      "Epoch [198/1500]\n",
      "Train Loss: 1636.6403\n",
      "Val Loss: 3645.1694, MAE: 3645.6692, NMAE: 55.4993, R^2: 0.3305\n",
      "Epoch [199/1500]\n",
      "Train Loss: 1650.9157\n",
      "Val Loss: 3650.6955, MAE: 3651.1953, NMAE: 55.5834, R^2: 0.2978\n",
      "Epoch [200/1500]\n",
      "Train Loss: 1605.5407\n",
      "Val Loss: 3675.2453, MAE: 3675.7451, NMAE: 55.9572, R^2: 0.3105\n",
      "Epoch [201/1500]\n",
      "Train Loss: 1605.4849\n",
      "Val Loss: 3743.0445, MAE: 3743.5442, NMAE: 56.9893, R^2: 0.2922\n",
      "Epoch [202/1500]\n",
      "Train Loss: 1575.3391\n",
      "Val Loss: 3693.7025, MAE: 3694.2024, NMAE: 56.2381, R^2: 0.3010\n",
      "Epoch [203/1500]\n",
      "Train Loss: 1596.0561\n",
      "Val Loss: 3632.6007, MAE: 3633.1003, NMAE: 55.3080, R^2: 0.3148\n",
      "Epoch [204/1500]\n",
      "Train Loss: 1619.8359\n",
      "Val Loss: 3695.2925, MAE: 3695.7925, NMAE: 56.2624, R^2: 0.3104\n",
      "Epoch [205/1500]\n",
      "Train Loss: 1630.8072\n",
      "Val Loss: 3670.2822, MAE: 3670.7822, NMAE: 55.8816, R^2: 0.3013\n",
      "Epoch [206/1500]\n",
      "Train Loss: 1616.6952\n",
      "Val Loss: 3575.3153, MAE: 3575.8149, NMAE: 54.4359, R^2: 0.3324\n",
      "Epoch [207/1500]\n",
      "Train Loss: 1588.9732\n",
      "Val Loss: 3620.9983, MAE: 3621.4983, NMAE: 55.1313, R^2: 0.3174\n",
      "Epoch [208/1500]\n",
      "Train Loss: 1600.7263\n",
      "Val Loss: 3585.9177, MAE: 3586.4177, NMAE: 54.5973, R^2: 0.3203\n",
      "Epoch [209/1500]\n",
      "Train Loss: 1593.9668\n",
      "Val Loss: 3646.1804, MAE: 3646.6802, NMAE: 55.5147, R^2: 0.3198\n",
      "Epoch [210/1500]\n",
      "Train Loss: 1583.4588\n",
      "Val Loss: 3602.2392, MAE: 3602.7390, NMAE: 54.8458, R^2: 0.3253\n",
      "Epoch [211/1500]\n",
      "Train Loss: 1602.3774\n",
      "Val Loss: 3711.0091, MAE: 3711.5090, NMAE: 56.5016, R^2: 0.2876\n",
      "Epoch [212/1500]\n",
      "Train Loss: 1644.0153\n",
      "Val Loss: 3678.0443, MAE: 3678.5442, NMAE: 55.9998, R^2: 0.3169\n",
      "Epoch [213/1500]\n",
      "Train Loss: 1634.0269\n",
      "Val Loss: 3658.5085, MAE: 3659.0085, NMAE: 55.7024, R^2: 0.3182\n",
      "Epoch [214/1500]\n",
      "Train Loss: 1622.2891\n",
      "Val Loss: 3616.7743, MAE: 3617.2739, NMAE: 55.0670, R^2: 0.3154\n",
      "Epoch [215/1500]\n",
      "Train Loss: 1600.6343\n",
      "Val Loss: 3700.5333, MAE: 3701.0332, NMAE: 56.3421, R^2: 0.3119\n",
      "Epoch [216/1500]\n",
      "Train Loss: 1633.4543\n",
      "Val Loss: 3695.1143, MAE: 3695.6140, NMAE: 56.2596, R^2: 0.2978\n",
      "Epoch [217/1500]\n",
      "Train Loss: 1589.7309\n",
      "Val Loss: 3692.6801, MAE: 3693.1797, NMAE: 56.2226, R^2: 0.3247\n",
      "Epoch [218/1500]\n",
      "Train Loss: 1591.2930\n",
      "Val Loss: 3676.8767, MAE: 3677.3765, NMAE: 55.9820, R^2: 0.3096\n",
      "Epoch [219/1500]\n",
      "Train Loss: 1577.6670\n",
      "Val Loss: 3723.9058, MAE: 3724.4058, NMAE: 56.6979, R^2: 0.2931\n",
      "Epoch [220/1500]\n",
      "Train Loss: 1609.9284\n",
      "Val Loss: 3645.8911, MAE: 3646.3914, NMAE: 55.5103, R^2: 0.3066\n",
      "Epoch [221/1500]\n",
      "Train Loss: 1660.7733\n",
      "Val Loss: 3682.0541, MAE: 3682.5537, NMAE: 56.0608, R^2: 0.3043\n",
      "Epoch [222/1500]\n",
      "Train Loss: 1635.0991\n",
      "Val Loss: 3667.9461, MAE: 3668.4460, NMAE: 55.8460, R^2: 0.3182\n",
      "Epoch [223/1500]\n",
      "Train Loss: 1588.1221\n",
      "Val Loss: 3646.3575, MAE: 3646.8572, NMAE: 55.5174, R^2: 0.3258\n",
      "Epoch [224/1500]\n",
      "Train Loss: 1604.8455\n",
      "Val Loss: 3634.5568, MAE: 3635.0566, NMAE: 55.3377, R^2: 0.3297\n",
      "Epoch [225/1500]\n",
      "Train Loss: 1596.9450\n",
      "Val Loss: 3637.7085, MAE: 3638.2083, NMAE: 55.3857, R^2: 0.3033\n",
      "Epoch [226/1500]\n",
      "Train Loss: 1581.9475\n",
      "Val Loss: 3730.6499, MAE: 3731.1497, NMAE: 56.8006, R^2: 0.2890\n",
      "Epoch [227/1500]\n",
      "Train Loss: 1599.3467\n",
      "Val Loss: 3858.7221, MAE: 3859.2222, NMAE: 58.7503, R^2: 0.2615\n",
      "Epoch [228/1500]\n",
      "Train Loss: 1571.1573\n",
      "Val Loss: 3718.4452, MAE: 3718.9451, NMAE: 56.6148, R^2: 0.2965\n",
      "Epoch [229/1500]\n",
      "Train Loss: 1535.9656\n",
      "Val Loss: 3694.2256, MAE: 3694.7256, NMAE: 56.2461, R^2: 0.3198\n",
      "Epoch [230/1500]\n",
      "Train Loss: 1534.7797\n",
      "Val Loss: 3647.8325, MAE: 3648.3323, NMAE: 55.5398, R^2: 0.3138\n",
      "Epoch [231/1500]\n",
      "Train Loss: 1526.3883\n",
      "Val Loss: 3682.8579, MAE: 3683.3577, NMAE: 56.0731, R^2: 0.3066\n",
      "Epoch [232/1500]\n",
      "Train Loss: 1556.9601\n",
      "Val Loss: 3709.9574, MAE: 3710.4570, NMAE: 56.4856, R^2: 0.2953\n",
      "Epoch [233/1500]\n",
      "Train Loss: 1577.1099\n",
      "Val Loss: 3691.8309, MAE: 3692.3308, NMAE: 56.2097, R^2: 0.3020\n",
      "Epoch [234/1500]\n",
      "Train Loss: 1552.1929\n",
      "Val Loss: 3675.1907, MAE: 3675.6907, NMAE: 55.9563, R^2: 0.3118\n",
      "Epoch [235/1500]\n",
      "Train Loss: 1615.2344\n",
      "Val Loss: 3681.0922, MAE: 3681.5923, NMAE: 56.0462, R^2: 0.3066\n",
      "Epoch [236/1500]\n",
      "Train Loss: 1556.6096\n",
      "Val Loss: 3656.5055, MAE: 3657.0054, NMAE: 55.6719, R^2: 0.3199\n",
      "Epoch [237/1500]\n",
      "Train Loss: 1562.7124\n",
      "Val Loss: 3694.5498, MAE: 3695.0496, NMAE: 56.2510, R^2: 0.2929\n",
      "Epoch [238/1500]\n",
      "Train Loss: 1601.0024\n",
      "Val Loss: 3721.0297, MAE: 3721.5295, NMAE: 56.6542, R^2: 0.2900\n",
      "Epoch [239/1500]\n",
      "Train Loss: 1578.1818\n",
      "Val Loss: 3761.7918, MAE: 3762.2917, NMAE: 57.2747, R^2: 0.2813\n",
      "Epoch [240/1500]\n",
      "Train Loss: 1551.1988\n",
      "Val Loss: 3652.1696, MAE: 3652.6694, NMAE: 55.6059, R^2: 0.3201\n",
      "Epoch [241/1500]\n",
      "Train Loss: 1571.6112\n",
      "Val Loss: 3673.4553, MAE: 3673.9553, NMAE: 55.9299, R^2: 0.3193\n",
      "Epoch [242/1500]\n",
      "Train Loss: 1550.7543\n",
      "Val Loss: 3656.9842, MAE: 3657.4839, NMAE: 55.6792, R^2: 0.3233\n",
      "Epoch [243/1500]\n",
      "Train Loss: 1593.9919\n",
      "Val Loss: 3653.9230, MAE: 3654.4229, NMAE: 55.6326, R^2: 0.3299\n",
      "Epoch [244/1500]\n",
      "Train Loss: 1662.2903\n",
      "Val Loss: 3607.4295, MAE: 3607.9294, NMAE: 54.9248, R^2: 0.3312\n",
      "Epoch [245/1500]\n",
      "Train Loss: 1607.3713\n",
      "Val Loss: 3668.7877, MAE: 3669.2876, NMAE: 55.8589, R^2: 0.2998\n",
      "Epoch [246/1500]\n",
      "Train Loss: 1572.3339\n",
      "Val Loss: 3647.0239, MAE: 3647.5237, NMAE: 55.5275, R^2: 0.3092\n",
      "Epoch [247/1500]\n",
      "Train Loss: 1551.5052\n",
      "Val Loss: 3755.7794, MAE: 3756.2791, NMAE: 57.1832, R^2: 0.2889\n",
      "Epoch [248/1500]\n",
      "Train Loss: 1548.9390\n",
      "Val Loss: 3669.1650, MAE: 3669.6650, NMAE: 55.8646, R^2: 0.3132\n",
      "Epoch [249/1500]\n",
      "Train Loss: 1564.1439\n",
      "Val Loss: 3719.9300, MAE: 3720.4297, NMAE: 56.6374, R^2: 0.3041\n",
      "Epoch [250/1500]\n",
      "Train Loss: 1577.2133\n",
      "Val Loss: 3680.0542, MAE: 3680.5540, NMAE: 56.0304, R^2: 0.3030\n",
      "Epoch [251/1500]\n",
      "Train Loss: 1560.1704\n",
      "Val Loss: 3616.4443, MAE: 3616.9443, NMAE: 55.0620, R^2: 0.3206\n",
      "Epoch [252/1500]\n",
      "Train Loss: 1563.8548\n",
      "Val Loss: 3657.6665, MAE: 3658.1665, NMAE: 55.6896, R^2: 0.3041\n",
      "Epoch [253/1500]\n",
      "Train Loss: 1653.3009\n",
      "Val Loss: 3660.1699, MAE: 3660.6699, NMAE: 55.7277, R^2: 0.3087\n",
      "Epoch [254/1500]\n",
      "Train Loss: 1625.4250\n",
      "Val Loss: 3714.2784, MAE: 3714.7778, NMAE: 56.5514, R^2: 0.2923\n",
      "Epoch [255/1500]\n",
      "Train Loss: 1617.2509\n",
      "Val Loss: 3709.9949, MAE: 3710.4946, NMAE: 56.4862, R^2: 0.2820\n",
      "Epoch [256/1500]\n",
      "Train Loss: 1590.3517\n",
      "Val Loss: 3648.6583, MAE: 3649.1582, NMAE: 55.5524, R^2: 0.3027\n",
      "Epoch [257/1500]\n",
      "Train Loss: 1597.1884\n",
      "Val Loss: 3693.2526, MAE: 3693.7524, NMAE: 56.2313, R^2: 0.2900\n",
      "Epoch [258/1500]\n",
      "Train Loss: 1570.5674\n",
      "Val Loss: 3772.2811, MAE: 3772.7810, NMAE: 57.4344, R^2: 0.2831\n",
      "Epoch [259/1500]\n",
      "Train Loss: 1548.9484\n",
      "Val Loss: 3704.0698, MAE: 3704.5696, NMAE: 56.3960, R^2: 0.3054\n",
      "Epoch [260/1500]\n",
      "Train Loss: 1570.0607\n",
      "Val Loss: 3772.2831, MAE: 3772.7830, NMAE: 57.4344, R^2: 0.2860\n",
      "Epoch [261/1500]\n",
      "Train Loss: 1559.1555\n",
      "Val Loss: 3741.1945, MAE: 3741.6943, NMAE: 56.9611, R^2: 0.2934\n",
      "Epoch [262/1500]\n",
      "Train Loss: 1553.3699\n",
      "Val Loss: 3751.6289, MAE: 3752.1287, NMAE: 57.1200, R^2: 0.2886\n",
      "Epoch [263/1500]\n",
      "Train Loss: 1596.5539\n",
      "Val Loss: 3820.4436, MAE: 3820.9434, NMAE: 58.1676, R^2: 0.2819\n",
      "Epoch [264/1500]\n",
      "Train Loss: 1557.5117\n",
      "Val Loss: 3726.9757, MAE: 3727.4756, NMAE: 56.7447, R^2: 0.2869\n",
      "Epoch [265/1500]\n",
      "Train Loss: 1576.4470\n",
      "Val Loss: 3710.7949, MAE: 3711.2947, NMAE: 56.4983, R^2: 0.2855\n",
      "Epoch [266/1500]\n",
      "Train Loss: 1577.9721\n",
      "Val Loss: 3690.0815, MAE: 3690.5813, NMAE: 56.1830, R^2: 0.2973\n",
      "Epoch [267/1500]\n",
      "Train Loss: 1580.4603\n",
      "Val Loss: 3780.0887, MAE: 3780.5886, NMAE: 57.5532, R^2: 0.2649\n",
      "Epoch [268/1500]\n",
      "Train Loss: 1621.2150\n",
      "Val Loss: 3659.6285, MAE: 3660.1284, NMAE: 55.7194, R^2: 0.3102\n",
      "Epoch [269/1500]\n",
      "Train Loss: 1601.2413\n",
      "Val Loss: 3719.3191, MAE: 3719.8188, NMAE: 56.6281, R^2: 0.2846\n",
      "Epoch [270/1500]\n",
      "Train Loss: 1613.5789\n",
      "Val Loss: 3694.5543, MAE: 3695.0540, NMAE: 56.2511, R^2: 0.2933\n",
      "Epoch [271/1500]\n",
      "Train Loss: 1604.4233\n",
      "Val Loss: 3676.1348, MAE: 3676.6348, NMAE: 55.9707, R^2: 0.2954\n",
      "Epoch [272/1500]\n",
      "Train Loss: 1593.4018\n",
      "Val Loss: 3647.9183, MAE: 3648.4180, NMAE: 55.5412, R^2: 0.3082\n",
      "Epoch [273/1500]\n",
      "Train Loss: 1587.8887\n",
      "Val Loss: 3650.1833, MAE: 3650.6831, NMAE: 55.5756, R^2: 0.3070\n",
      "Epoch [274/1500]\n",
      "Train Loss: 1579.9668\n",
      "Val Loss: 3642.5318, MAE: 3643.0315, NMAE: 55.4592, R^2: 0.3166\n",
      "Epoch [275/1500]\n",
      "Train Loss: 1595.0435\n",
      "Val Loss: 3656.3411, MAE: 3656.8408, NMAE: 55.6694, R^2: 0.3128\n",
      "Epoch [276/1500]\n",
      "Train Loss: 1572.8267\n",
      "Val Loss: 3684.6693, MAE: 3685.1692, NMAE: 56.1006, R^2: 0.2975\n",
      "Epoch [277/1500]\n",
      "Train Loss: 1613.9860\n",
      "Val Loss: 3690.4258, MAE: 3690.9258, NMAE: 56.1883, R^2: 0.3128\n",
      "Epoch [278/1500]\n",
      "Train Loss: 1616.7865\n",
      "Val Loss: 3609.0806, MAE: 3609.5803, NMAE: 54.9499, R^2: 0.3192\n",
      "Epoch [279/1500]\n",
      "Train Loss: 1607.0729\n",
      "Val Loss: 3640.1970, MAE: 3640.6968, NMAE: 55.4236, R^2: 0.3239\n",
      "Epoch [280/1500]\n",
      "Train Loss: 1609.8492\n",
      "Val Loss: 3676.0752, MAE: 3676.5750, NMAE: 55.9698, R^2: 0.3032\n",
      "Epoch [281/1500]\n",
      "Train Loss: 1677.6901\n",
      "Val Loss: 3641.2998, MAE: 3641.7996, NMAE: 55.4404, R^2: 0.3148\n",
      "Epoch [282/1500]\n",
      "Train Loss: 1646.2921\n",
      "Val Loss: 3672.4941, MAE: 3672.9941, NMAE: 55.9153, R^2: 0.3028\n",
      "Epoch [283/1500]\n",
      "Train Loss: 1598.9646\n",
      "Val Loss: 3605.9744, MAE: 3606.4744, NMAE: 54.9026, R^2: 0.3228\n",
      "Epoch [284/1500]\n",
      "Train Loss: 1579.9201\n",
      "Val Loss: 3666.3918, MAE: 3666.8918, NMAE: 55.8224, R^2: 0.2945\n",
      "Epoch [285/1500]\n",
      "Train Loss: 1607.7198\n",
      "Val Loss: 3670.7700, MAE: 3671.2698, NMAE: 55.8890, R^2: 0.3047\n",
      "Epoch [286/1500]\n",
      "Train Loss: 1626.7066\n",
      "Val Loss: 3697.5385, MAE: 3698.0383, NMAE: 56.2965, R^2: 0.3028\n",
      "Epoch [287/1500]\n",
      "Train Loss: 1580.0086\n",
      "Val Loss: 3693.2549, MAE: 3693.7546, NMAE: 56.2313, R^2: 0.2901\n",
      "Epoch [288/1500]\n",
      "Train Loss: 1561.2152\n",
      "Val Loss: 3641.3815, MAE: 3641.8816, NMAE: 55.4416, R^2: 0.3204\n",
      "Epoch [289/1500]\n",
      "Train Loss: 1607.4583\n",
      "Val Loss: 3752.5964, MAE: 3753.0964, NMAE: 57.1347, R^2: 0.2757\n",
      "Epoch [290/1500]\n",
      "Train Loss: 1635.0378\n",
      "Val Loss: 3745.7564, MAE: 3746.2563, NMAE: 57.0306, R^2: 0.2897\n",
      "Epoch [291/1500]\n",
      "Train Loss: 1644.8964\n",
      "Val Loss: 3659.9471, MAE: 3660.4468, NMAE: 55.7243, R^2: 0.3022\n",
      "Epoch [292/1500]\n",
      "Train Loss: 1627.7510\n",
      "Val Loss: 3738.8502, MAE: 3739.3499, NMAE: 56.9254, R^2: 0.2893\n",
      "Epoch [293/1500]\n",
      "Train Loss: 1655.3220\n",
      "Val Loss: 3734.3422, MAE: 3734.8418, NMAE: 56.8568, R^2: 0.2728\n",
      "Epoch [294/1500]\n",
      "Train Loss: 1661.6259\n",
      "Val Loss: 3700.9233, MAE: 3701.4231, NMAE: 56.3481, R^2: 0.2817\n",
      "Epoch [295/1500]\n",
      "Train Loss: 1619.3031\n",
      "Val Loss: 3681.7970, MAE: 3682.2969, NMAE: 56.0569, R^2: 0.2915\n",
      "Epoch [296/1500]\n",
      "Train Loss: 1605.1708\n",
      "Val Loss: 3663.2824, MAE: 3663.7822, NMAE: 55.7750, R^2: 0.2990\n",
      "Epoch [297/1500]\n",
      "Train Loss: 1613.2404\n",
      "Val Loss: 3713.2027, MAE: 3713.7026, NMAE: 56.5350, R^2: 0.2805\n",
      "Epoch [298/1500]\n",
      "Train Loss: 1614.6242\n",
      "Val Loss: 3737.5678, MAE: 3738.0676, NMAE: 56.9059, R^2: 0.2753\n",
      "Epoch [299/1500]\n",
      "Train Loss: 1651.5755\n",
      "Val Loss: 3668.1345, MAE: 3668.6345, NMAE: 55.8489, R^2: 0.3079\n",
      "Epoch [300/1500]\n",
      "Train Loss: 1619.9581\n",
      "Val Loss: 3709.3742, MAE: 3709.8738, NMAE: 56.4767, R^2: 0.2883\n",
      "Epoch [301/1500]\n",
      "Train Loss: 1566.4883\n",
      "Val Loss: 3704.3385, MAE: 3704.8381, NMAE: 56.4001, R^2: 0.2981\n",
      "Epoch [302/1500]\n",
      "Train Loss: 1559.8538\n",
      "Val Loss: 3702.7398, MAE: 3703.2395, NMAE: 56.3757, R^2: 0.2784\n",
      "Epoch [303/1500]\n",
      "Train Loss: 1659.8531\n",
      "Val Loss: 3677.4879, MAE: 3677.9880, NMAE: 55.9913, R^2: 0.2879\n",
      "Epoch [304/1500]\n",
      "Train Loss: 1622.3437\n",
      "Val Loss: 3708.9845, MAE: 3709.4844, NMAE: 56.4708, R^2: 0.2898\n",
      "Epoch [305/1500]\n",
      "Train Loss: 1629.9617\n",
      "Val Loss: 3700.3689, MAE: 3700.8684, NMAE: 56.3396, R^2: 0.2775\n",
      "Epoch [306/1500]\n",
      "Train Loss: 1613.1411\n",
      "Val Loss: 3692.2813, MAE: 3692.7812, NMAE: 56.2165, R^2: 0.2852\n",
      "Epoch [307/1500]\n",
      "Train Loss: 1633.6815\n",
      "Val Loss: 3701.0457, MAE: 3701.5454, NMAE: 56.3499, R^2: 0.2843\n",
      "Epoch [308/1500]\n",
      "Train Loss: 1641.4862\n",
      "Val Loss: 3743.4174, MAE: 3743.9172, NMAE: 56.9950, R^2: 0.2865\n",
      "Epoch [309/1500]\n",
      "Train Loss: 1683.6123\n",
      "Val Loss: 3658.5521, MAE: 3659.0520, NMAE: 55.7030, R^2: 0.3082\n",
      "Epoch [310/1500]\n",
      "Train Loss: 1631.5475\n",
      "Val Loss: 3729.5957, MAE: 3730.0957, NMAE: 56.7846, R^2: 0.2894\n",
      "Epoch [311/1500]\n",
      "Train Loss: 1660.8528\n",
      "Val Loss: 3704.9343, MAE: 3705.4343, NMAE: 56.4091, R^2: 0.2918\n",
      "Epoch [312/1500]\n",
      "Train Loss: 1662.0754\n",
      "Val Loss: 3669.6324, MAE: 3670.1321, NMAE: 55.8717, R^2: 0.2933\n",
      "Epoch [313/1500]\n",
      "Train Loss: 1640.9691\n",
      "Val Loss: 3740.4733, MAE: 3740.9731, NMAE: 56.9502, R^2: 0.2695\n",
      "Epoch [314/1500]\n",
      "Train Loss: 1623.0286\n",
      "Val Loss: 3785.7051, MAE: 3786.2051, NMAE: 57.6387, R^2: 0.2581\n",
      "Epoch [315/1500]\n",
      "Train Loss: 1629.8277\n",
      "Val Loss: 3637.8056, MAE: 3638.3052, NMAE: 55.3872, R^2: 0.3068\n",
      "Epoch [316/1500]\n",
      "Train Loss: 1643.1536\n",
      "Val Loss: 3686.0894, MAE: 3686.5891, NMAE: 56.1222, R^2: 0.3010\n",
      "Epoch [317/1500]\n",
      "Train Loss: 1656.4905\n",
      "Val Loss: 3654.6175, MAE: 3655.1174, NMAE: 55.6431, R^2: 0.3117\n",
      "Epoch [318/1500]\n",
      "Train Loss: 1698.0083\n",
      "Val Loss: 3653.1496, MAE: 3653.6494, NMAE: 55.6208, R^2: 0.3005\n",
      "Epoch [319/1500]\n",
      "Train Loss: 1653.7739\n",
      "Val Loss: 3620.8566, MAE: 3621.3564, NMAE: 55.1292, R^2: 0.3274\n",
      "Epoch [320/1500]\n",
      "Train Loss: 1683.5631\n",
      "Val Loss: 3671.3449, MAE: 3671.8445, NMAE: 55.8978, R^2: 0.3017\n",
      "Epoch [321/1500]\n",
      "Train Loss: 1723.1297\n",
      "Val Loss: 3759.5176, MAE: 3760.0176, NMAE: 57.2401, R^2: 0.2825\n",
      "Epoch [322/1500]\n",
      "Train Loss: 1648.0517\n",
      "Val Loss: 3686.8301, MAE: 3687.3301, NMAE: 56.1335, R^2: 0.3036\n",
      "Epoch [323/1500]\n",
      "Train Loss: 1648.6272\n",
      "Val Loss: 3739.0950, MAE: 3739.5950, NMAE: 56.9292, R^2: 0.2875\n",
      "Epoch [324/1500]\n",
      "Train Loss: 1625.7180\n",
      "Val Loss: 3701.0557, MAE: 3701.5557, NMAE: 56.3501, R^2: 0.2931\n",
      "Epoch [325/1500]\n",
      "Train Loss: 1681.5106\n",
      "Val Loss: 3771.1123, MAE: 3771.6123, NMAE: 57.4166, R^2: 0.2710\n",
      "Epoch [326/1500]\n",
      "Train Loss: 1667.2675\n",
      "Val Loss: 3662.8595, MAE: 3663.3596, NMAE: 55.7686, R^2: 0.2966\n",
      "Epoch [327/1500]\n",
      "Train Loss: 1642.9770\n",
      "Val Loss: 3677.8217, MAE: 3678.3215, NMAE: 55.9964, R^2: 0.3046\n",
      "Epoch [328/1500]\n",
      "Train Loss: 1602.5831\n",
      "Val Loss: 3734.4686, MAE: 3734.9685, NMAE: 56.8587, R^2: 0.2809\n",
      "Epoch [329/1500]\n",
      "Train Loss: 1625.4999\n",
      "Val Loss: 3652.2651, MAE: 3652.7651, NMAE: 55.6073, R^2: 0.3004\n",
      "Epoch [330/1500]\n",
      "Train Loss: 1693.1571\n",
      "Val Loss: 3733.0953, MAE: 3733.5952, NMAE: 56.8378, R^2: 0.2700\n",
      "Epoch [331/1500]\n",
      "Train Loss: 1701.0978\n",
      "Val Loss: 3754.7998, MAE: 3755.2996, NMAE: 57.1682, R^2: 0.2669\n",
      "Epoch [332/1500]\n",
      "Train Loss: 1682.1260\n",
      "Val Loss: 3701.9075, MAE: 3702.4075, NMAE: 56.3631, R^2: 0.2906\n",
      "Epoch [333/1500]\n",
      "Train Loss: 1737.5754\n",
      "Val Loss: 3781.6474, MAE: 3782.1475, NMAE: 57.5770, R^2: 0.2687\n",
      "Epoch [334/1500]\n",
      "Train Loss: 1770.2752\n",
      "Val Loss: 3670.6621, MAE: 3671.1619, NMAE: 55.8874, R^2: 0.2925\n",
      "Epoch [335/1500]\n",
      "Train Loss: 1743.0484\n",
      "Val Loss: 3753.9810, MAE: 3754.4810, NMAE: 57.1558, R^2: 0.2580\n",
      "Epoch [336/1500]\n",
      "Train Loss: 1726.8258\n",
      "Val Loss: 3693.9458, MAE: 3694.4458, NMAE: 56.2418, R^2: 0.2940\n",
      "Epoch [337/1500]\n",
      "Train Loss: 1691.0004\n",
      "Val Loss: 3705.3436, MAE: 3705.8433, NMAE: 56.4154, R^2: 0.3031\n",
      "Epoch [338/1500]\n",
      "Train Loss: 1641.4521\n",
      "Val Loss: 3666.4796, MAE: 3666.9792, NMAE: 55.8237, R^2: 0.2863\n",
      "Epoch [339/1500]\n",
      "Train Loss: 1681.4512\n",
      "Val Loss: 3645.6509, MAE: 3646.1509, NMAE: 55.5066, R^2: 0.3024\n",
      "Epoch [340/1500]\n",
      "Train Loss: 1739.7534\n",
      "Val Loss: 3706.7870, MAE: 3707.2871, NMAE: 56.4373, R^2: 0.3039\n",
      "Epoch [341/1500]\n",
      "Train Loss: 1725.0808\n",
      "Val Loss: 3678.3318, MAE: 3678.8315, NMAE: 56.0041, R^2: 0.3034\n",
      "Epoch [342/1500]\n",
      "Train Loss: 1698.5242\n",
      "Val Loss: 3734.1773, MAE: 3734.6770, NMAE: 56.8543, R^2: 0.2870\n",
      "Epoch [343/1500]\n",
      "Train Loss: 1731.2732\n",
      "Val Loss: 3713.6432, MAE: 3714.1431, NMAE: 56.5417, R^2: 0.2797\n",
      "Epoch [344/1500]\n",
      "Train Loss: 1768.4424\n",
      "Val Loss: 3654.3400, MAE: 3654.8398, NMAE: 55.6389, R^2: 0.3063\n",
      "Epoch [345/1500]\n",
      "Train Loss: 1791.0756\n",
      "Val Loss: 3686.6386, MAE: 3687.1384, NMAE: 56.1306, R^2: 0.3140\n",
      "Epoch [346/1500]\n",
      "Train Loss: 1739.9940\n",
      "Val Loss: 3721.6866, MAE: 3722.1868, NMAE: 56.6642, R^2: 0.3042\n",
      "Epoch [347/1500]\n",
      "Train Loss: 1716.8476\n",
      "Val Loss: 3673.8278, MAE: 3674.3276, NMAE: 55.9356, R^2: 0.3128\n",
      "Epoch [348/1500]\n",
      "Train Loss: 1748.1975\n",
      "Val Loss: 3717.6010, MAE: 3718.1006, NMAE: 56.6020, R^2: 0.3033\n",
      "Epoch [349/1500]\n",
      "Train Loss: 1762.7947\n",
      "Val Loss: 3696.8645, MAE: 3697.3643, NMAE: 56.2863, R^2: 0.3188\n",
      "Epoch [350/1500]\n",
      "Train Loss: 1776.0333\n",
      "Val Loss: 3679.7999, MAE: 3680.2996, NMAE: 56.0265, R^2: 0.3027\n",
      "Epoch [351/1500]\n",
      "Train Loss: 1771.9838\n",
      "Val Loss: 3678.3563, MAE: 3678.8562, NMAE: 56.0045, R^2: 0.3088\n",
      "Epoch [352/1500]\n",
      "Train Loss: 1682.3083\n",
      "Val Loss: 3694.6460, MAE: 3695.1455, NMAE: 56.2525, R^2: 0.3001\n",
      "Epoch [353/1500]\n",
      "Train Loss: 1692.0474\n",
      "Val Loss: 3638.6512, MAE: 3639.1511, NMAE: 55.4001, R^2: 0.3083\n",
      "Epoch [354/1500]\n",
      "Train Loss: 1737.2325\n",
      "Val Loss: 3704.2380, MAE: 3704.7378, NMAE: 56.3985, R^2: 0.3006\n",
      "Epoch [355/1500]\n",
      "Train Loss: 1752.2182\n",
      "Val Loss: 3676.5341, MAE: 3677.0339, NMAE: 55.9768, R^2: 0.2995\n",
      "Epoch [356/1500]\n",
      "Train Loss: 1715.4631\n",
      "Val Loss: 3710.9439, MAE: 3711.4438, NMAE: 56.5006, R^2: 0.2983\n",
      "Epoch [357/1500]\n",
      "Train Loss: 1746.1193\n",
      "Val Loss: 3706.2604, MAE: 3706.7603, NMAE: 56.4293, R^2: 0.2875\n",
      "Epoch [358/1500]\n",
      "Train Loss: 1743.7700\n",
      "Val Loss: 3807.9100, MAE: 3808.4097, NMAE: 57.9768, R^2: 0.2580\n",
      "Epoch [359/1500]\n",
      "Train Loss: 1735.3582\n",
      "Val Loss: 3703.0691, MAE: 3703.5688, NMAE: 56.3807, R^2: 0.2948\n",
      "Epoch [360/1500]\n",
      "Train Loss: 1702.5632\n",
      "Val Loss: 3746.9860, MAE: 3747.4861, NMAE: 57.0493, R^2: 0.2786\n",
      "Epoch [361/1500]\n",
      "Train Loss: 1710.9033\n",
      "Val Loss: 3686.8731, MAE: 3687.3726, NMAE: 56.1342, R^2: 0.3016\n",
      "Epoch [362/1500]\n",
      "Train Loss: 1703.9349\n",
      "Val Loss: 3796.7213, MAE: 3797.2212, NMAE: 57.8064, R^2: 0.2690\n",
      "Epoch [363/1500]\n",
      "Train Loss: 1693.8048\n",
      "Val Loss: 3626.1061, MAE: 3626.6060, NMAE: 55.2091, R^2: 0.3059\n",
      "Epoch [364/1500]\n",
      "Train Loss: 1694.9042\n",
      "Val Loss: 3618.4444, MAE: 3618.9441, NMAE: 55.0925, R^2: 0.3148\n",
      "Epoch [365/1500]\n",
      "Train Loss: 1783.8376\n",
      "Val Loss: 3617.9376, MAE: 3618.4377, NMAE: 55.0848, R^2: 0.3138\n",
      "Epoch [366/1500]\n",
      "Train Loss: 1731.2912\n",
      "Val Loss: 3648.8925, MAE: 3649.3923, NMAE: 55.5560, R^2: 0.3002\n",
      "Epoch [367/1500]\n",
      "Train Loss: 1782.9025\n",
      "Val Loss: 3702.1410, MAE: 3702.6409, NMAE: 56.3666, R^2: 0.2878\n",
      "Epoch [368/1500]\n",
      "Train Loss: 1810.8068\n",
      "Val Loss: 3706.5801, MAE: 3707.0798, NMAE: 56.4342, R^2: 0.2852\n",
      "Epoch [369/1500]\n",
      "Train Loss: 1802.2224\n",
      "Val Loss: 3655.5484, MAE: 3656.0483, NMAE: 55.6573, R^2: 0.3038\n",
      "Epoch [370/1500]\n",
      "Train Loss: 1738.7493\n",
      "Val Loss: 3684.0462, MAE: 3684.5461, NMAE: 56.0911, R^2: 0.2856\n",
      "Epoch [371/1500]\n",
      "Train Loss: 1845.8059\n",
      "Val Loss: 3675.1705, MAE: 3675.6702, NMAE: 55.9560, R^2: 0.3038\n",
      "Epoch [372/1500]\n",
      "Train Loss: 1850.6858\n",
      "Val Loss: 3616.6693, MAE: 3617.1689, NMAE: 55.0654, R^2: 0.3245\n",
      "Epoch [373/1500]\n",
      "Train Loss: 1856.4495\n",
      "Val Loss: 3665.4424, MAE: 3665.9424, NMAE: 55.8079, R^2: 0.3047\n",
      "Epoch [374/1500]\n",
      "Train Loss: 1873.9774\n",
      "Val Loss: 3616.6011, MAE: 3617.1008, NMAE: 55.0644, R^2: 0.3203\n",
      "Epoch [375/1500]\n",
      "Train Loss: 1837.0870\n",
      "Val Loss: 3648.9591, MAE: 3649.4587, NMAE: 55.5570, R^2: 0.3189\n",
      "Epoch [376/1500]\n",
      "Train Loss: 1888.8877\n",
      "Val Loss: 3659.6537, MAE: 3660.1538, NMAE: 55.7198, R^2: 0.2990\n",
      "Epoch [377/1500]\n",
      "Train Loss: 1890.5857\n",
      "Val Loss: 3655.8874, MAE: 3656.3872, NMAE: 55.6625, R^2: 0.3077\n",
      "Epoch [378/1500]\n",
      "Train Loss: 1877.1503\n",
      "Val Loss: 3667.9880, MAE: 3668.4878, NMAE: 55.8467, R^2: 0.2978\n",
      "Epoch [379/1500]\n",
      "Train Loss: 1896.4280\n",
      "Val Loss: 3571.4699, MAE: 3571.9697, NMAE: 54.3774, R^2: 0.3050\n",
      "Epoch [380/1500]\n",
      "Train Loss: 1908.6712\n",
      "Val Loss: 3618.9612, MAE: 3619.4609, NMAE: 55.1003, R^2: 0.3114\n",
      "Epoch [381/1500]\n",
      "Train Loss: 1931.9788\n",
      "Val Loss: 3605.0098, MAE: 3605.5098, NMAE: 54.8879, R^2: 0.3030\n",
      "Epoch [382/1500]\n",
      "Train Loss: 1897.4991\n",
      "Val Loss: 3627.3945, MAE: 3627.8943, NMAE: 55.2287, R^2: 0.3040\n",
      "Epoch [383/1500]\n",
      "Train Loss: 1875.6721\n",
      "Val Loss: 3667.2225, MAE: 3667.7224, NMAE: 55.8350, R^2: 0.3070\n",
      "Epoch [384/1500]\n",
      "Train Loss: 1840.3034\n",
      "Val Loss: 3663.7894, MAE: 3664.2893, NMAE: 55.7828, R^2: 0.3127\n",
      "Epoch [385/1500]\n",
      "Train Loss: 1867.9412\n",
      "Val Loss: 3719.8747, MAE: 3720.3745, NMAE: 56.6366, R^2: 0.2864\n",
      "Epoch [386/1500]\n",
      "Train Loss: 1921.8504\n",
      "Val Loss: 3733.5052, MAE: 3734.0051, NMAE: 56.8441, R^2: 0.2854\n",
      "Epoch [387/1500]\n",
      "Train Loss: 1890.5487\n",
      "Val Loss: 3722.0553, MAE: 3722.5552, NMAE: 56.6698, R^2: 0.2914\n",
      "Epoch [388/1500]\n",
      "Train Loss: 1858.1203\n",
      "Val Loss: 3706.2071, MAE: 3706.7070, NMAE: 56.4285, R^2: 0.2985\n",
      "Epoch [389/1500]\n",
      "Train Loss: 1823.8983\n",
      "Val Loss: 3654.0706, MAE: 3654.5706, NMAE: 55.6348, R^2: 0.3012\n",
      "Epoch [390/1500]\n",
      "Train Loss: 1887.4017\n",
      "Val Loss: 3708.8596, MAE: 3709.3594, NMAE: 56.4689, R^2: 0.2884\n",
      "Epoch [391/1500]\n",
      "Train Loss: 1895.5369\n",
      "Val Loss: 3721.1402, MAE: 3721.6399, NMAE: 56.6558, R^2: 0.2814\n",
      "Epoch [392/1500]\n",
      "Train Loss: 1871.4230\n",
      "Val Loss: 3656.2395, MAE: 3656.7393, NMAE: 55.6678, R^2: 0.3013\n",
      "Epoch [393/1500]\n",
      "Train Loss: 1860.0402\n",
      "Val Loss: 3668.2390, MAE: 3668.7388, NMAE: 55.8505, R^2: 0.2939\n",
      "Epoch [394/1500]\n",
      "Train Loss: 1901.0315\n",
      "Val Loss: 3673.5684, MAE: 3674.0681, NMAE: 55.9316, R^2: 0.3075\n",
      "Epoch [395/1500]\n",
      "Train Loss: 1844.3349\n",
      "Val Loss: 3680.8605, MAE: 3681.3604, NMAE: 56.0426, R^2: 0.2919\n",
      "Epoch [396/1500]\n",
      "Train Loss: 1861.0198\n",
      "Val Loss: 3660.7687, MAE: 3661.2686, NMAE: 55.7368, R^2: 0.3077\n",
      "Epoch [397/1500]\n",
      "Train Loss: 1877.0616\n",
      "Val Loss: 3622.7679, MAE: 3623.2676, NMAE: 55.1583, R^2: 0.3110\n",
      "Epoch [398/1500]\n",
      "Train Loss: 1854.0262\n",
      "Val Loss: 3675.0074, MAE: 3675.5073, NMAE: 55.9535, R^2: 0.2931\n",
      "Epoch [399/1500]\n",
      "Train Loss: 1842.9485\n",
      "Val Loss: 3700.9223, MAE: 3701.4221, NMAE: 56.3481, R^2: 0.2993\n",
      "Epoch [400/1500]\n",
      "Train Loss: 1894.9488\n",
      "Val Loss: 3706.8844, MAE: 3707.3840, NMAE: 56.4388, R^2: 0.2847\n",
      "Epoch [401/1500]\n",
      "Train Loss: 1866.1058\n",
      "Val Loss: 3714.8464, MAE: 3715.3459, NMAE: 56.5600, R^2: 0.2846\n",
      "Epoch [402/1500]\n",
      "Train Loss: 1871.4699\n",
      "Val Loss: 3714.9307, MAE: 3715.4309, NMAE: 56.5613, R^2: 0.2974\n",
      "Epoch [403/1500]\n",
      "Train Loss: 1895.1033\n",
      "Val Loss: 3731.3682, MAE: 3731.8682, NMAE: 56.8115, R^2: 0.2711\n",
      "Epoch [404/1500]\n",
      "Train Loss: 1933.7413\n",
      "Val Loss: 3701.5608, MAE: 3702.0608, NMAE: 56.3578, R^2: 0.2899\n",
      "Epoch [405/1500]\n",
      "Train Loss: 1939.2181\n",
      "Val Loss: 3657.7753, MAE: 3658.2751, NMAE: 55.6912, R^2: 0.2962\n",
      "Epoch [406/1500]\n",
      "Train Loss: 1918.7593\n",
      "Val Loss: 3727.6392, MAE: 3728.1392, NMAE: 56.7548, R^2: 0.2877\n",
      "Epoch [407/1500]\n",
      "Train Loss: 1929.0392\n",
      "Val Loss: 3660.0062, MAE: 3660.5061, NMAE: 55.7252, R^2: 0.3049\n",
      "Epoch [408/1500]\n",
      "Train Loss: 1903.4299\n",
      "Val Loss: 3630.4764, MAE: 3630.9763, NMAE: 55.2756, R^2: 0.3077\n",
      "Epoch [409/1500]\n",
      "Train Loss: 1897.6590\n",
      "Val Loss: 3687.3171, MAE: 3687.8169, NMAE: 56.1409, R^2: 0.3157\n",
      "Epoch [410/1500]\n",
      "Train Loss: 1893.5926\n",
      "Val Loss: 3630.1311, MAE: 3630.6309, NMAE: 55.2704, R^2: 0.3130\n",
      "Epoch [411/1500]\n",
      "Train Loss: 1862.7166\n",
      "Val Loss: 3670.1048, MAE: 3670.6047, NMAE: 55.8789, R^2: 0.3099\n",
      "Epoch [412/1500]\n",
      "Train Loss: 1918.4970\n",
      "Val Loss: 3690.7272, MAE: 3691.2271, NMAE: 56.1928, R^2: 0.2993\n",
      "Epoch [413/1500]\n",
      "Train Loss: 1920.2168\n",
      "Val Loss: 3661.4284, MAE: 3661.9282, NMAE: 55.7468, R^2: 0.3125\n",
      "Epoch [414/1500]\n",
      "Train Loss: 1915.5665\n",
      "Val Loss: 3690.8587, MAE: 3691.3586, NMAE: 56.1949, R^2: 0.2931\n",
      "Epoch [415/1500]\n",
      "Train Loss: 1976.4176\n",
      "Val Loss: 3682.6169, MAE: 3683.1167, NMAE: 56.0694, R^2: 0.2842\n",
      "Epoch [416/1500]\n",
      "Train Loss: 2025.5882\n",
      "Val Loss: 3662.2674, MAE: 3662.7673, NMAE: 55.7596, R^2: 0.2977\n",
      "Epoch [417/1500]\n",
      "Train Loss: 1976.1300\n",
      "Val Loss: 3594.2793, MAE: 3594.7793, NMAE: 54.7246, R^2: 0.3135\n",
      "Epoch [418/1500]\n",
      "Train Loss: 1950.7460\n",
      "Val Loss: 3573.8482, MAE: 3574.3479, NMAE: 54.4136, R^2: 0.3243\n",
      "Epoch [419/1500]\n",
      "Train Loss: 2008.6117\n",
      "Val Loss: 3603.5683, MAE: 3604.0681, NMAE: 54.8660, R^2: 0.3141\n",
      "Epoch [420/1500]\n",
      "Train Loss: 1950.0500\n",
      "Val Loss: 3641.6413, MAE: 3642.1411, NMAE: 55.4456, R^2: 0.2881\n",
      "Epoch [421/1500]\n",
      "Train Loss: 1950.6911\n",
      "Val Loss: 3601.9996, MAE: 3602.4995, NMAE: 54.8421, R^2: 0.3030\n",
      "Epoch [422/1500]\n",
      "Train Loss: 1936.3717\n",
      "Val Loss: 3659.0841, MAE: 3659.5842, NMAE: 55.7111, R^2: 0.3082\n",
      "Epoch [423/1500]\n",
      "Train Loss: 1937.9552\n",
      "Val Loss: 3647.8186, MAE: 3648.3186, NMAE: 55.5396, R^2: 0.3159\n",
      "Epoch [424/1500]\n",
      "Train Loss: 1906.1730\n",
      "Val Loss: 3620.4537, MAE: 3620.9536, NMAE: 55.1231, R^2: 0.3165\n",
      "Epoch [425/1500]\n",
      "Train Loss: 1876.1675\n",
      "Val Loss: 3590.6581, MAE: 3591.1582, NMAE: 54.6695, R^2: 0.3362\n",
      "Epoch [426/1500]\n",
      "Train Loss: 1856.1404\n",
      "Val Loss: 3659.1374, MAE: 3659.6372, NMAE: 55.7119, R^2: 0.3024\n",
      "Epoch [427/1500]\n",
      "Train Loss: 1898.7175\n",
      "Val Loss: 3678.7022, MAE: 3679.2021, NMAE: 56.0098, R^2: 0.2869\n",
      "Epoch [428/1500]\n",
      "Train Loss: 1930.8551\n",
      "Val Loss: 3631.4928, MAE: 3631.9927, NMAE: 55.2911, R^2: 0.3080\n",
      "Epoch [429/1500]\n",
      "Train Loss: 1939.7764\n",
      "Val Loss: 3622.5113, MAE: 3623.0115, NMAE: 55.1544, R^2: 0.3073\n",
      "Epoch [430/1500]\n",
      "Train Loss: 1872.0689\n",
      "Val Loss: 3685.8263, MAE: 3686.3262, NMAE: 56.1182, R^2: 0.3027\n",
      "Epoch [431/1500]\n",
      "Train Loss: 2018.3968\n",
      "Val Loss: 3685.5688, MAE: 3686.0688, NMAE: 56.1143, R^2: 0.3015\n",
      "Epoch [432/1500]\n",
      "Train Loss: 2010.7814\n",
      "Val Loss: 3639.4759, MAE: 3639.9758, NMAE: 55.4126, R^2: 0.3264\n",
      "Epoch [433/1500]\n",
      "Train Loss: 2002.2994\n",
      "Val Loss: 3625.2790, MAE: 3625.7786, NMAE: 55.1965, R^2: 0.3193\n",
      "Epoch [434/1500]\n",
      "Train Loss: 1973.5682\n",
      "Val Loss: 3647.2089, MAE: 3647.7085, NMAE: 55.5304, R^2: 0.3100\n",
      "Epoch [435/1500]\n",
      "Train Loss: 2032.1113\n",
      "Val Loss: 3613.3627, MAE: 3613.8625, NMAE: 55.0151, R^2: 0.3155\n",
      "Epoch [436/1500]\n",
      "Train Loss: 2038.7305\n",
      "Val Loss: 3578.2163, MAE: 3578.7163, NMAE: 54.4801, R^2: 0.3324\n",
      "Epoch [437/1500]\n",
      "Train Loss: 2026.6118\n",
      "Val Loss: 3591.1486, MAE: 3591.6484, NMAE: 54.6769, R^2: 0.3251\n",
      "Epoch [438/1500]\n",
      "Train Loss: 2055.0760\n",
      "Val Loss: 3636.2457, MAE: 3636.7456, NMAE: 55.3635, R^2: 0.3129\n",
      "Epoch [439/1500]\n",
      "Train Loss: 2058.7916\n",
      "Val Loss: 3565.2842, MAE: 3565.7842, NMAE: 54.2832, R^2: 0.3301\n",
      "Epoch [440/1500]\n",
      "Train Loss: 2019.1292\n",
      "Val Loss: 3610.4667, MAE: 3610.9666, NMAE: 54.9710, R^2: 0.3090\n",
      "Epoch [441/1500]\n",
      "Train Loss: 2009.9557\n",
      "Val Loss: 3564.4671, MAE: 3564.9668, NMAE: 54.2707, R^2: 0.3290\n",
      "Epoch [442/1500]\n",
      "Train Loss: 1974.5911\n",
      "Val Loss: 3599.8067, MAE: 3600.3064, NMAE: 54.8087, R^2: 0.3286\n",
      "Epoch [443/1500]\n",
      "Train Loss: 2008.8327\n",
      "Val Loss: 3581.2439, MAE: 3581.7439, NMAE: 54.5261, R^2: 0.3308\n",
      "Epoch [444/1500]\n",
      "Train Loss: 1966.5220\n",
      "Val Loss: 3575.6210, MAE: 3576.1208, NMAE: 54.4405, R^2: 0.3386\n",
      "Epoch [445/1500]\n",
      "Train Loss: 2027.2390\n",
      "Val Loss: 3582.1291, MAE: 3582.6289, NMAE: 54.5396, R^2: 0.3260\n",
      "Epoch [446/1500]\n",
      "Train Loss: 2033.6786\n",
      "Val Loss: 3698.1582, MAE: 3698.6580, NMAE: 56.3060, R^2: 0.2933\n",
      "Epoch [447/1500]\n",
      "Train Loss: 2036.9074\n",
      "Val Loss: 3659.4782, MAE: 3659.9783, NMAE: 55.7171, R^2: 0.2992\n",
      "Epoch [448/1500]\n",
      "Train Loss: 2061.1286\n",
      "Val Loss: 3649.9566, MAE: 3650.4565, NMAE: 55.5722, R^2: 0.3203\n",
      "Epoch [449/1500]\n",
      "Train Loss: 2063.5667\n",
      "Val Loss: 3695.1907, MAE: 3695.6904, NMAE: 56.2608, R^2: 0.3058\n",
      "Epoch [450/1500]\n",
      "Train Loss: 2011.5422\n",
      "Val Loss: 3681.0257, MAE: 3681.5256, NMAE: 56.0452, R^2: 0.2773\n",
      "Epoch [451/1500]\n",
      "Train Loss: 2067.7909\n",
      "Val Loss: 3634.0546, MAE: 3634.5544, NMAE: 55.3301, R^2: 0.3122\n",
      "Epoch [452/1500]\n",
      "Train Loss: 1973.4727\n",
      "Val Loss: 3640.9260, MAE: 3641.4260, NMAE: 55.4347, R^2: 0.3016\n",
      "Epoch [453/1500]\n",
      "Train Loss: 1969.3326\n",
      "Val Loss: 3644.0939, MAE: 3644.5938, NMAE: 55.4829, R^2: 0.2987\n",
      "Epoch [454/1500]\n",
      "Train Loss: 1950.9200\n",
      "Val Loss: 3712.7364, MAE: 3713.2363, NMAE: 56.5279, R^2: 0.2798\n",
      "Epoch [455/1500]\n",
      "Train Loss: 1963.4690\n",
      "Val Loss: 3702.8731, MAE: 3703.3728, NMAE: 56.3777, R^2: 0.2736\n",
      "Epoch [456/1500]\n",
      "Train Loss: 1970.1113\n",
      "Val Loss: 3689.3953, MAE: 3689.8950, NMAE: 56.1726, R^2: 0.2760\n",
      "Epoch [457/1500]\n",
      "Train Loss: 1956.5984\n",
      "Val Loss: 3684.4222, MAE: 3684.9221, NMAE: 56.0969, R^2: 0.2797\n",
      "Epoch [458/1500]\n",
      "Train Loss: 1987.9013\n",
      "Val Loss: 3713.4209, MAE: 3713.9204, NMAE: 56.5383, R^2: 0.2730\n",
      "Epoch [459/1500]\n",
      "Train Loss: 1983.5277\n",
      "Val Loss: 3653.7785, MAE: 3654.2783, NMAE: 55.6304, R^2: 0.2872\n",
      "Epoch [460/1500]\n",
      "Train Loss: 1980.3111\n",
      "Val Loss: 3724.8462, MAE: 3725.3462, NMAE: 56.7123, R^2: 0.2778\n",
      "Epoch [461/1500]\n",
      "Train Loss: 2039.9431\n",
      "Val Loss: 3676.4074, MAE: 3676.9075, NMAE: 55.9749, R^2: 0.2909\n",
      "Epoch [462/1500]\n",
      "Train Loss: 2154.8608\n",
      "Val Loss: 3680.9072, MAE: 3681.4072, NMAE: 56.0434, R^2: 0.2984\n",
      "Epoch [463/1500]\n",
      "Train Loss: 2141.8305\n",
      "Val Loss: 3741.9562, MAE: 3742.4561, NMAE: 56.9727, R^2: 0.2908\n",
      "Epoch [464/1500]\n",
      "Train Loss: 2076.2980\n",
      "Val Loss: 3761.6965, MAE: 3762.1963, NMAE: 57.2732, R^2: 0.2775\n",
      "Epoch [465/1500]\n",
      "Train Loss: 2065.9020\n",
      "Val Loss: 3670.8035, MAE: 3671.3032, NMAE: 55.8895, R^2: 0.2870\n",
      "Epoch [466/1500]\n",
      "Train Loss: 2051.5718\n",
      "Val Loss: 3696.4143, MAE: 3696.9141, NMAE: 56.2794, R^2: 0.2906\n",
      "Epoch [467/1500]\n",
      "Train Loss: 2029.9497\n",
      "Val Loss: 3698.6518, MAE: 3699.1516, NMAE: 56.3135, R^2: 0.2851\n",
      "Epoch [468/1500]\n",
      "Train Loss: 2022.2113\n",
      "Val Loss: 3768.8210, MAE: 3769.3208, NMAE: 57.3817, R^2: 0.2765\n",
      "Epoch [469/1500]\n",
      "Train Loss: 2038.0928\n",
      "Val Loss: 3759.5447, MAE: 3760.0447, NMAE: 57.2405, R^2: 0.2916\n",
      "Epoch [470/1500]\n",
      "Train Loss: 2051.2425\n",
      "Val Loss: 3736.9093, MAE: 3737.4092, NMAE: 56.8959, R^2: 0.2789\n",
      "Epoch [471/1500]\n",
      "Train Loss: 2043.2484\n",
      "Val Loss: 3738.0575, MAE: 3738.5571, NMAE: 56.9134, R^2: 0.2802\n",
      "Epoch [472/1500]\n",
      "Train Loss: 2086.6317\n",
      "Val Loss: 3773.7034, MAE: 3774.2031, NMAE: 57.4560, R^2: 0.2702\n",
      "Epoch [473/1500]\n",
      "Train Loss: 2108.0650\n",
      "Val Loss: 3751.1615, MAE: 3751.6611, NMAE: 57.1129, R^2: 0.2886\n",
      "Epoch [474/1500]\n",
      "Train Loss: 2127.1173\n",
      "Val Loss: 3644.4208, MAE: 3644.9204, NMAE: 55.4879, R^2: 0.2978\n",
      "Epoch [475/1500]\n",
      "Train Loss: 2049.2023\n",
      "Val Loss: 3610.8033, MAE: 3611.3032, NMAE: 54.9761, R^2: 0.3278\n",
      "Epoch [476/1500]\n",
      "Train Loss: 2055.0310\n",
      "Val Loss: 3651.1960, MAE: 3651.6958, NMAE: 55.5911, R^2: 0.3150\n",
      "Epoch [477/1500]\n",
      "Train Loss: 2065.7920\n",
      "Val Loss: 3660.2267, MAE: 3660.7263, NMAE: 55.7285, R^2: 0.3130\n",
      "Epoch [478/1500]\n",
      "Train Loss: 2047.3515\n",
      "Val Loss: 3807.0793, MAE: 3807.5791, NMAE: 57.9641, R^2: 0.2493\n",
      "Epoch [479/1500]\n",
      "Train Loss: 2114.2975\n",
      "Val Loss: 3824.2707, MAE: 3824.7705, NMAE: 58.2258, R^2: 0.2431\n",
      "Epoch [480/1500]\n",
      "Train Loss: 2185.6496\n",
      "Val Loss: 3859.9281, MAE: 3860.4280, NMAE: 58.7687, R^2: 0.2370\n",
      "Epoch [481/1500]\n",
      "Train Loss: 2260.9145\n",
      "Val Loss: 3691.5888, MAE: 3692.0884, NMAE: 56.2060, R^2: 0.2821\n",
      "Epoch [482/1500]\n",
      "Train Loss: 2177.2310\n",
      "Val Loss: 3705.4073, MAE: 3705.9072, NMAE: 56.4163, R^2: 0.2902\n",
      "Epoch [483/1500]\n",
      "Train Loss: 2203.1766\n",
      "Val Loss: 3660.8135, MAE: 3661.3132, NMAE: 55.7375, R^2: 0.3024\n",
      "Epoch [484/1500]\n",
      "Train Loss: 2217.1977\n",
      "Val Loss: 3607.6585, MAE: 3608.1584, NMAE: 54.9283, R^2: 0.3070\n",
      "Epoch [485/1500]\n",
      "Train Loss: 2173.3858\n",
      "Val Loss: 3626.2551, MAE: 3626.7549, NMAE: 55.2114, R^2: 0.3064\n",
      "Epoch [486/1500]\n",
      "Train Loss: 2183.3380\n",
      "Val Loss: 3570.5395, MAE: 3571.0393, NMAE: 54.3632, R^2: 0.3207\n",
      "Epoch [487/1500]\n",
      "Train Loss: 2203.9888\n",
      "Val Loss: 3586.1442, MAE: 3586.6438, NMAE: 54.6007, R^2: 0.3171\n",
      "Epoch [488/1500]\n",
      "Train Loss: 2186.9086\n",
      "Val Loss: 3588.8663, MAE: 3589.3660, NMAE: 54.6422, R^2: 0.3209\n",
      "Epoch [489/1500]\n",
      "Train Loss: 2218.8461\n",
      "Val Loss: 3589.7440, MAE: 3590.2437, NMAE: 54.6555, R^2: 0.3121\n",
      "Epoch [490/1500]\n",
      "Train Loss: 2121.6088\n",
      "Val Loss: 3605.2927, MAE: 3605.7925, NMAE: 54.8922, R^2: 0.3001\n",
      "Epoch [491/1500]\n",
      "Train Loss: 2158.1687\n",
      "Val Loss: 3623.0436, MAE: 3623.5437, NMAE: 55.1625, R^2: 0.3102\n",
      "Epoch [492/1500]\n",
      "Train Loss: 2141.2291\n",
      "Val Loss: 3638.0037, MAE: 3638.5034, NMAE: 55.3902, R^2: 0.2984\n",
      "Epoch [493/1500]\n",
      "Train Loss: 2191.4791\n",
      "Val Loss: 3618.9763, MAE: 3619.4763, NMAE: 55.1006, R^2: 0.3160\n",
      "Epoch [494/1500]\n",
      "Train Loss: 2210.9539\n",
      "Val Loss: 3589.1814, MAE: 3589.6814, NMAE: 54.6470, R^2: 0.3142\n",
      "Epoch [495/1500]\n",
      "Train Loss: 2242.9408\n",
      "Val Loss: 3637.9537, MAE: 3638.4539, NMAE: 55.3895, R^2: 0.3033\n",
      "Epoch [496/1500]\n",
      "Train Loss: 2255.4831\n",
      "Val Loss: 3592.7826, MAE: 3593.2822, NMAE: 54.7018, R^2: 0.3241\n",
      "Epoch [497/1500]\n",
      "Train Loss: 2293.2570\n",
      "Val Loss: 3575.6841, MAE: 3576.1841, NMAE: 54.4415, R^2: 0.3356\n",
      "Epoch [498/1500]\n",
      "Train Loss: 2245.0289\n",
      "Val Loss: 3668.2438, MAE: 3668.7434, NMAE: 55.8506, R^2: 0.3038\n",
      "Epoch [499/1500]\n",
      "Train Loss: 2278.8713\n",
      "Val Loss: 3680.0786, MAE: 3680.5786, NMAE: 56.0307, R^2: 0.3114\n",
      "Epoch [500/1500]\n",
      "Train Loss: 2248.7568\n",
      "Val Loss: 3590.2816, MAE: 3590.7815, NMAE: 54.6637, R^2: 0.3240\n",
      "Epoch [501/1500]\n",
      "Train Loss: 2201.9789\n",
      "Val Loss: 3633.4769, MAE: 3633.9768, NMAE: 55.3213, R^2: 0.3098\n",
      "Epoch [502/1500]\n",
      "Train Loss: 2217.9692\n",
      "Val Loss: 3624.6907, MAE: 3625.1904, NMAE: 55.1876, R^2: 0.3027\n",
      "Epoch [503/1500]\n",
      "Train Loss: 2265.7709\n",
      "Val Loss: 3605.3294, MAE: 3605.8291, NMAE: 54.8928, R^2: 0.3289\n",
      "Epoch [504/1500]\n",
      "Train Loss: 2264.3055\n",
      "Val Loss: 3618.9289, MAE: 3619.4287, NMAE: 55.0998, R^2: 0.3063\n",
      "Epoch [505/1500]\n",
      "Train Loss: 2273.0339\n",
      "Val Loss: 3689.1683, MAE: 3689.6682, NMAE: 56.1691, R^2: 0.2953\n",
      "Epoch [506/1500]\n",
      "Train Loss: 2214.9201\n",
      "Val Loss: 3700.0089, MAE: 3700.5088, NMAE: 56.3341, R^2: 0.2777\n",
      "Epoch [507/1500]\n",
      "Train Loss: 2249.1439\n",
      "Val Loss: 3623.7946, MAE: 3624.2942, NMAE: 55.1739, R^2: 0.3021\n",
      "Epoch [508/1500]\n",
      "Train Loss: 2251.7592\n",
      "Val Loss: 3675.1082, MAE: 3675.6082, NMAE: 55.9551, R^2: 0.2899\n",
      "Epoch [509/1500]\n",
      "Train Loss: 2224.4328\n",
      "Val Loss: 3657.5506, MAE: 3658.0505, NMAE: 55.6878, R^2: 0.2863\n",
      "Epoch [510/1500]\n",
      "Train Loss: 2231.0987\n",
      "Val Loss: 3654.7198, MAE: 3655.2197, NMAE: 55.6447, R^2: 0.2978\n",
      "Epoch [511/1500]\n",
      "Train Loss: 2162.2882\n",
      "Val Loss: 3632.2162, MAE: 3632.7158, NMAE: 55.3021, R^2: 0.3040\n",
      "Epoch [512/1500]\n",
      "Train Loss: 2190.1939\n",
      "Val Loss: 3618.8444, MAE: 3619.3445, NMAE: 55.0986, R^2: 0.3070\n",
      "Epoch [513/1500]\n",
      "Train Loss: 2192.1814\n",
      "Val Loss: 3675.6770, MAE: 3676.1770, NMAE: 55.9637, R^2: 0.3070\n",
      "Epoch [514/1500]\n",
      "Train Loss: 2210.7411\n",
      "Val Loss: 3660.4913, MAE: 3660.9910, NMAE: 55.7326, R^2: 0.2971\n",
      "Epoch [515/1500]\n",
      "Train Loss: 2210.7584\n",
      "Val Loss: 3688.3897, MAE: 3688.8896, NMAE: 56.1573, R^2: 0.2846\n",
      "Epoch [516/1500]\n",
      "Train Loss: 2281.8402\n",
      "Val Loss: 3716.4751, MAE: 3716.9749, NMAE: 56.5848, R^2: 0.2779\n",
      "Epoch [517/1500]\n",
      "Train Loss: 2240.6828\n",
      "Val Loss: 3703.2304, MAE: 3703.7302, NMAE: 56.3832, R^2: 0.2886\n",
      "Epoch [518/1500]\n",
      "Train Loss: 2249.8563\n",
      "Val Loss: 3687.3864, MAE: 3687.8862, NMAE: 56.1420, R^2: 0.2667\n",
      "Epoch [519/1500]\n",
      "Train Loss: 2287.2936\n",
      "Val Loss: 3660.9752, MAE: 3661.4751, NMAE: 55.7399, R^2: 0.2936\n",
      "Epoch [520/1500]\n",
      "Train Loss: 2347.8237\n",
      "Val Loss: 3675.0557, MAE: 3675.5557, NMAE: 55.9543, R^2: 0.2940\n",
      "Epoch [521/1500]\n",
      "Train Loss: 2247.1774\n",
      "Val Loss: 3609.6667, MAE: 3610.1665, NMAE: 54.9588, R^2: 0.3043\n",
      "Epoch [522/1500]\n",
      "Train Loss: 2225.3565\n",
      "Val Loss: 3632.9951, MAE: 3633.4949, NMAE: 55.3140, R^2: 0.3054\n",
      "Epoch [523/1500]\n",
      "Train Loss: 2281.8986\n",
      "Val Loss: 3644.7342, MAE: 3645.2341, NMAE: 55.4927, R^2: 0.2975\n",
      "Epoch [524/1500]\n",
      "Train Loss: 2266.4757\n",
      "Val Loss: 3660.5761, MAE: 3661.0759, NMAE: 55.7338, R^2: 0.3015\n",
      "Epoch [525/1500]\n",
      "Train Loss: 2212.4149\n",
      "Val Loss: 3686.3266, MAE: 3686.8267, NMAE: 56.1259, R^2: 0.3021\n",
      "Epoch [526/1500]\n",
      "Train Loss: 2205.2996\n",
      "Val Loss: 3683.2976, MAE: 3683.7974, NMAE: 56.0797, R^2: 0.2827\n",
      "Epoch [527/1500]\n",
      "Train Loss: 2184.6978\n",
      "Val Loss: 3662.3929, MAE: 3662.8928, NMAE: 55.7615, R^2: 0.2925\n",
      "Epoch [528/1500]\n",
      "Train Loss: 2249.5280\n",
      "Val Loss: 3624.2889, MAE: 3624.7891, NMAE: 55.1814, R^2: 0.3143\n",
      "Epoch [529/1500]\n",
      "Train Loss: 2255.6886\n",
      "Val Loss: 3711.1463, MAE: 3711.6462, NMAE: 56.5037, R^2: 0.2855\n",
      "Epoch [530/1500]\n",
      "Train Loss: 2213.9121\n",
      "Val Loss: 3713.3448, MAE: 3713.8447, NMAE: 56.5372, R^2: 0.2912\n",
      "Epoch [531/1500]\n",
      "Train Loss: 2197.2621\n",
      "Val Loss: 3735.3017, MAE: 3735.8013, NMAE: 56.8714, R^2: 0.2877\n",
      "Epoch [532/1500]\n",
      "Train Loss: 2209.2636\n",
      "Val Loss: 3686.7467, MAE: 3687.2466, NMAE: 56.1323, R^2: 0.3004\n",
      "Epoch [533/1500]\n",
      "Train Loss: 2211.5415\n",
      "Val Loss: 3750.8885, MAE: 3751.3884, NMAE: 57.1087, R^2: 0.2864\n",
      "Epoch [534/1500]\n",
      "Train Loss: 2237.2328\n",
      "Val Loss: 3750.3848, MAE: 3750.8848, NMAE: 57.1010, R^2: 0.2752\n",
      "Epoch [535/1500]\n",
      "Train Loss: 2268.9406\n",
      "Val Loss: 3727.5355, MAE: 3728.0356, NMAE: 56.7532, R^2: 0.2909\n",
      "Epoch [536/1500]\n",
      "Train Loss: 2280.4016\n",
      "Val Loss: 3782.5420, MAE: 3783.0420, NMAE: 57.5906, R^2: 0.2651\n",
      "Epoch [537/1500]\n",
      "Train Loss: 2287.0875\n",
      "Val Loss: 3735.1770, MAE: 3735.6770, NMAE: 56.8695, R^2: 0.2707\n",
      "Epoch [538/1500]\n",
      "Train Loss: 2268.9232\n",
      "Val Loss: 3730.6390, MAE: 3731.1392, NMAE: 56.8004, R^2: 0.2811\n",
      "Epoch [539/1500]\n",
      "Train Loss: 2264.4715\n",
      "Val Loss: 3802.2208, MAE: 3802.7207, NMAE: 57.8902, R^2: 0.2796\n",
      "Epoch [540/1500]\n",
      "Train Loss: 2316.0697\n",
      "Val Loss: 3807.8444, MAE: 3808.3442, NMAE: 57.9758, R^2: 0.2736\n",
      "Epoch [541/1500]\n",
      "Train Loss: 2364.5339\n",
      "Val Loss: 3862.1563, MAE: 3862.6560, NMAE: 58.8026, R^2: 0.2576\n",
      "Epoch [542/1500]\n",
      "Train Loss: 2257.0283\n",
      "Val Loss: 3724.0036, MAE: 3724.5034, NMAE: 56.6994, R^2: 0.2819\n",
      "Epoch [543/1500]\n",
      "Train Loss: 2274.9623\n",
      "Val Loss: 3729.5121, MAE: 3730.0120, NMAE: 56.7833, R^2: 0.2711\n",
      "Epoch [544/1500]\n",
      "Train Loss: 2287.7823\n",
      "Val Loss: 3687.0449, MAE: 3687.5447, NMAE: 56.1368, R^2: 0.2882\n",
      "Epoch [545/1500]\n",
      "Train Loss: 2322.3038\n",
      "Val Loss: 3753.9595, MAE: 3754.4592, NMAE: 57.1555, R^2: 0.2653\n",
      "Epoch [546/1500]\n",
      "Train Loss: 2323.3212\n",
      "Val Loss: 3754.3938, MAE: 3754.8938, NMAE: 57.1621, R^2: 0.2744\n",
      "Epoch [547/1500]\n",
      "Train Loss: 2275.3022\n",
      "Val Loss: 3706.2591, MAE: 3706.7590, NMAE: 56.4293, R^2: 0.2814\n",
      "Epoch [548/1500]\n",
      "Train Loss: 2240.9733\n",
      "Val Loss: 3649.3521, MAE: 3649.8521, NMAE: 55.5630, R^2: 0.3142\n",
      "Epoch [549/1500]\n",
      "Train Loss: 2245.3982\n",
      "Val Loss: 3663.1340, MAE: 3663.6338, NMAE: 55.7728, R^2: 0.3095\n",
      "Epoch [550/1500]\n",
      "Train Loss: 2346.2360\n",
      "Val Loss: 3702.4780, MAE: 3702.9780, NMAE: 56.3717, R^2: 0.3003\n",
      "Epoch [551/1500]\n",
      "Train Loss: 2217.4800\n",
      "Val Loss: 3781.5499, MAE: 3782.0493, NMAE: 57.5755, R^2: 0.2636\n",
      "Epoch [552/1500]\n",
      "Train Loss: 2237.9546\n",
      "Val Loss: 3717.7983, MAE: 3718.2981, NMAE: 56.6050, R^2: 0.2778\n",
      "Epoch [553/1500]\n",
      "Train Loss: 2174.3588\n",
      "Val Loss: 3741.2601, MAE: 3741.7600, NMAE: 56.9621, R^2: 0.2635\n",
      "Epoch [554/1500]\n",
      "Train Loss: 2269.9949\n",
      "Val Loss: 3682.0590, MAE: 3682.5588, NMAE: 56.0609, R^2: 0.2764\n",
      "Epoch [555/1500]\n",
      "Train Loss: 2199.6334\n",
      "Val Loss: 3672.7052, MAE: 3673.2051, NMAE: 55.9185, R^2: 0.2990\n",
      "Epoch [556/1500]\n",
      "Train Loss: 2245.2445\n",
      "Val Loss: 3653.5440, MAE: 3654.0437, NMAE: 55.6268, R^2: 0.2884\n",
      "Epoch [557/1500]\n",
      "Train Loss: 2240.0197\n",
      "Val Loss: 3646.7023, MAE: 3647.2019, NMAE: 55.5226, R^2: 0.2864\n",
      "Epoch [558/1500]\n",
      "Train Loss: 2268.5142\n",
      "Val Loss: 3658.9638, MAE: 3659.4634, NMAE: 55.7093, R^2: 0.2754\n",
      "Epoch [559/1500]\n",
      "Train Loss: 2278.1740\n",
      "Val Loss: 3690.2573, MAE: 3690.7573, NMAE: 56.1857, R^2: 0.2989\n",
      "Epoch [560/1500]\n",
      "Train Loss: 2257.8401\n",
      "Val Loss: 3716.2625, MAE: 3716.7622, NMAE: 56.5816, R^2: 0.2648\n",
      "Epoch [561/1500]\n",
      "Train Loss: 2224.8852\n",
      "Val Loss: 3675.7822, MAE: 3676.2822, NMAE: 55.9653, R^2: 0.2878\n",
      "Epoch [562/1500]\n",
      "Train Loss: 2230.0734\n",
      "Val Loss: 3686.9756, MAE: 3687.4753, NMAE: 56.1357, R^2: 0.2789\n",
      "Epoch [563/1500]\n",
      "Train Loss: 2247.5484\n",
      "Val Loss: 3661.9772, MAE: 3662.4771, NMAE: 55.7552, R^2: 0.2939\n",
      "Epoch [564/1500]\n",
      "Train Loss: 2235.2836\n",
      "Val Loss: 3663.4197, MAE: 3663.9194, NMAE: 55.7771, R^2: 0.2962\n",
      "Epoch [565/1500]\n",
      "Train Loss: 2267.5490\n",
      "Val Loss: 3698.3609, MAE: 3698.8608, NMAE: 56.3091, R^2: 0.2962\n",
      "Epoch [566/1500]\n",
      "Train Loss: 2278.2162\n",
      "Val Loss: 3737.0933, MAE: 3737.5930, NMAE: 56.8987, R^2: 0.2680\n",
      "Epoch [567/1500]\n",
      "Train Loss: 2297.8907\n",
      "Val Loss: 3750.8414, MAE: 3751.3411, NMAE: 57.1080, R^2: 0.2683\n",
      "Epoch [568/1500]\n",
      "Train Loss: 2335.0598\n",
      "Val Loss: 3698.9150, MAE: 3699.4150, NMAE: 56.3175, R^2: 0.2778\n",
      "Epoch [569/1500]\n",
      "Train Loss: 2299.1886\n",
      "Val Loss: 3684.1997, MAE: 3684.6995, NMAE: 56.0935, R^2: 0.3058\n",
      "Epoch [570/1500]\n",
      "Train Loss: 2291.0963\n",
      "Val Loss: 3686.8641, MAE: 3687.3638, NMAE: 56.1340, R^2: 0.2929\n",
      "Epoch [571/1500]\n",
      "Train Loss: 2266.8666\n",
      "Val Loss: 3714.5616, MAE: 3715.0613, NMAE: 56.5557, R^2: 0.2936\n",
      "Epoch [572/1500]\n",
      "Train Loss: 2315.9724\n",
      "Val Loss: 3647.1674, MAE: 3647.6672, NMAE: 55.5297, R^2: 0.3187\n",
      "Epoch [573/1500]\n",
      "Train Loss: 2355.2750\n",
      "Val Loss: 3597.3282, MAE: 3597.8281, NMAE: 54.7710, R^2: 0.3380\n",
      "Epoch [574/1500]\n",
      "Train Loss: 2311.1411\n",
      "Val Loss: 3664.8362, MAE: 3665.3362, NMAE: 55.7987, R^2: 0.3000\n",
      "Epoch [575/1500]\n",
      "Train Loss: 2347.3100\n",
      "Val Loss: 3621.3810, MAE: 3621.8809, NMAE: 55.1372, R^2: 0.3234\n",
      "Epoch [576/1500]\n",
      "Train Loss: 2438.7609\n",
      "Val Loss: 3640.0470, MAE: 3640.5469, NMAE: 55.4213, R^2: 0.2968\n",
      "Epoch [577/1500]\n",
      "Train Loss: 2321.7171\n",
      "Val Loss: 3752.3947, MAE: 3752.8948, NMAE: 57.1316, R^2: 0.2664\n",
      "Epoch [578/1500]\n",
      "Train Loss: 2373.4604\n",
      "Val Loss: 3699.6502, MAE: 3700.1501, NMAE: 56.3287, R^2: 0.2918\n",
      "Epoch [579/1500]\n",
      "Train Loss: 2349.3429\n",
      "Val Loss: 3681.4716, MAE: 3681.9714, NMAE: 56.0519, R^2: 0.2931\n",
      "Epoch [580/1500]\n",
      "Train Loss: 2374.4330\n",
      "Val Loss: 3700.1874, MAE: 3700.6873, NMAE: 56.3369, R^2: 0.2862\n",
      "Epoch [581/1500]\n",
      "Train Loss: 2323.1996\n",
      "Val Loss: 3726.1860, MAE: 3726.6860, NMAE: 56.7327, R^2: 0.2889\n",
      "Epoch [582/1500]\n",
      "Train Loss: 2309.3314\n",
      "Val Loss: 3646.7327, MAE: 3647.2327, NMAE: 55.5231, R^2: 0.3019\n",
      "Epoch [583/1500]\n",
      "Train Loss: 2316.7546\n",
      "Val Loss: 3609.1267, MAE: 3609.6265, NMAE: 54.9506, R^2: 0.3049\n",
      "Epoch [584/1500]\n",
      "Train Loss: 2325.4024\n",
      "Val Loss: 3660.7110, MAE: 3661.2107, NMAE: 55.7359, R^2: 0.2863\n",
      "Epoch [585/1500]\n",
      "Train Loss: 2363.6696\n",
      "Val Loss: 3748.0493, MAE: 3748.5493, NMAE: 57.0655, R^2: 0.2569\n",
      "Epoch [586/1500]\n",
      "Train Loss: 2427.4247\n",
      "Val Loss: 3713.1102, MAE: 3713.6101, NMAE: 56.5336, R^2: 0.2718\n",
      "Epoch [587/1500]\n",
      "Train Loss: 2391.3225\n",
      "Val Loss: 3745.2907, MAE: 3745.7905, NMAE: 57.0235, R^2: 0.2655\n",
      "Epoch [588/1500]\n",
      "Train Loss: 2420.6888\n",
      "Val Loss: 3689.7403, MAE: 3690.2405, NMAE: 56.1778, R^2: 0.2784\n",
      "Epoch [589/1500]\n",
      "Train Loss: 2379.6460\n",
      "Val Loss: 3720.3615, MAE: 3720.8611, NMAE: 56.6440, R^2: 0.2763\n",
      "Epoch [590/1500]\n",
      "Train Loss: 2393.9628\n",
      "Val Loss: 3808.4859, MAE: 3808.9858, NMAE: 57.9855, R^2: 0.2806\n",
      "Epoch [591/1500]\n",
      "Train Loss: 2399.8330\n",
      "Val Loss: 3747.4196, MAE: 3747.9194, NMAE: 57.0559, R^2: 0.2631\n",
      "Epoch [592/1500]\n",
      "Train Loss: 2382.0030\n",
      "Val Loss: 3729.3027, MAE: 3729.8025, NMAE: 56.7801, R^2: 0.2711\n",
      "Epoch [593/1500]\n",
      "Train Loss: 2393.0165\n",
      "Val Loss: 3693.6702, MAE: 3694.1702, NMAE: 56.2377, R^2: 0.2860\n",
      "Epoch [594/1500]\n",
      "Train Loss: 2445.0238\n",
      "Val Loss: 3772.0770, MAE: 3772.5767, NMAE: 57.4313, R^2: 0.2588\n",
      "Epoch [595/1500]\n",
      "Train Loss: 2389.3614\n",
      "Val Loss: 3794.9740, MAE: 3795.4739, NMAE: 57.7798, R^2: 0.2479\n",
      "Epoch [596/1500]\n",
      "Train Loss: 2431.7160\n",
      "Val Loss: 3740.1675, MAE: 3740.6672, NMAE: 56.9455, R^2: 0.2588\n",
      "Epoch [597/1500]\n",
      "Train Loss: 2376.8419\n",
      "Val Loss: 3778.9843, MAE: 3779.4844, NMAE: 57.5364, R^2: 0.2595\n",
      "Epoch [598/1500]\n",
      "Train Loss: 2390.0075\n",
      "Val Loss: 3729.8986, MAE: 3730.3984, NMAE: 56.7892, R^2: 0.2671\n",
      "Epoch [599/1500]\n",
      "Train Loss: 2435.9330\n",
      "Val Loss: 3689.2344, MAE: 3689.7344, NMAE: 56.1701, R^2: 0.2983\n",
      "Epoch [600/1500]\n",
      "Train Loss: 2360.2356\n",
      "Val Loss: 3669.1850, MAE: 3669.6848, NMAE: 55.8649, R^2: 0.2925\n",
      "Epoch [601/1500]\n",
      "Train Loss: 2443.5844\n",
      "Val Loss: 3717.3859, MAE: 3717.8855, NMAE: 56.5987, R^2: 0.2720\n",
      "Epoch [602/1500]\n",
      "Train Loss: 2431.5264\n",
      "Val Loss: 3680.0782, MAE: 3680.5776, NMAE: 56.0307, R^2: 0.2930\n",
      "Epoch [603/1500]\n",
      "Train Loss: 2427.8166\n",
      "Val Loss: 3662.0891, MAE: 3662.5889, NMAE: 55.7569, R^2: 0.3220\n",
      "Epoch [604/1500]\n",
      "Train Loss: 2381.6264\n",
      "Val Loss: 3640.3492, MAE: 3640.8491, NMAE: 55.4259, R^2: 0.3167\n",
      "Epoch [605/1500]\n",
      "Train Loss: 2426.0780\n",
      "Val Loss: 3585.2067, MAE: 3585.7068, NMAE: 54.5865, R^2: 0.3225\n",
      "Epoch [606/1500]\n",
      "Train Loss: 2423.8658\n",
      "Val Loss: 3623.9672, MAE: 3624.4668, NMAE: 55.1765, R^2: 0.3246\n",
      "Epoch [607/1500]\n",
      "Train Loss: 2411.4345\n",
      "Val Loss: 3638.7341, MAE: 3639.2341, NMAE: 55.4013, R^2: 0.3030\n",
      "Epoch [608/1500]\n",
      "Train Loss: 2435.6171\n",
      "Val Loss: 3566.1966, MAE: 3566.6963, NMAE: 54.2971, R^2: 0.3531\n",
      "Epoch [609/1500]\n",
      "Train Loss: 2436.4428\n",
      "Val Loss: 3774.4908, MAE: 3774.9905, NMAE: 57.4680, R^2: 0.2735\n",
      "Epoch [610/1500]\n",
      "Train Loss: 2442.4584\n",
      "Val Loss: 3730.1335, MAE: 3730.6333, NMAE: 56.7927, R^2: 0.2932\n",
      "Epoch [611/1500]\n",
      "Train Loss: 2430.2169\n",
      "Val Loss: 3695.5680, MAE: 3696.0676, NMAE: 56.2665, R^2: 0.2833\n",
      "Epoch [612/1500]\n",
      "Train Loss: 2378.1861\n",
      "Val Loss: 3759.7309, MAE: 3760.2307, NMAE: 57.2433, R^2: 0.2665\n",
      "Epoch [613/1500]\n",
      "Train Loss: 2382.2219\n",
      "Val Loss: 3926.8313, MAE: 3927.3311, NMAE: 59.7871, R^2: 0.2297\n",
      "Epoch [614/1500]\n",
      "Train Loss: 2476.2614\n",
      "Val Loss: 3900.6324, MAE: 3901.1318, NMAE: 59.3883, R^2: 0.2224\n",
      "Epoch [615/1500]\n",
      "Train Loss: 2472.6860\n",
      "Val Loss: 3849.2268, MAE: 3849.7266, NMAE: 58.6057, R^2: 0.2183\n",
      "Epoch [616/1500]\n",
      "Train Loss: 2444.6070\n",
      "Val Loss: 3802.5143, MAE: 3803.0139, NMAE: 57.8946, R^2: 0.2499\n",
      "Epoch [617/1500]\n",
      "Train Loss: 2461.0060\n",
      "Val Loss: 3735.0992, MAE: 3735.5991, NMAE: 56.8683, R^2: 0.2619\n",
      "Epoch [618/1500]\n",
      "Train Loss: 2395.3711\n",
      "Val Loss: 3715.9569, MAE: 3716.4570, NMAE: 56.5769, R^2: 0.2490\n",
      "Epoch [619/1500]\n",
      "Train Loss: 2332.6314\n",
      "Val Loss: 3715.7778, MAE: 3716.2778, NMAE: 56.5742, R^2: 0.2662\n",
      "Epoch [620/1500]\n",
      "Train Loss: 2369.0470\n",
      "Val Loss: 3714.8475, MAE: 3715.3474, NMAE: 56.5600, R^2: 0.2731\n",
      "Epoch [621/1500]\n",
      "Train Loss: 2444.8309\n",
      "Val Loss: 3879.3117, MAE: 3879.8115, NMAE: 59.0637, R^2: 0.2088\n",
      "Epoch [622/1500]\n",
      "Train Loss: 2544.6655\n",
      "Val Loss: 3711.7839, MAE: 3712.2837, NMAE: 56.5134, R^2: 0.2831\n",
      "Epoch [623/1500]\n",
      "Train Loss: 2483.0410\n",
      "Val Loss: 3715.1290, MAE: 3715.6289, NMAE: 56.5643, R^2: 0.2720\n",
      "Epoch [624/1500]\n",
      "Train Loss: 2490.4655\n",
      "Val Loss: 3739.7893, MAE: 3740.2893, NMAE: 56.9397, R^2: 0.2646\n",
      "Epoch [625/1500]\n",
      "Train Loss: 2436.5940\n",
      "Val Loss: 3721.2421, MAE: 3721.7419, NMAE: 56.6574, R^2: 0.2790\n",
      "Epoch [626/1500]\n",
      "Train Loss: 2432.4102\n",
      "Val Loss: 3703.1569, MAE: 3703.6567, NMAE: 56.3821, R^2: 0.2861\n",
      "Epoch [627/1500]\n",
      "Train Loss: 2439.3821\n",
      "Val Loss: 3703.4633, MAE: 3703.9631, NMAE: 56.3867, R^2: 0.2817\n",
      "Epoch [628/1500]\n",
      "Train Loss: 2434.1815\n",
      "Val Loss: 3726.7855, MAE: 3727.2852, NMAE: 56.7418, R^2: 0.2801\n",
      "Epoch [629/1500]\n",
      "Train Loss: 2493.2194\n",
      "Val Loss: 3786.0449, MAE: 3786.5447, NMAE: 57.6439, R^2: 0.2619\n",
      "Epoch [630/1500]\n",
      "Train Loss: 2507.5941\n",
      "Val Loss: 3823.3137, MAE: 3823.8135, NMAE: 58.2113, R^2: 0.2601\n",
      "Epoch [631/1500]\n",
      "Train Loss: 2437.5604\n",
      "Val Loss: 3744.2195, MAE: 3744.7192, NMAE: 57.0072, R^2: 0.2654\n",
      "Epoch [632/1500]\n",
      "Train Loss: 2478.8134\n",
      "Val Loss: 3756.6662, MAE: 3757.1660, NMAE: 57.1967, R^2: 0.2617\n",
      "Epoch [633/1500]\n",
      "Train Loss: 2428.9600\n",
      "Val Loss: 3684.1355, MAE: 3684.6355, NMAE: 56.0925, R^2: 0.2721\n",
      "Epoch [634/1500]\n",
      "Train Loss: 2478.8974\n",
      "Val Loss: 3720.0545, MAE: 3720.5542, NMAE: 56.6393, R^2: 0.2708\n",
      "Epoch [635/1500]\n",
      "Train Loss: 2458.0902\n",
      "Val Loss: 3766.0407, MAE: 3766.5408, NMAE: 57.3394, R^2: 0.2418\n",
      "Epoch [636/1500]\n",
      "Train Loss: 2477.4014\n",
      "Val Loss: 3806.2600, MAE: 3806.7600, NMAE: 57.9516, R^2: 0.2515\n",
      "Epoch [637/1500]\n",
      "Train Loss: 2484.0021\n",
      "Val Loss: 3730.3323, MAE: 3730.8323, NMAE: 56.7958, R^2: 0.2803\n",
      "Epoch [638/1500]\n",
      "Train Loss: 2545.5847\n",
      "Val Loss: 3756.2910, MAE: 3756.7913, NMAE: 57.1910, R^2: 0.2755\n",
      "Epoch [639/1500]\n",
      "Train Loss: 2508.1313\n",
      "Val Loss: 3718.8790, MAE: 3719.3789, NMAE: 56.6214, R^2: 0.2878\n",
      "Epoch [640/1500]\n",
      "Train Loss: 2535.5094\n",
      "Val Loss: 3732.3779, MAE: 3732.8779, NMAE: 56.8269, R^2: 0.3025\n",
      "Epoch [641/1500]\n",
      "Train Loss: 2540.8402\n",
      "Val Loss: 3723.8155, MAE: 3724.3154, NMAE: 56.6966, R^2: 0.2863\n",
      "Epoch [642/1500]\n",
      "Train Loss: 2547.9975\n",
      "Val Loss: 3779.3440, MAE: 3779.8442, NMAE: 57.5419, R^2: 0.2612\n",
      "Epoch [643/1500]\n",
      "Train Loss: 2510.6299\n",
      "Val Loss: 3777.5179, MAE: 3778.0178, NMAE: 57.5141, R^2: 0.2623\n",
      "Epoch [644/1500]\n",
      "Train Loss: 2596.9893\n",
      "Val Loss: 3847.7542, MAE: 3848.2539, NMAE: 58.5833, R^2: 0.2434\n",
      "Epoch [645/1500]\n",
      "Train Loss: 2593.4851\n",
      "Val Loss: 3794.1287, MAE: 3794.6284, NMAE: 57.7670, R^2: 0.2416\n",
      "Epoch [646/1500]\n",
      "Train Loss: 2550.5577\n",
      "Val Loss: 3778.3848, MAE: 3778.8845, NMAE: 57.5273, R^2: 0.2482\n",
      "Epoch [647/1500]\n",
      "Train Loss: 2532.9423\n",
      "Val Loss: 3725.3941, MAE: 3725.8938, NMAE: 56.7206, R^2: 0.2768\n",
      "Epoch [648/1500]\n",
      "Train Loss: 2515.4153\n",
      "Val Loss: 3752.3851, MAE: 3752.8848, NMAE: 57.1315, R^2: 0.2492\n",
      "Epoch [649/1500]\n",
      "Train Loss: 2469.1006\n",
      "Val Loss: 3793.1557, MAE: 3793.6555, NMAE: 57.7522, R^2: 0.2596\n",
      "Epoch [650/1500]\n",
      "Train Loss: 2457.4808\n",
      "Val Loss: 3752.2485, MAE: 3752.7483, NMAE: 57.1294, R^2: 0.2655\n",
      "Epoch [651/1500]\n",
      "Train Loss: 2510.5821\n",
      "Val Loss: 3742.8583, MAE: 3743.3584, NMAE: 56.9865, R^2: 0.2554\n",
      "Epoch [652/1500]\n",
      "Train Loss: 2541.7934\n",
      "Val Loss: 3765.2463, MAE: 3765.7461, NMAE: 57.3273, R^2: 0.2564\n",
      "Epoch [653/1500]\n",
      "Train Loss: 2473.2573\n",
      "Val Loss: 3726.6528, MAE: 3727.1526, NMAE: 56.7398, R^2: 0.2652\n",
      "Epoch [654/1500]\n",
      "Train Loss: 2498.0392\n",
      "Val Loss: 3700.1672, MAE: 3700.6672, NMAE: 56.3366, R^2: 0.2765\n",
      "Epoch [655/1500]\n",
      "Train Loss: 2527.3267\n",
      "Val Loss: 3782.1885, MAE: 3782.6887, NMAE: 57.5852, R^2: 0.2432\n",
      "Epoch [656/1500]\n",
      "Train Loss: 2518.0602\n",
      "Val Loss: 3844.6047, MAE: 3845.1045, NMAE: 58.5354, R^2: 0.2344\n",
      "Epoch [657/1500]\n",
      "Train Loss: 2511.1616\n",
      "Val Loss: 3798.9434, MAE: 3799.4434, NMAE: 57.8403, R^2: 0.2509\n",
      "Epoch [658/1500]\n",
      "Train Loss: 2558.0041\n",
      "Val Loss: 3747.4805, MAE: 3747.9805, NMAE: 57.0568, R^2: 0.2632\n",
      "Epoch [659/1500]\n",
      "Train Loss: 2583.5369\n",
      "Val Loss: 3724.9493, MAE: 3725.4492, NMAE: 56.7138, R^2: 0.2585\n",
      "Epoch [660/1500]\n",
      "Train Loss: 2526.8475\n",
      "Val Loss: 3704.5236, MAE: 3705.0237, NMAE: 56.4029, R^2: 0.2668\n",
      "Epoch [661/1500]\n",
      "Train Loss: 2525.2289\n",
      "Val Loss: 3699.3378, MAE: 3699.8376, NMAE: 56.3239, R^2: 0.2843\n",
      "Epoch [662/1500]\n",
      "Train Loss: 2570.8091\n",
      "Val Loss: 3714.0100, MAE: 3714.5098, NMAE: 56.5473, R^2: 0.2801\n",
      "Epoch [663/1500]\n",
      "Train Loss: 2573.7751\n",
      "Val Loss: 3786.0798, MAE: 3786.5798, NMAE: 57.6444, R^2: 0.2552\n",
      "Epoch [664/1500]\n",
      "Train Loss: 2540.4575\n",
      "Val Loss: 3797.0108, MAE: 3797.5105, NMAE: 57.8108, R^2: 0.2532\n",
      "Epoch [665/1500]\n",
      "Train Loss: 2506.6724\n",
      "Val Loss: 3729.2380, MAE: 3729.7380, NMAE: 56.7791, R^2: 0.2754\n",
      "Epoch [666/1500]\n",
      "Train Loss: 2560.5269\n",
      "Val Loss: 3726.7553, MAE: 3727.2551, NMAE: 56.7413, R^2: 0.2759\n",
      "Epoch [667/1500]\n",
      "Train Loss: 2503.2822\n",
      "Val Loss: 3667.6894, MAE: 3668.1892, NMAE: 55.8421, R^2: 0.2941\n",
      "Epoch [668/1500]\n",
      "Train Loss: 2532.9375\n",
      "Val Loss: 3667.9926, MAE: 3668.4924, NMAE: 55.8468, R^2: 0.2732\n",
      "Epoch [669/1500]\n",
      "Train Loss: 2506.0046\n",
      "Val Loss: 3658.7049, MAE: 3659.2048, NMAE: 55.7054, R^2: 0.2814\n",
      "Epoch [670/1500]\n",
      "Train Loss: 2573.3988\n",
      "Val Loss: 3656.2274, MAE: 3656.7271, NMAE: 55.6676, R^2: 0.3016\n",
      "Epoch [671/1500]\n",
      "Train Loss: 2559.2040\n",
      "Val Loss: 3691.4457, MAE: 3691.9458, NMAE: 56.2038, R^2: 0.2818\n",
      "Epoch [672/1500]\n",
      "Train Loss: 2521.1231\n",
      "Val Loss: 3745.8545, MAE: 3746.3545, NMAE: 57.0321, R^2: 0.2672\n",
      "Epoch [673/1500]\n",
      "Train Loss: 2543.8503\n",
      "Val Loss: 3720.2060, MAE: 3720.7058, NMAE: 56.6416, R^2: 0.2739\n",
      "Epoch [674/1500]\n",
      "Train Loss: 2568.7894\n",
      "Val Loss: 3726.0404, MAE: 3726.5403, NMAE: 56.7304, R^2: 0.2718\n",
      "Epoch [675/1500]\n",
      "Train Loss: 2582.7339\n",
      "Val Loss: 3749.2142, MAE: 3749.7141, NMAE: 57.0832, R^2: 0.2718\n",
      "Epoch [676/1500]\n",
      "Train Loss: 2649.6335\n",
      "Val Loss: 3781.0401, MAE: 3781.5398, NMAE: 57.5677, R^2: 0.2640\n",
      "Epoch [677/1500]\n",
      "Train Loss: 2599.5121\n",
      "Val Loss: 3784.4542, MAE: 3784.9539, NMAE: 57.6197, R^2: 0.2853\n",
      "Epoch [678/1500]\n",
      "Train Loss: 2579.7145\n",
      "Val Loss: 3741.2557, MAE: 3741.7559, NMAE: 56.9621, R^2: 0.2729\n",
      "Epoch [679/1500]\n",
      "Train Loss: 2511.6627\n",
      "Val Loss: 3765.1477, MAE: 3765.6475, NMAE: 57.3258, R^2: 0.2686\n",
      "Epoch [680/1500]\n",
      "Train Loss: 2471.1811\n",
      "Val Loss: 3767.5358, MAE: 3768.0354, NMAE: 57.3621, R^2: 0.2690\n",
      "Epoch [681/1500]\n",
      "Train Loss: 2550.0563\n",
      "Val Loss: 3739.4426, MAE: 3739.9426, NMAE: 56.9345, R^2: 0.2720\n",
      "Epoch [682/1500]\n",
      "Train Loss: 2503.3771\n",
      "Val Loss: 3723.2725, MAE: 3723.7722, NMAE: 56.6883, R^2: 0.2682\n",
      "Epoch [683/1500]\n",
      "Train Loss: 2508.0617\n",
      "Val Loss: 3722.8750, MAE: 3723.3748, NMAE: 56.6822, R^2: 0.2689\n",
      "Epoch [684/1500]\n",
      "Train Loss: 2476.9881\n",
      "Val Loss: 3763.0844, MAE: 3763.5845, NMAE: 57.2944, R^2: 0.2634\n",
      "Epoch [685/1500]\n",
      "Train Loss: 2532.0801\n",
      "Val Loss: 3838.7064, MAE: 3839.2061, NMAE: 58.4456, R^2: 0.2321\n",
      "Epoch [686/1500]\n",
      "Train Loss: 2528.3593\n",
      "Val Loss: 3857.5621, MAE: 3858.0620, NMAE: 58.7326, R^2: 0.2239\n",
      "Epoch [687/1500]\n",
      "Train Loss: 2503.3462\n",
      "Val Loss: 3875.4407, MAE: 3875.9402, NMAE: 59.0048, R^2: 0.2403\n",
      "Epoch [688/1500]\n",
      "Train Loss: 2554.6171\n",
      "Val Loss: 3850.0439, MAE: 3850.5437, NMAE: 58.6182, R^2: 0.2292\n",
      "Epoch [689/1500]\n",
      "Train Loss: 2519.3667\n",
      "Val Loss: 3832.4003, MAE: 3832.9001, NMAE: 58.3496, R^2: 0.2393\n",
      "Epoch [690/1500]\n",
      "Train Loss: 2549.0052\n",
      "Val Loss: 3806.6376, MAE: 3807.1375, NMAE: 57.9574, R^2: 0.2511\n",
      "Epoch [691/1500]\n",
      "Train Loss: 2573.0265\n",
      "Val Loss: 3830.1394, MAE: 3830.6394, NMAE: 58.3152, R^2: 0.2336\n",
      "Epoch [692/1500]\n",
      "Train Loss: 2559.0807\n",
      "Val Loss: 3857.2617, MAE: 3857.7615, NMAE: 58.7281, R^2: 0.2305\n",
      "Epoch [693/1500]\n",
      "Train Loss: 2563.8163\n",
      "Val Loss: 3894.0407, MAE: 3894.5403, NMAE: 59.2880, R^2: 0.2189\n",
      "Epoch [694/1500]\n",
      "Train Loss: 2586.7884\n",
      "Val Loss: 3897.6423, MAE: 3898.1421, NMAE: 59.3428, R^2: 0.2266\n",
      "Epoch [695/1500]\n",
      "Train Loss: 2614.9404\n",
      "Val Loss: 3831.6002, MAE: 3832.1001, NMAE: 58.3374, R^2: 0.2584\n",
      "Epoch [696/1500]\n",
      "Train Loss: 2578.8865\n",
      "Val Loss: 3848.8249, MAE: 3849.3247, NMAE: 58.5996, R^2: 0.2254\n",
      "Epoch [697/1500]\n",
      "Train Loss: 2670.9333\n",
      "Val Loss: 3795.5101, MAE: 3796.0098, NMAE: 57.7880, R^2: 0.2517\n",
      "Epoch [698/1500]\n",
      "Train Loss: 2598.3201\n",
      "Val Loss: 3786.8092, MAE: 3787.3093, NMAE: 57.6555, R^2: 0.2540\n",
      "Epoch [699/1500]\n",
      "Train Loss: 2531.0443\n",
      "Val Loss: 3850.5026, MAE: 3851.0024, NMAE: 58.6252, R^2: 0.2357\n",
      "Epoch [700/1500]\n",
      "Train Loss: 2458.4169\n",
      "Val Loss: 3811.0206, MAE: 3811.5205, NMAE: 58.0241, R^2: 0.2484\n",
      "Epoch [701/1500]\n",
      "Train Loss: 2522.7389\n",
      "Val Loss: 3795.7413, MAE: 3796.2412, NMAE: 57.7915, R^2: 0.2499\n",
      "Epoch [702/1500]\n",
      "Train Loss: 2572.3487\n",
      "Val Loss: 3793.7680, MAE: 3794.2678, NMAE: 57.7615, R^2: 0.2487\n",
      "Epoch [703/1500]\n",
      "Train Loss: 2531.2256\n",
      "Val Loss: 3761.2533, MAE: 3761.7532, NMAE: 57.2665, R^2: 0.2475\n",
      "Epoch [704/1500]\n",
      "Train Loss: 2604.2950\n",
      "Val Loss: 3805.6222, MAE: 3806.1218, NMAE: 57.9419, R^2: 0.2302\n",
      "Epoch [705/1500]\n",
      "Train Loss: 2559.9250\n",
      "Val Loss: 3766.7374, MAE: 3767.2371, NMAE: 57.3500, R^2: 0.2577\n",
      "Epoch [706/1500]\n",
      "Train Loss: 2582.7445\n",
      "Val Loss: 3729.2556, MAE: 3729.7556, NMAE: 56.7794, R^2: 0.2728\n",
      "Epoch [707/1500]\n",
      "Train Loss: 2569.1489\n",
      "Val Loss: 3767.2037, MAE: 3767.7036, NMAE: 57.3571, R^2: 0.2619\n",
      "Epoch [708/1500]\n",
      "Train Loss: 2525.7932\n",
      "Val Loss: 3726.8870, MAE: 3727.3867, NMAE: 56.7433, R^2: 0.2742\n",
      "Epoch [709/1500]\n",
      "Train Loss: 2478.6273\n",
      "Val Loss: 3720.1177, MAE: 3720.6177, NMAE: 56.6403, R^2: 0.2791\n",
      "Epoch [710/1500]\n",
      "Train Loss: 2570.6769\n",
      "Val Loss: 3736.2141, MAE: 3736.7139, NMAE: 56.8853, R^2: 0.2625\n",
      "Epoch [711/1500]\n",
      "Train Loss: 2534.0284\n",
      "Val Loss: 3722.2755, MAE: 3722.7754, NMAE: 56.6731, R^2: 0.2625\n",
      "Epoch [712/1500]\n",
      "Train Loss: 2500.8796\n",
      "Val Loss: 3772.8439, MAE: 3773.3438, NMAE: 57.4429, R^2: 0.2495\n",
      "Epoch [713/1500]\n",
      "Train Loss: 2593.2954\n",
      "Val Loss: 3831.4960, MAE: 3831.9958, NMAE: 58.3358, R^2: 0.2289\n",
      "Epoch [714/1500]\n",
      "Train Loss: 2532.7700\n",
      "Val Loss: 3765.0501, MAE: 3765.5498, NMAE: 57.3243, R^2: 0.2736\n",
      "Epoch [715/1500]\n",
      "Train Loss: 2582.2078\n",
      "Val Loss: 3796.5632, MAE: 3797.0630, NMAE: 57.8040, R^2: 0.2572\n",
      "Epoch [716/1500]\n",
      "Train Loss: 2644.2980\n",
      "Val Loss: 3730.5679, MAE: 3731.0676, NMAE: 56.7994, R^2: 0.2869\n",
      "Epoch [717/1500]\n",
      "Train Loss: 2550.9355\n",
      "Val Loss: 3877.4317, MAE: 3877.9314, NMAE: 59.0351, R^2: 0.2272\n",
      "Epoch [718/1500]\n",
      "Train Loss: 2532.6782\n",
      "Val Loss: 3731.2461, MAE: 3731.7461, NMAE: 56.8097, R^2: 0.2671\n",
      "Epoch [719/1500]\n",
      "Train Loss: 2569.5903\n",
      "Val Loss: 3798.6121, MAE: 3799.1121, NMAE: 57.8352, R^2: 0.2464\n",
      "Epoch [720/1500]\n",
      "Train Loss: 2604.4726\n",
      "Val Loss: 3827.2680, MAE: 3827.7681, NMAE: 58.2715, R^2: 0.2500\n",
      "Epoch [721/1500]\n",
      "Train Loss: 2637.5585\n",
      "Val Loss: 3757.8458, MAE: 3758.3457, NMAE: 57.2146, R^2: 0.2723\n",
      "Epoch [722/1500]\n",
      "Train Loss: 2640.2361\n",
      "Val Loss: 3768.0375, MAE: 3768.5374, NMAE: 57.3698, R^2: 0.2719\n",
      "Epoch [723/1500]\n",
      "Train Loss: 2605.1960\n",
      "Val Loss: 3785.9365, MAE: 3786.4363, NMAE: 57.6423, R^2: 0.2503\n",
      "Epoch [724/1500]\n",
      "Train Loss: 2608.0219\n",
      "Val Loss: 3775.4221, MAE: 3775.9219, NMAE: 57.4822, R^2: 0.2522\n",
      "Epoch [725/1500]\n",
      "Train Loss: 2641.6080\n",
      "Val Loss: 3723.3046, MAE: 3723.8044, NMAE: 56.6888, R^2: 0.3010\n",
      "Epoch [726/1500]\n",
      "Train Loss: 2647.1497\n",
      "Val Loss: 3717.7965, MAE: 3718.2964, NMAE: 56.6049, R^2: 0.2923\n",
      "Epoch [727/1500]\n",
      "Train Loss: 2568.9609\n",
      "Val Loss: 3699.0871, MAE: 3699.5869, NMAE: 56.3201, R^2: 0.2945\n",
      "Epoch [728/1500]\n",
      "Train Loss: 2625.6608\n",
      "Val Loss: 3785.8541, MAE: 3786.3538, NMAE: 57.6410, R^2: 0.2665\n",
      "Epoch [729/1500]\n",
      "Train Loss: 2622.8027\n",
      "Val Loss: 3763.1779, MAE: 3763.6777, NMAE: 57.2958, R^2: 0.2608\n",
      "Epoch [730/1500]\n",
      "Train Loss: 2678.7270\n",
      "Val Loss: 3782.3492, MAE: 3782.8491, NMAE: 57.5876, R^2: 0.2700\n",
      "Epoch [731/1500]\n",
      "Train Loss: 2617.7942\n",
      "Val Loss: 3747.8162, MAE: 3748.3159, NMAE: 57.0619, R^2: 0.2759\n",
      "Epoch [732/1500]\n",
      "Train Loss: 2623.8782\n",
      "Val Loss: 3738.5058, MAE: 3739.0056, NMAE: 56.9202, R^2: 0.2772\n",
      "Epoch [733/1500]\n",
      "Train Loss: 2635.8114\n",
      "Val Loss: 3761.0884, MAE: 3761.5884, NMAE: 57.2640, R^2: 0.2788\n",
      "Epoch [734/1500]\n",
      "Train Loss: 2612.8748\n",
      "Val Loss: 3848.9963, MAE: 3849.4961, NMAE: 58.6022, R^2: 0.2427\n",
      "Epoch [735/1500]\n",
      "Train Loss: 2550.0584\n",
      "Val Loss: 3773.4506, MAE: 3773.9504, NMAE: 57.4522, R^2: 0.2644\n",
      "Epoch [736/1500]\n",
      "Train Loss: 2561.0258\n",
      "Val Loss: 3778.7412, MAE: 3779.2412, NMAE: 57.5327, R^2: 0.2604\n",
      "Epoch [737/1500]\n",
      "Train Loss: 2562.8771\n",
      "Val Loss: 3747.9826, MAE: 3748.4824, NMAE: 57.0645, R^2: 0.2653\n",
      "Epoch [738/1500]\n",
      "Train Loss: 2576.4154\n",
      "Val Loss: 3816.8895, MAE: 3817.3894, NMAE: 58.1135, R^2: 0.2609\n",
      "Epoch [739/1500]\n",
      "Train Loss: 2552.3327\n",
      "Val Loss: 3693.5980, MAE: 3694.0979, NMAE: 56.2366, R^2: 0.2893\n",
      "Epoch [740/1500]\n",
      "Train Loss: 2563.3061\n",
      "Val Loss: 3691.0211, MAE: 3691.5210, NMAE: 56.1973, R^2: 0.2858\n",
      "Epoch [741/1500]\n",
      "Train Loss: 2556.5817\n",
      "Val Loss: 3803.4736, MAE: 3803.9736, NMAE: 57.9092, R^2: 0.2612\n",
      "Epoch [742/1500]\n",
      "Train Loss: 2593.8706\n",
      "Val Loss: 3712.5568, MAE: 3713.0569, NMAE: 56.5252, R^2: 0.2812\n",
      "Epoch [743/1500]\n",
      "Train Loss: 2572.7113\n",
      "Val Loss: 3760.7067, MAE: 3761.2068, NMAE: 57.2582, R^2: 0.2733\n",
      "Epoch [744/1500]\n",
      "Train Loss: 2540.5122\n",
      "Val Loss: 3658.9896, MAE: 3659.4897, NMAE: 55.7097, R^2: 0.2997\n",
      "Epoch [745/1500]\n",
      "Train Loss: 2597.3031\n",
      "Val Loss: 3754.1209, MAE: 3754.6206, NMAE: 57.1579, R^2: 0.2719\n",
      "Epoch [746/1500]\n",
      "Train Loss: 2573.5404\n",
      "Val Loss: 3669.6033, MAE: 3670.1030, NMAE: 55.8713, R^2: 0.2975\n",
      "Epoch [747/1500]\n",
      "Train Loss: 2546.6771\n",
      "Val Loss: 3689.2225, MAE: 3689.7224, NMAE: 56.1699, R^2: 0.2895\n",
      "Epoch [748/1500]\n",
      "Train Loss: 2536.7836\n",
      "Val Loss: 3649.3123, MAE: 3649.8120, NMAE: 55.5624, R^2: 0.3136\n",
      "Epoch [749/1500]\n",
      "Train Loss: 2596.2025\n",
      "Val Loss: 3687.2020, MAE: 3687.7019, NMAE: 56.1392, R^2: 0.3000\n",
      "Epoch [750/1500]\n",
      "Train Loss: 2520.6802\n",
      "Val Loss: 3695.2245, MAE: 3695.7246, NMAE: 56.2613, R^2: 0.2878\n",
      "Epoch [751/1500]\n",
      "Train Loss: 2584.1249\n",
      "Val Loss: 3675.2258, MAE: 3675.7258, NMAE: 55.9569, R^2: 0.3101\n",
      "Epoch [752/1500]\n",
      "Train Loss: 2505.9579\n",
      "Val Loss: 3661.7619, MAE: 3662.2617, NMAE: 55.7519, R^2: 0.3028\n",
      "Epoch [753/1500]\n",
      "Train Loss: 2561.1997\n",
      "Val Loss: 3703.1046, MAE: 3703.6045, NMAE: 56.3813, R^2: 0.2921\n",
      "Epoch [754/1500]\n",
      "Train Loss: 2524.2415\n",
      "Val Loss: 3665.8295, MAE: 3666.3291, NMAE: 55.8138, R^2: 0.2994\n",
      "Epoch [755/1500]\n",
      "Train Loss: 2594.4762\n",
      "Val Loss: 3690.0070, MAE: 3690.5068, NMAE: 56.1819, R^2: 0.2933\n",
      "Epoch [756/1500]\n",
      "Train Loss: 2546.4273\n",
      "Val Loss: 3710.3918, MAE: 3710.8918, NMAE: 56.4922, R^2: 0.2812\n",
      "Epoch [757/1500]\n",
      "Train Loss: 2565.0564\n",
      "Val Loss: 3694.5699, MAE: 3695.0698, NMAE: 56.2513, R^2: 0.2865\n",
      "Epoch [758/1500]\n",
      "Train Loss: 2583.2656\n",
      "Val Loss: 3682.7282, MAE: 3683.2280, NMAE: 56.0711, R^2: 0.2889\n",
      "Epoch [759/1500]\n",
      "Train Loss: 2565.5339\n",
      "Val Loss: 3764.6880, MAE: 3765.1877, NMAE: 57.3188, R^2: 0.2533\n",
      "Epoch [760/1500]\n",
      "Train Loss: 2565.0977\n",
      "Val Loss: 3774.6879, MAE: 3775.1875, NMAE: 57.4710, R^2: 0.2470\n",
      "Epoch [761/1500]\n",
      "Train Loss: 2549.0219\n",
      "Val Loss: 3740.9224, MAE: 3741.4224, NMAE: 56.9570, R^2: 0.2808\n",
      "Epoch [762/1500]\n",
      "Train Loss: 2573.3574\n",
      "Val Loss: 3735.2784, MAE: 3735.7781, NMAE: 56.8711, R^2: 0.2802\n",
      "Epoch [763/1500]\n",
      "Train Loss: 2555.7099\n",
      "Val Loss: 3768.8001, MAE: 3769.3003, NMAE: 57.3814, R^2: 0.2604\n",
      "Epoch [764/1500]\n",
      "Train Loss: 2531.3014\n",
      "Val Loss: 3753.1867, MAE: 3753.6865, NMAE: 57.1437, R^2: 0.2682\n",
      "Epoch [765/1500]\n",
      "Train Loss: 2540.9379\n",
      "Val Loss: 3768.5791, MAE: 3769.0791, NMAE: 57.3780, R^2: 0.2519\n",
      "Epoch [766/1500]\n",
      "Train Loss: 2524.1783\n",
      "Val Loss: 3743.0404, MAE: 3743.5403, NMAE: 56.9892, R^2: 0.2705\n",
      "Epoch [767/1500]\n",
      "Train Loss: 2543.7604\n",
      "Val Loss: 3709.5605, MAE: 3710.0605, NMAE: 56.4796, R^2: 0.2624\n",
      "Epoch [768/1500]\n",
      "Train Loss: 2499.7006\n",
      "Val Loss: 3685.0344, MAE: 3685.5339, NMAE: 56.1062, R^2: 0.2971\n",
      "Epoch [769/1500]\n",
      "Train Loss: 2539.2315\n",
      "Val Loss: 3712.2381, MAE: 3712.7380, NMAE: 56.5203, R^2: 0.2754\n",
      "Epoch [770/1500]\n",
      "Train Loss: 2565.0914\n",
      "Val Loss: 3775.6855, MAE: 3776.1851, NMAE: 57.4862, R^2: 0.2616\n",
      "Epoch [771/1500]\n",
      "Train Loss: 2551.9553\n",
      "Val Loss: 3719.0805, MAE: 3719.5803, NMAE: 56.6245, R^2: 0.2655\n",
      "Epoch [772/1500]\n",
      "Train Loss: 2533.7124\n",
      "Val Loss: 3737.6967, MAE: 3738.1965, NMAE: 56.9079, R^2: 0.2689\n",
      "Epoch [773/1500]\n",
      "Train Loss: 2502.1979\n",
      "Val Loss: 3744.2124, MAE: 3744.7119, NMAE: 57.0071, R^2: 0.2524\n",
      "Epoch [774/1500]\n",
      "Train Loss: 2528.8711\n",
      "Val Loss: 3666.2438, MAE: 3666.7434, NMAE: 55.8201, R^2: 0.2951\n",
      "Epoch [775/1500]\n",
      "Train Loss: 2584.2162\n",
      "Val Loss: 3783.0609, MAE: 3783.5608, NMAE: 57.5985, R^2: 0.2447\n",
      "Epoch [776/1500]\n",
      "Train Loss: 2586.7680\n",
      "Val Loss: 3794.4896, MAE: 3794.9897, NMAE: 57.7725, R^2: 0.2601\n",
      "Epoch [777/1500]\n",
      "Train Loss: 2583.9704\n",
      "Val Loss: 3743.8856, MAE: 3744.3853, NMAE: 57.0021, R^2: 0.2547\n",
      "Epoch [778/1500]\n",
      "Train Loss: 2628.6866\n",
      "Val Loss: 3816.1677, MAE: 3816.6675, NMAE: 58.1025, R^2: 0.2399\n",
      "Epoch [779/1500]\n",
      "Train Loss: 2578.0402\n",
      "Val Loss: 3764.0526, MAE: 3764.5525, NMAE: 57.3091, R^2: 0.2638\n",
      "Epoch [780/1500]\n",
      "Train Loss: 2539.9287\n",
      "Val Loss: 3752.3914, MAE: 3752.8914, NMAE: 57.1316, R^2: 0.2724\n",
      "Epoch [781/1500]\n",
      "Train Loss: 2600.1775\n",
      "Val Loss: 3761.9427, MAE: 3762.4426, NMAE: 57.2770, R^2: 0.2609\n",
      "Epoch [782/1500]\n",
      "Train Loss: 2604.9844\n",
      "Val Loss: 3766.8834, MAE: 3767.3835, NMAE: 57.3522, R^2: 0.2602\n",
      "Epoch [783/1500]\n",
      "Train Loss: 2613.7453\n",
      "Val Loss: 3762.9674, MAE: 3763.4673, NMAE: 57.2926, R^2: 0.2548\n",
      "Epoch [784/1500]\n",
      "Train Loss: 2580.8536\n",
      "Val Loss: 3796.8873, MAE: 3797.3872, NMAE: 57.8090, R^2: 0.2462\n",
      "Epoch [785/1500]\n",
      "Train Loss: 2676.4872\n",
      "Val Loss: 3770.1007, MAE: 3770.6003, NMAE: 57.4012, R^2: 0.2438\n",
      "Epoch [786/1500]\n",
      "Train Loss: 2620.5603\n",
      "Val Loss: 3760.0065, MAE: 3760.5063, NMAE: 57.2475, R^2: 0.2552\n",
      "Epoch [787/1500]\n",
      "Train Loss: 2642.6957\n",
      "Val Loss: 3801.0123, MAE: 3801.5120, NMAE: 57.8718, R^2: 0.2598\n",
      "Epoch [788/1500]\n",
      "Train Loss: 2565.5906\n",
      "Val Loss: 3742.4642, MAE: 3742.9641, NMAE: 56.9805, R^2: 0.2758\n",
      "Epoch [789/1500]\n",
      "Train Loss: 2575.1253\n",
      "Val Loss: 3781.3615, MAE: 3781.8613, NMAE: 57.5726, R^2: 0.2670\n",
      "Epoch [790/1500]\n",
      "Train Loss: 2664.4149\n",
      "Val Loss: 3776.5416, MAE: 3777.0413, NMAE: 57.4992, R^2: 0.2558\n",
      "Epoch [791/1500]\n",
      "Train Loss: 2726.3762\n",
      "Val Loss: 3790.6494, MAE: 3791.1492, NMAE: 57.7140, R^2: 0.2634\n",
      "Epoch [792/1500]\n",
      "Train Loss: 2719.9553\n",
      "Val Loss: 3768.8958, MAE: 3769.3958, NMAE: 57.3828, R^2: 0.2620\n",
      "Epoch [793/1500]\n",
      "Train Loss: 2642.3835\n",
      "Val Loss: 3752.0836, MAE: 3752.5835, NMAE: 57.1269, R^2: 0.2782\n",
      "Epoch [794/1500]\n",
      "Train Loss: 2694.6856\n",
      "Val Loss: 3734.9634, MAE: 3735.4634, NMAE: 56.8663, R^2: 0.2809\n",
      "Epoch [795/1500]\n",
      "Train Loss: 2685.3247\n",
      "Val Loss: 3739.1720, MAE: 3739.6716, NMAE: 56.9303, R^2: 0.2854\n",
      "Epoch [796/1500]\n",
      "Train Loss: 2666.1235\n",
      "Val Loss: 3798.9303, MAE: 3799.4302, NMAE: 57.8401, R^2: 0.2450\n",
      "Epoch [797/1500]\n",
      "Train Loss: 2701.3039\n",
      "Val Loss: 3721.1431, MAE: 3721.6431, NMAE: 56.6559, R^2: 0.2789\n",
      "Epoch [798/1500]\n",
      "Train Loss: 2676.4680\n",
      "Val Loss: 3737.1337, MAE: 3737.6335, NMAE: 56.8993, R^2: 0.2694\n",
      "Epoch [799/1500]\n",
      "Train Loss: 2662.7133\n",
      "Val Loss: 3751.2271, MAE: 3751.7268, NMAE: 57.1139, R^2: 0.2561\n",
      "Epoch [800/1500]\n",
      "Train Loss: 2607.7864\n",
      "Val Loss: 3712.5305, MAE: 3713.0303, NMAE: 56.5248, R^2: 0.2715\n",
      "Epoch [801/1500]\n",
      "Train Loss: 2698.6849\n",
      "Val Loss: 3764.6349, MAE: 3765.1348, NMAE: 57.3180, R^2: 0.2554\n",
      "Epoch [802/1500]\n",
      "Train Loss: 2734.5754\n",
      "Val Loss: 3773.4342, MAE: 3773.9341, NMAE: 57.4519, R^2: 0.2544\n",
      "Epoch [803/1500]\n",
      "Train Loss: 2660.0708\n",
      "Val Loss: 3779.7346, MAE: 3780.2346, NMAE: 57.5478, R^2: 0.2428\n",
      "Epoch [804/1500]\n",
      "Train Loss: 2652.5550\n",
      "Val Loss: 3857.4170, MAE: 3857.9167, NMAE: 58.7304, R^2: 0.2294\n",
      "Epoch [805/1500]\n",
      "Train Loss: 2684.6491\n",
      "Val Loss: 3841.0718, MAE: 3841.5718, NMAE: 58.4816, R^2: 0.2242\n",
      "Epoch [806/1500]\n",
      "Train Loss: 2651.2158\n",
      "Val Loss: 3819.7360, MAE: 3820.2358, NMAE: 58.1568, R^2: 0.2359\n",
      "Epoch [807/1500]\n",
      "Train Loss: 2725.7590\n",
      "Val Loss: 3766.5487, MAE: 3767.0488, NMAE: 57.3471, R^2: 0.2414\n",
      "Epoch [808/1500]\n",
      "Train Loss: 2640.6154\n",
      "Val Loss: 3759.8014, MAE: 3760.3013, NMAE: 57.2444, R^2: 0.2611\n",
      "Epoch [809/1500]\n",
      "Train Loss: 2594.4160\n",
      "Val Loss: 3807.3766, MAE: 3807.8767, NMAE: 57.9686, R^2: 0.2312\n",
      "Epoch [810/1500]\n",
      "Train Loss: 2643.8372\n",
      "Val Loss: 3765.5625, MAE: 3766.0623, NMAE: 57.3321, R^2: 0.2531\n",
      "Epoch [811/1500]\n",
      "Train Loss: 2588.2167\n",
      "Val Loss: 3785.9746, MAE: 3786.4744, NMAE: 57.6428, R^2: 0.2409\n",
      "Epoch [812/1500]\n",
      "Train Loss: 2597.0644\n",
      "Val Loss: 3774.4512, MAE: 3774.9509, NMAE: 57.4674, R^2: 0.2542\n",
      "Epoch [813/1500]\n",
      "Train Loss: 2542.0213\n",
      "Val Loss: 3750.3570, MAE: 3750.8569, NMAE: 57.1006, R^2: 0.2627\n",
      "Epoch [814/1500]\n",
      "Train Loss: 2677.8673\n",
      "Val Loss: 3739.1752, MAE: 3739.6748, NMAE: 56.9304, R^2: 0.2603\n",
      "Epoch [815/1500]\n",
      "Train Loss: 2641.3696\n",
      "Val Loss: 3704.7762, MAE: 3705.2759, NMAE: 56.4067, R^2: 0.2918\n",
      "Epoch [816/1500]\n",
      "Train Loss: 2651.5386\n",
      "Val Loss: 3704.9320, MAE: 3705.4316, NMAE: 56.4091, R^2: 0.2857\n",
      "Epoch [817/1500]\n",
      "Train Loss: 2635.1454\n",
      "Val Loss: 3706.1194, MAE: 3706.6194, NMAE: 56.4272, R^2: 0.2897\n",
      "Epoch [818/1500]\n",
      "Train Loss: 2645.7152\n",
      "Val Loss: 3671.9589, MAE: 3672.4587, NMAE: 55.9071, R^2: 0.2932\n",
      "Epoch [819/1500]\n",
      "Train Loss: 2681.1642\n",
      "Val Loss: 3663.4664, MAE: 3663.9663, NMAE: 55.7778, R^2: 0.2956\n",
      "Epoch [820/1500]\n",
      "Train Loss: 2630.0931\n",
      "Val Loss: 3726.5862, MAE: 3727.0862, NMAE: 56.7387, R^2: 0.2807\n",
      "Epoch [821/1500]\n",
      "Train Loss: 2671.1923\n",
      "Val Loss: 3706.7946, MAE: 3707.2947, NMAE: 56.4375, R^2: 0.2790\n",
      "Epoch [822/1500]\n",
      "Train Loss: 2589.5008\n",
      "Val Loss: 3749.5448, MAE: 3750.0449, NMAE: 57.0883, R^2: 0.2704\n",
      "Epoch [823/1500]\n",
      "Train Loss: 2580.1790\n",
      "Val Loss: 3718.3126, MAE: 3718.8127, NMAE: 56.6128, R^2: 0.2939\n",
      "Epoch [824/1500]\n",
      "Train Loss: 2587.9849\n",
      "Val Loss: 3717.2158, MAE: 3717.7156, NMAE: 56.5961, R^2: 0.2940\n",
      "Epoch [825/1500]\n",
      "Train Loss: 2659.1838\n",
      "Val Loss: 3714.7618, MAE: 3715.2612, NMAE: 56.5587, R^2: 0.3013\n",
      "Epoch [826/1500]\n",
      "Train Loss: 2629.0538\n",
      "Val Loss: 3711.9318, MAE: 3712.4316, NMAE: 56.5157, R^2: 0.2866\n",
      "Epoch [827/1500]\n",
      "Train Loss: 2636.4242\n",
      "Val Loss: 3712.8186, MAE: 3713.3186, NMAE: 56.5292, R^2: 0.2893\n",
      "Epoch [828/1500]\n",
      "Train Loss: 2627.4583\n",
      "Val Loss: 3716.1018, MAE: 3716.6016, NMAE: 56.5791, R^2: 0.2805\n",
      "Epoch [829/1500]\n",
      "Train Loss: 2698.9560\n",
      "Val Loss: 3715.9603, MAE: 3716.4602, NMAE: 56.5770, R^2: 0.2886\n",
      "Epoch [830/1500]\n",
      "Train Loss: 2714.2085\n",
      "Val Loss: 3711.9370, MAE: 3712.4365, NMAE: 56.5157, R^2: 0.2782\n",
      "Epoch [831/1500]\n",
      "Train Loss: 2716.5595\n",
      "Val Loss: 3742.3365, MAE: 3742.8362, NMAE: 56.9785, R^2: 0.2776\n",
      "Epoch [832/1500]\n",
      "Train Loss: 2718.9364\n",
      "Val Loss: 3781.7948, MAE: 3782.2947, NMAE: 57.5792, R^2: 0.2588\n",
      "Epoch [833/1500]\n",
      "Train Loss: 2690.9971\n",
      "Val Loss: 3759.5990, MAE: 3760.0989, NMAE: 57.2413, R^2: 0.2561\n",
      "Epoch [834/1500]\n",
      "Train Loss: 2664.1104\n",
      "Val Loss: 3801.0133, MAE: 3801.5132, NMAE: 57.8718, R^2: 0.2486\n",
      "Epoch [835/1500]\n",
      "Train Loss: 2714.8763\n",
      "Val Loss: 3840.3542, MAE: 3840.8540, NMAE: 58.4707, R^2: 0.2539\n",
      "Epoch [836/1500]\n",
      "Train Loss: 2661.3331\n",
      "Val Loss: 3844.3815, MAE: 3844.8816, NMAE: 58.5320, R^2: 0.2431\n",
      "Epoch [837/1500]\n",
      "Train Loss: 2701.9994\n",
      "Val Loss: 3767.5811, MAE: 3768.0808, NMAE: 57.3628, R^2: 0.2554\n",
      "Epoch [838/1500]\n",
      "Train Loss: 2631.0754\n",
      "Val Loss: 3787.9004, MAE: 3788.4001, NMAE: 57.6721, R^2: 0.2527\n",
      "Epoch [839/1500]\n",
      "Train Loss: 2684.2889\n",
      "Val Loss: 3807.4596, MAE: 3807.9590, NMAE: 57.9699, R^2: 0.2419\n",
      "Epoch [840/1500]\n",
      "Train Loss: 2665.4043\n",
      "Val Loss: 3851.1944, MAE: 3851.6946, NMAE: 58.6357, R^2: 0.2275\n",
      "Epoch [841/1500]\n",
      "Train Loss: 2797.2709\n",
      "Val Loss: 3892.6640, MAE: 3893.1641, NMAE: 59.2670, R^2: 0.2355\n",
      "Epoch [842/1500]\n",
      "Train Loss: 2696.6280\n",
      "Val Loss: 3784.0006, MAE: 3784.5005, NMAE: 57.6128, R^2: 0.2673\n",
      "Epoch [843/1500]\n",
      "Train Loss: 2755.0164\n",
      "Val Loss: 3833.1097, MAE: 3833.6096, NMAE: 58.3604, R^2: 0.2459\n",
      "Epoch [844/1500]\n",
      "Train Loss: 2743.7170\n",
      "Val Loss: 3827.9493, MAE: 3828.4490, NMAE: 58.2818, R^2: 0.2386\n",
      "Epoch [845/1500]\n",
      "Train Loss: 2741.0213\n",
      "Val Loss: 3814.1176, MAE: 3814.6174, NMAE: 58.0713, R^2: 0.2481\n",
      "Epoch [846/1500]\n",
      "Train Loss: 2725.9089\n",
      "Val Loss: 3745.9320, MAE: 3746.4319, NMAE: 57.0333, R^2: 0.2639\n",
      "Epoch [847/1500]\n",
      "Train Loss: 2735.4284\n",
      "Val Loss: 3746.5184, MAE: 3747.0178, NMAE: 57.0422, R^2: 0.2738\n",
      "Epoch [848/1500]\n",
      "Train Loss: 2766.9741\n",
      "Val Loss: 3799.3536, MAE: 3799.8535, NMAE: 57.8465, R^2: 0.2625\n",
      "Epoch [849/1500]\n",
      "Train Loss: 2707.1381\n",
      "Val Loss: 3763.8291, MAE: 3764.3289, NMAE: 57.3057, R^2: 0.2660\n",
      "Epoch [850/1500]\n",
      "Train Loss: 2759.9584\n",
      "Val Loss: 3805.8687, MAE: 3806.3684, NMAE: 57.9457, R^2: 0.2659\n",
      "Epoch [851/1500]\n",
      "Train Loss: 2752.1336\n",
      "Val Loss: 3788.6389, MAE: 3789.1384, NMAE: 57.6834, R^2: 0.2525\n",
      "Epoch [852/1500]\n",
      "Train Loss: 2754.7646\n",
      "Val Loss: 3796.2908, MAE: 3796.7905, NMAE: 57.7999, R^2: 0.2496\n",
      "Epoch [853/1500]\n",
      "Train Loss: 2799.7048\n",
      "Val Loss: 3822.0652, MAE: 3822.5649, NMAE: 58.1923, R^2: 0.2414\n",
      "Epoch [854/1500]\n",
      "Train Loss: 2772.3725\n",
      "Val Loss: 3819.5527, MAE: 3820.0527, NMAE: 58.1540, R^2: 0.2473\n",
      "Epoch [855/1500]\n",
      "Train Loss: 2694.9560\n",
      "Val Loss: 3830.5312, MAE: 3831.0312, NMAE: 58.3211, R^2: 0.2506\n",
      "Epoch [856/1500]\n",
      "Train Loss: 2738.1672\n",
      "Val Loss: 3806.6294, MAE: 3807.1292, NMAE: 57.9573, R^2: 0.2572\n",
      "Epoch [857/1500]\n",
      "Train Loss: 2725.4711\n",
      "Val Loss: 3819.7885, MAE: 3820.2881, NMAE: 58.1576, R^2: 0.2526\n",
      "Epoch [858/1500]\n",
      "Train Loss: 2722.5111\n",
      "Val Loss: 3835.1637, MAE: 3835.6636, NMAE: 58.3917, R^2: 0.2415\n",
      "Epoch [859/1500]\n",
      "Train Loss: 2727.4099\n",
      "Val Loss: 3820.5105, MAE: 3821.0103, NMAE: 58.1686, R^2: 0.2575\n",
      "Epoch [860/1500]\n",
      "Train Loss: 2749.3865\n",
      "Val Loss: 3793.3122, MAE: 3793.8118, NMAE: 57.7545, R^2: 0.2561\n",
      "Epoch [861/1500]\n",
      "Train Loss: 2763.9676\n",
      "Val Loss: 3878.8629, MAE: 3879.3628, NMAE: 59.0569, R^2: 0.2391\n",
      "Epoch [862/1500]\n",
      "Train Loss: 2721.0815\n",
      "Val Loss: 3861.6632, MAE: 3862.1633, NMAE: 58.7951, R^2: 0.2391\n",
      "Epoch [863/1500]\n",
      "Train Loss: 2712.9251\n",
      "Val Loss: 3913.4161, MAE: 3913.9158, NMAE: 59.5829, R^2: 0.2189\n",
      "Epoch [864/1500]\n",
      "Train Loss: 2715.3524\n",
      "Val Loss: 3810.5750, MAE: 3811.0747, NMAE: 58.0173, R^2: 0.2501\n",
      "Epoch [865/1500]\n",
      "Train Loss: 2738.2521\n",
      "Val Loss: 3851.3744, MAE: 3851.8743, NMAE: 58.6384, R^2: 0.2461\n",
      "Epoch [866/1500]\n",
      "Train Loss: 2780.3884\n",
      "Val Loss: 3834.7152, MAE: 3835.2151, NMAE: 58.3848, R^2: 0.2432\n",
      "Epoch [867/1500]\n",
      "Train Loss: 2696.6590\n",
      "Val Loss: 3839.8152, MAE: 3840.3149, NMAE: 58.4625, R^2: 0.2432\n",
      "Epoch [868/1500]\n",
      "Train Loss: 2694.0754\n",
      "Val Loss: 3826.8985, MAE: 3827.3982, NMAE: 58.2658, R^2: 0.2473\n",
      "Epoch [869/1500]\n",
      "Train Loss: 2729.5307\n",
      "Val Loss: 3789.0042, MAE: 3789.5039, NMAE: 57.6890, R^2: 0.2671\n",
      "Epoch [870/1500]\n",
      "Train Loss: 2752.6400\n",
      "Val Loss: 3844.4109, MAE: 3844.9109, NMAE: 58.5324, R^2: 0.2502\n",
      "Epoch [871/1500]\n",
      "Train Loss: 2680.0502\n",
      "Val Loss: 3788.8518, MAE: 3789.3518, NMAE: 57.6866, R^2: 0.2665\n",
      "Epoch [872/1500]\n",
      "Train Loss: 2652.3664\n",
      "Val Loss: 3824.9721, MAE: 3825.4722, NMAE: 58.2365, R^2: 0.2439\n",
      "Epoch [873/1500]\n",
      "Train Loss: 2686.5392\n",
      "Val Loss: 3833.1555, MAE: 3833.6553, NMAE: 58.3611, R^2: 0.2494\n",
      "Epoch [874/1500]\n",
      "Train Loss: 2667.3214\n",
      "Val Loss: 3837.3313, MAE: 3837.8313, NMAE: 58.4247, R^2: 0.2514\n",
      "Epoch [875/1500]\n",
      "Train Loss: 2701.2939\n",
      "Val Loss: 3757.1125, MAE: 3757.6123, NMAE: 57.2035, R^2: 0.2617\n",
      "Epoch [876/1500]\n",
      "Train Loss: 2665.0583\n",
      "Val Loss: 3835.9762, MAE: 3836.4761, NMAE: 58.4040, R^2: 0.2435\n",
      "Epoch [877/1500]\n",
      "Train Loss: 2768.5589\n",
      "Val Loss: 3862.3297, MAE: 3862.8298, NMAE: 58.8052, R^2: 0.2419\n",
      "Epoch [878/1500]\n",
      "Train Loss: 2736.2245\n",
      "Val Loss: 3826.7841, MAE: 3827.2842, NMAE: 58.2641, R^2: 0.2407\n",
      "Epoch [879/1500]\n",
      "Train Loss: 2715.0718\n",
      "Val Loss: 3813.4234, MAE: 3813.9233, NMAE: 58.0607, R^2: 0.2501\n",
      "Epoch [880/1500]\n",
      "Train Loss: 2712.3640\n",
      "Val Loss: 3800.4037, MAE: 3800.9036, NMAE: 57.8625, R^2: 0.2592\n",
      "Epoch [881/1500]\n",
      "Train Loss: 2653.3277\n",
      "Val Loss: 3862.7548, MAE: 3863.2546, NMAE: 58.8117, R^2: 0.2331\n",
      "Epoch [882/1500]\n",
      "Train Loss: 2697.4759\n",
      "Val Loss: 3838.1130, MAE: 3838.6125, NMAE: 58.4366, R^2: 0.2561\n",
      "Epoch [883/1500]\n",
      "Train Loss: 2635.0493\n",
      "Val Loss: 3835.7722, MAE: 3836.2722, NMAE: 58.4009, R^2: 0.2584\n",
      "Epoch [884/1500]\n",
      "Train Loss: 2720.0526\n",
      "Val Loss: 3836.9482, MAE: 3837.4482, NMAE: 58.4188, R^2: 0.2494\n",
      "Epoch [885/1500]\n",
      "Train Loss: 2693.6125\n",
      "Val Loss: 3865.1231, MAE: 3865.6230, NMAE: 58.8477, R^2: 0.2256\n",
      "Epoch [886/1500]\n",
      "Train Loss: 2715.8810\n",
      "Val Loss: 3909.3484, MAE: 3909.8484, NMAE: 59.5210, R^2: 0.2124\n",
      "Epoch [887/1500]\n",
      "Train Loss: 2685.1526\n",
      "Val Loss: 3831.5656, MAE: 3832.0652, NMAE: 58.3369, R^2: 0.2405\n",
      "Epoch [888/1500]\n",
      "Train Loss: 2651.1273\n",
      "Val Loss: 3831.7711, MAE: 3832.2710, NMAE: 58.3400, R^2: 0.2550\n",
      "Epoch [889/1500]\n",
      "Train Loss: 2632.5399\n",
      "Val Loss: 3908.0898, MAE: 3908.5894, NMAE: 59.5018, R^2: 0.2174\n",
      "Epoch [890/1500]\n",
      "Train Loss: 2659.0145\n",
      "Val Loss: 3889.5037, MAE: 3890.0032, NMAE: 59.2189, R^2: 0.2040\n",
      "Epoch [891/1500]\n",
      "Train Loss: 2671.8360\n",
      "Val Loss: 3964.7813, MAE: 3965.2815, NMAE: 60.3649, R^2: 0.2114\n",
      "Epoch [892/1500]\n",
      "Train Loss: 2677.5781\n",
      "Val Loss: 3842.1941, MAE: 3842.6938, NMAE: 58.4987, R^2: 0.2585\n",
      "Epoch [893/1500]\n",
      "Train Loss: 2726.6043\n",
      "Val Loss: 3881.2595, MAE: 3881.7595, NMAE: 59.0934, R^2: 0.2433\n",
      "Epoch [894/1500]\n",
      "Train Loss: 2703.4958\n",
      "Val Loss: 3930.8050, MAE: 3931.3049, NMAE: 59.8476, R^2: 0.2148\n",
      "Epoch [895/1500]\n",
      "Train Loss: 2730.6461\n",
      "Val Loss: 3954.5363, MAE: 3955.0359, NMAE: 60.2089, R^2: 0.2119\n",
      "Epoch [896/1500]\n",
      "Train Loss: 2692.6506\n",
      "Val Loss: 3857.1539, MAE: 3857.6543, NMAE: 58.7264, R^2: 0.2304\n",
      "Epoch [897/1500]\n",
      "Train Loss: 2688.7551\n",
      "Val Loss: 3846.2729, MAE: 3846.7729, NMAE: 58.5608, R^2: 0.2417\n",
      "Epoch [898/1500]\n",
      "Train Loss: 2751.7891\n",
      "Val Loss: 3797.4551, MAE: 3797.9548, NMAE: 57.8176, R^2: 0.2655\n",
      "Epoch [899/1500]\n",
      "Train Loss: 2681.0796\n",
      "Val Loss: 3828.0547, MAE: 3828.5544, NMAE: 58.2834, R^2: 0.2511\n",
      "Epoch [900/1500]\n",
      "Train Loss: 2672.7918\n",
      "Val Loss: 3801.0747, MAE: 3801.5747, NMAE: 57.8727, R^2: 0.2598\n",
      "Epoch [901/1500]\n",
      "Train Loss: 2620.6391\n",
      "Val Loss: 3818.2102, MAE: 3818.7100, NMAE: 58.1336, R^2: 0.2465\n",
      "Epoch [902/1500]\n",
      "Train Loss: 2683.7461\n",
      "Val Loss: 3771.1197, MAE: 3771.6196, NMAE: 57.4167, R^2: 0.2610\n",
      "Epoch [903/1500]\n",
      "Train Loss: 2689.5528\n",
      "Val Loss: 3802.5645, MAE: 3803.0645, NMAE: 57.8954, R^2: 0.2568\n",
      "Epoch [904/1500]\n",
      "Train Loss: 2643.5353\n",
      "Val Loss: 3850.0804, MAE: 3850.5803, NMAE: 58.6187, R^2: 0.2472\n",
      "Epoch [905/1500]\n",
      "Train Loss: 2673.4944\n",
      "Val Loss: 3827.5915, MAE: 3828.0916, NMAE: 58.2764, R^2: 0.2583\n",
      "Epoch [906/1500]\n",
      "Train Loss: 2709.9677\n",
      "Val Loss: 3789.6422, MAE: 3790.1421, NMAE: 57.6987, R^2: 0.2639\n",
      "Epoch [907/1500]\n",
      "Train Loss: 2698.5363\n",
      "Val Loss: 3758.7951, MAE: 3759.2949, NMAE: 57.2291, R^2: 0.2631\n",
      "Epoch [908/1500]\n",
      "Train Loss: 2684.6158\n",
      "Val Loss: 3807.3829, MAE: 3807.8828, NMAE: 57.9687, R^2: 0.2757\n",
      "Epoch [909/1500]\n",
      "Train Loss: 2676.6931\n",
      "Val Loss: 3807.3579, MAE: 3807.8579, NMAE: 57.9684, R^2: 0.2692\n",
      "Epoch [910/1500]\n",
      "Train Loss: 2721.9992\n",
      "Val Loss: 3749.5204, MAE: 3750.0205, NMAE: 57.0879, R^2: 0.2821\n",
      "Epoch [911/1500]\n",
      "Train Loss: 2619.6171\n",
      "Val Loss: 3726.8723, MAE: 3727.3721, NMAE: 56.7431, R^2: 0.2840\n",
      "Epoch [912/1500]\n",
      "Train Loss: 2665.3206\n",
      "Val Loss: 3790.8870, MAE: 3791.3870, NMAE: 57.7176, R^2: 0.2612\n",
      "Epoch [913/1500]\n",
      "Train Loss: 2673.0058\n",
      "Val Loss: 3724.3944, MAE: 3724.8943, NMAE: 56.7054, R^2: 0.2768\n",
      "Epoch [914/1500]\n",
      "Train Loss: 2665.8396\n",
      "Val Loss: 3776.6129, MAE: 3777.1128, NMAE: 57.5003, R^2: 0.2634\n",
      "Epoch [915/1500]\n",
      "Train Loss: 2701.7552\n",
      "Val Loss: 3728.2586, MAE: 3728.7585, NMAE: 56.7642, R^2: 0.2761\n",
      "Epoch [916/1500]\n",
      "Train Loss: 2721.2051\n",
      "Val Loss: 3782.8728, MAE: 3783.3726, NMAE: 57.5956, R^2: 0.2634\n",
      "Epoch [917/1500]\n",
      "Train Loss: 2699.6186\n",
      "Val Loss: 3791.5688, MAE: 3792.0688, NMAE: 57.7280, R^2: 0.2737\n",
      "Epoch [918/1500]\n",
      "Train Loss: 2729.7786\n",
      "Val Loss: 3762.6267, MAE: 3763.1265, NMAE: 57.2874, R^2: 0.2715\n",
      "Epoch [919/1500]\n",
      "Train Loss: 2681.0609\n",
      "Val Loss: 3777.6818, MAE: 3778.1816, NMAE: 57.5166, R^2: 0.2621\n",
      "Epoch [920/1500]\n",
      "Train Loss: 2693.0753\n",
      "Val Loss: 3744.4930, MAE: 3744.9929, NMAE: 57.0113, R^2: 0.2721\n",
      "Epoch [921/1500]\n",
      "Train Loss: 2690.5777\n",
      "Val Loss: 3749.3049, MAE: 3749.8047, NMAE: 57.0846, R^2: 0.2780\n",
      "Epoch [922/1500]\n",
      "Train Loss: 2774.1480\n",
      "Val Loss: 3711.7505, MAE: 3712.2502, NMAE: 56.5129, R^2: 0.2941\n",
      "Epoch [923/1500]\n",
      "Train Loss: 2744.3332\n",
      "Val Loss: 3794.2513, MAE: 3794.7512, NMAE: 57.7688, R^2: 0.2628\n",
      "Epoch [924/1500]\n",
      "Train Loss: 2758.9595\n",
      "Val Loss: 3869.6130, MAE: 3870.1125, NMAE: 58.9161, R^2: 0.2370\n",
      "Epoch [925/1500]\n",
      "Train Loss: 2761.8962\n",
      "Val Loss: 3912.5386, MAE: 3913.0381, NMAE: 59.5696, R^2: 0.2093\n",
      "Epoch [926/1500]\n",
      "Train Loss: 2837.6369\n",
      "Val Loss: 3795.1721, MAE: 3795.6719, NMAE: 57.7828, R^2: 0.2560\n",
      "Epoch [927/1500]\n",
      "Train Loss: 2770.8894\n",
      "Val Loss: 3839.6757, MAE: 3840.1755, NMAE: 58.4603, R^2: 0.2417\n",
      "Epoch [928/1500]\n",
      "Train Loss: 2779.7098\n",
      "Val Loss: 3937.8639, MAE: 3938.3638, NMAE: 59.9551, R^2: 0.2335\n",
      "Epoch [929/1500]\n",
      "Train Loss: 2798.5420\n",
      "Val Loss: 3872.8747, MAE: 3873.3748, NMAE: 58.9657, R^2: 0.2358\n",
      "Epoch [930/1500]\n",
      "Train Loss: 2755.1869\n",
      "Val Loss: 3859.7813, MAE: 3860.2810, NMAE: 58.7664, R^2: 0.2439\n",
      "Epoch [931/1500]\n",
      "Train Loss: 2806.4118\n",
      "Val Loss: 3786.7635, MAE: 3787.2632, NMAE: 57.6548, R^2: 0.2793\n",
      "Epoch [932/1500]\n",
      "Train Loss: 2789.5006\n",
      "Val Loss: 3854.5922, MAE: 3855.0920, NMAE: 58.6874, R^2: 0.2391\n",
      "Epoch [933/1500]\n",
      "Train Loss: 2771.5568\n",
      "Val Loss: 3811.4636, MAE: 3811.9634, NMAE: 58.0309, R^2: 0.2618\n",
      "Epoch [934/1500]\n",
      "Train Loss: 2673.5435\n",
      "Val Loss: 3790.2822, MAE: 3790.7822, NMAE: 57.7084, R^2: 0.2584\n",
      "Epoch [935/1500]\n",
      "Train Loss: 2733.2728\n",
      "Val Loss: 3783.6895, MAE: 3784.1895, NMAE: 57.6080, R^2: 0.2639\n",
      "Epoch [936/1500]\n",
      "Train Loss: 2702.8490\n",
      "Val Loss: 3799.9795, MAE: 3800.4792, NMAE: 57.8560, R^2: 0.2689\n",
      "Epoch [937/1500]\n",
      "Train Loss: 2763.2804\n",
      "Val Loss: 3898.6406, MAE: 3899.1401, NMAE: 59.3580, R^2: 0.2441\n",
      "Epoch [938/1500]\n",
      "Train Loss: 2755.4309\n",
      "Val Loss: 3909.3778, MAE: 3909.8777, NMAE: 59.5214, R^2: 0.2228\n",
      "Epoch [939/1500]\n",
      "Train Loss: 2845.3050\n",
      "Val Loss: 3909.8382, MAE: 3910.3384, NMAE: 59.5285, R^2: 0.2442\n",
      "Epoch [940/1500]\n",
      "Train Loss: 2785.6843\n",
      "Val Loss: 3909.3035, MAE: 3909.8032, NMAE: 59.5203, R^2: 0.2378\n",
      "Epoch [941/1500]\n",
      "Train Loss: 2769.6820\n",
      "Val Loss: 3946.0473, MAE: 3946.5471, NMAE: 60.0797, R^2: 0.2242\n",
      "Epoch [942/1500]\n",
      "Train Loss: 2788.8414\n",
      "Val Loss: 3889.7403, MAE: 3890.2400, NMAE: 59.2225, R^2: 0.2234\n",
      "Epoch [943/1500]\n",
      "Train Loss: 2791.2280\n",
      "Val Loss: 3887.6825, MAE: 3888.1826, NMAE: 59.1912, R^2: 0.2476\n",
      "Epoch [944/1500]\n",
      "Train Loss: 2738.5703\n",
      "Val Loss: 3832.3204, MAE: 3832.8206, NMAE: 58.3484, R^2: 0.2342\n",
      "Epoch [945/1500]\n",
      "Train Loss: 2704.4694\n",
      "Val Loss: 3858.8179, MAE: 3859.3176, NMAE: 58.7518, R^2: 0.2362\n",
      "Epoch [946/1500]\n",
      "Train Loss: 2791.4445\n",
      "Val Loss: 3840.6242, MAE: 3841.1240, NMAE: 58.4748, R^2: 0.2446\n",
      "Epoch [947/1500]\n",
      "Train Loss: 2792.7912\n",
      "Val Loss: 3830.4249, MAE: 3830.9248, NMAE: 58.3195, R^2: 0.2343\n",
      "Epoch [948/1500]\n",
      "Train Loss: 2767.7138\n",
      "Val Loss: 3906.0923, MAE: 3906.5923, NMAE: 59.4714, R^2: 0.2096\n",
      "Epoch [949/1500]\n",
      "Train Loss: 2812.5542\n",
      "Val Loss: 3878.2790, MAE: 3878.7788, NMAE: 59.0480, R^2: 0.2200\n",
      "Epoch [950/1500]\n",
      "Train Loss: 2781.4403\n",
      "Val Loss: 3924.4620, MAE: 3924.9619, NMAE: 59.7511, R^2: 0.1961\n",
      "Epoch [951/1500]\n",
      "Train Loss: 2749.1166\n",
      "Val Loss: 3887.7509, MAE: 3888.2510, NMAE: 59.1922, R^2: 0.2405\n",
      "Epoch [952/1500]\n",
      "Train Loss: 2844.3202\n",
      "Val Loss: 3894.8918, MAE: 3895.3918, NMAE: 59.3009, R^2: 0.2234\n",
      "Epoch [953/1500]\n",
      "Train Loss: 2808.2566\n",
      "Val Loss: 3884.9664, MAE: 3885.4663, NMAE: 59.1498, R^2: 0.2291\n",
      "Epoch [954/1500]\n",
      "Train Loss: 2838.7545\n",
      "Val Loss: 3895.5050, MAE: 3896.0046, NMAE: 59.3103, R^2: 0.2176\n",
      "Epoch [955/1500]\n",
      "Train Loss: 2992.5395\n",
      "Val Loss: 4004.1680, MAE: 4004.6675, NMAE: 60.9645, R^2: 0.1837\n",
      "Epoch [956/1500]\n",
      "Train Loss: 2838.6388\n",
      "Val Loss: 3918.0472, MAE: 3918.5471, NMAE: 59.6534, R^2: 0.2104\n",
      "Epoch [957/1500]\n",
      "Train Loss: 2800.8007\n",
      "Val Loss: 3936.1568, MAE: 3936.6565, NMAE: 59.9291, R^2: 0.2063\n",
      "Epoch [958/1500]\n",
      "Train Loss: 2813.2176\n",
      "Val Loss: 3953.9069, MAE: 3954.4070, NMAE: 60.1993, R^2: 0.2056\n",
      "Epoch [959/1500]\n",
      "Train Loss: 2726.5506\n",
      "Val Loss: 3894.2471, MAE: 3894.7466, NMAE: 59.2911, R^2: 0.2103\n",
      "Epoch [960/1500]\n",
      "Train Loss: 2797.8089\n",
      "Val Loss: 3889.8789, MAE: 3890.3789, NMAE: 59.2246, R^2: 0.2116\n",
      "Epoch [961/1500]\n",
      "Train Loss: 2740.8581\n",
      "Val Loss: 3922.9593, MAE: 3923.4592, NMAE: 59.7282, R^2: 0.2169\n",
      "Epoch [962/1500]\n",
      "Train Loss: 2833.3432\n",
      "Val Loss: 3862.4006, MAE: 3862.9001, NMAE: 58.8063, R^2: 0.2444\n",
      "Epoch [963/1500]\n",
      "Train Loss: 2743.2698\n",
      "Val Loss: 3871.9200, MAE: 3872.4197, NMAE: 58.9512, R^2: 0.2281\n",
      "Epoch [964/1500]\n",
      "Train Loss: 2841.3588\n",
      "Val Loss: 3895.6189, MAE: 3896.1187, NMAE: 59.3120, R^2: 0.2218\n",
      "Epoch [965/1500]\n",
      "Train Loss: 2847.2321\n",
      "Val Loss: 3903.1421, MAE: 3903.6418, NMAE: 59.4265, R^2: 0.2184\n",
      "Epoch [966/1500]\n",
      "Train Loss: 2864.1492\n",
      "Val Loss: 3896.9744, MAE: 3897.4744, NMAE: 59.3326, R^2: 0.2259\n",
      "Epoch [967/1500]\n",
      "Train Loss: 2782.3026\n",
      "Val Loss: 3946.0968, MAE: 3946.5967, NMAE: 60.0804, R^2: 0.2082\n",
      "Epoch [968/1500]\n",
      "Train Loss: 2840.8665\n",
      "Val Loss: 3962.2017, MAE: 3962.7017, NMAE: 60.3256, R^2: 0.2021\n",
      "Epoch [969/1500]\n",
      "Train Loss: 2881.8571\n",
      "Val Loss: 3973.4819, MAE: 3973.9817, NMAE: 60.4973, R^2: 0.2082\n",
      "Epoch [970/1500]\n",
      "Train Loss: 2802.1614\n",
      "Val Loss: 3981.6222, MAE: 3982.1218, NMAE: 60.6212, R^2: 0.2032\n",
      "Epoch [971/1500]\n",
      "Train Loss: 2762.1302\n",
      "Val Loss: 3989.2437, MAE: 3989.7439, NMAE: 60.7373, R^2: 0.2043\n",
      "Epoch [972/1500]\n",
      "Train Loss: 2718.2624\n",
      "Val Loss: 3959.7757, MAE: 3960.2759, NMAE: 60.2887, R^2: 0.2042\n",
      "Epoch [973/1500]\n",
      "Train Loss: 2765.4543\n",
      "Val Loss: 3955.8920, MAE: 3956.3918, NMAE: 60.2295, R^2: 0.2003\n",
      "Epoch [974/1500]\n",
      "Train Loss: 2811.1434\n",
      "Val Loss: 3915.6286, MAE: 3916.1282, NMAE: 59.6166, R^2: 0.2243\n",
      "Epoch [975/1500]\n",
      "Train Loss: 2856.0356\n",
      "Val Loss: 3929.6091, MAE: 3930.1089, NMAE: 59.8294, R^2: 0.2253\n",
      "Epoch [976/1500]\n",
      "Train Loss: 2813.4157\n",
      "Val Loss: 3906.6785, MAE: 3907.1785, NMAE: 59.4804, R^2: 0.2333\n",
      "Epoch [977/1500]\n",
      "Train Loss: 2826.7157\n",
      "Val Loss: 3916.7864, MAE: 3917.2859, NMAE: 59.6342, R^2: 0.2190\n",
      "Epoch [978/1500]\n",
      "Train Loss: 2836.7771\n",
      "Val Loss: 3947.4388, MAE: 3947.9390, NMAE: 60.1009, R^2: 0.2074\n",
      "Epoch [979/1500]\n",
      "Train Loss: 2829.0361\n",
      "Val Loss: 3885.0599, MAE: 3885.5596, NMAE: 59.1512, R^2: 0.2189\n",
      "Epoch [980/1500]\n",
      "Train Loss: 2802.3628\n",
      "Val Loss: 3946.3650, MAE: 3946.8647, NMAE: 60.0845, R^2: 0.1948\n",
      "Epoch [981/1500]\n",
      "Train Loss: 2819.7018\n",
      "Val Loss: 4009.5061, MAE: 4010.0059, NMAE: 61.0457, R^2: 0.1857\n",
      "Epoch [982/1500]\n",
      "Train Loss: 2825.2879\n",
      "Val Loss: 4022.5433, MAE: 4023.0432, NMAE: 61.2442, R^2: 0.1835\n",
      "Epoch [983/1500]\n",
      "Train Loss: 2832.7467\n",
      "Val Loss: 3943.0331, MAE: 3943.5330, NMAE: 60.0338, R^2: 0.1959\n",
      "Epoch [984/1500]\n",
      "Train Loss: 2852.8761\n",
      "Val Loss: 3960.6445, MAE: 3961.1443, NMAE: 60.3019, R^2: 0.2064\n",
      "Epoch [985/1500]\n",
      "Train Loss: 2830.6031\n",
      "Val Loss: 3963.6930, MAE: 3964.1931, NMAE: 60.3483, R^2: 0.2000\n",
      "Epoch [986/1500]\n",
      "Train Loss: 2830.5743\n",
      "Val Loss: 3977.6406, MAE: 3978.1401, NMAE: 60.5606, R^2: 0.1946\n",
      "Epoch [987/1500]\n",
      "Train Loss: 2788.8773\n",
      "Val Loss: 3980.7703, MAE: 3981.2698, NMAE: 60.6083, R^2: 0.1940\n",
      "Epoch [988/1500]\n",
      "Train Loss: 2806.4981\n",
      "Val Loss: 3939.1794, MAE: 3939.6792, NMAE: 59.9751, R^2: 0.1995\n",
      "Epoch [989/1500]\n",
      "Train Loss: 2780.0015\n",
      "Val Loss: 4023.7847, MAE: 4024.2847, NMAE: 61.2631, R^2: 0.1717\n",
      "Epoch [990/1500]\n",
      "Train Loss: 2789.9860\n",
      "Val Loss: 3999.4191, MAE: 3999.9192, NMAE: 60.8922, R^2: 0.1861\n",
      "Epoch [991/1500]\n",
      "Train Loss: 2787.2931\n",
      "Val Loss: 3955.0265, MAE: 3955.5264, NMAE: 60.2164, R^2: 0.2024\n",
      "Epoch [992/1500]\n",
      "Train Loss: 2781.9950\n",
      "Val Loss: 3964.8846, MAE: 3965.3843, NMAE: 60.3664, R^2: 0.2028\n",
      "Epoch [993/1500]\n",
      "Train Loss: 2751.6547\n",
      "Val Loss: 3959.1220, MAE: 3959.6221, NMAE: 60.2787, R^2: 0.2119\n",
      "Epoch [994/1500]\n",
      "Train Loss: 2778.2327\n",
      "Val Loss: 3989.9882, MAE: 3990.4878, NMAE: 60.7486, R^2: 0.1993\n",
      "Epoch [995/1500]\n",
      "Train Loss: 2745.5559\n",
      "Val Loss: 4001.7551, MAE: 4002.2546, NMAE: 60.9277, R^2: 0.1872\n",
      "Epoch [996/1500]\n",
      "Train Loss: 2794.6636\n",
      "Val Loss: 4000.8554, MAE: 4001.3550, NMAE: 60.9140, R^2: 0.1820\n",
      "Epoch [997/1500]\n",
      "Train Loss: 2724.5184\n",
      "Val Loss: 4043.7100, MAE: 4044.2102, NMAE: 61.5664, R^2: 0.1564\n",
      "Epoch [998/1500]\n",
      "Train Loss: 2806.1789\n",
      "Val Loss: 3987.6101, MAE: 3988.1099, NMAE: 60.7124, R^2: 0.1948\n",
      "Epoch [999/1500]\n",
      "Train Loss: 2787.6068\n",
      "Val Loss: 3973.5203, MAE: 3974.0203, NMAE: 60.4979, R^2: 0.1919\n",
      "Epoch [1000/1500]\n",
      "Train Loss: 2793.5129\n",
      "Val Loss: 4021.3498, MAE: 4021.8501, NMAE: 61.2260, R^2: 0.1743\n",
      "Epoch [1001/1500]\n",
      "Train Loss: 2795.1455\n",
      "Val Loss: 3934.5610, MAE: 3935.0608, NMAE: 59.9048, R^2: 0.1902\n",
      "Epoch [1002/1500]\n",
      "Train Loss: 2801.2241\n",
      "Val Loss: 3958.5030, MAE: 3959.0027, NMAE: 60.2693, R^2: 0.1838\n",
      "Epoch [1003/1500]\n",
      "Train Loss: 2822.9370\n",
      "Val Loss: 4018.7523, MAE: 4019.2520, NMAE: 61.1865, R^2: 0.1963\n",
      "Epoch [1004/1500]\n",
      "Train Loss: 2827.8478\n",
      "Val Loss: 3955.9897, MAE: 3956.4897, NMAE: 60.2310, R^2: 0.2126\n",
      "Epoch [1005/1500]\n",
      "Train Loss: 2851.4185\n",
      "Val Loss: 3974.9366, MAE: 3975.4363, NMAE: 60.5195, R^2: 0.1952\n",
      "Epoch [1006/1500]\n",
      "Train Loss: 2841.7685\n",
      "Val Loss: 3972.8527, MAE: 3973.3525, NMAE: 60.4877, R^2: 0.2079\n",
      "Epoch [1007/1500]\n",
      "Train Loss: 2807.1819\n",
      "Val Loss: 3908.6278, MAE: 3909.1279, NMAE: 59.5100, R^2: 0.2031\n",
      "Epoch [1008/1500]\n",
      "Train Loss: 2795.3484\n",
      "Val Loss: 3894.7442, MAE: 3895.2441, NMAE: 59.2987, R^2: 0.2198\n",
      "Epoch [1009/1500]\n",
      "Train Loss: 2790.3478\n",
      "Val Loss: 3855.4904, MAE: 3855.9902, NMAE: 58.7011, R^2: 0.2268\n",
      "Epoch [1010/1500]\n",
      "Train Loss: 2856.7712\n",
      "Val Loss: 3913.5457, MAE: 3914.0454, NMAE: 59.5849, R^2: 0.2160\n",
      "Epoch [1011/1500]\n",
      "Train Loss: 2800.4196\n",
      "Val Loss: 3925.0801, MAE: 3925.5798, NMAE: 59.7605, R^2: 0.2166\n",
      "Epoch [1012/1500]\n",
      "Train Loss: 2827.0001\n",
      "Val Loss: 3934.4837, MAE: 3934.9829, NMAE: 59.9036, R^2: 0.2221\n",
      "Epoch [1013/1500]\n",
      "Train Loss: 2830.3077\n",
      "Val Loss: 3954.4010, MAE: 3954.9006, NMAE: 60.2068, R^2: 0.2162\n",
      "Epoch [1014/1500]\n",
      "Train Loss: 2783.9173\n",
      "Val Loss: 3894.3454, MAE: 3894.8455, NMAE: 59.2926, R^2: 0.2244\n",
      "Epoch [1015/1500]\n",
      "Train Loss: 2866.8434\n",
      "Val Loss: 3904.8188, MAE: 3905.3186, NMAE: 59.4520, R^2: 0.2135\n",
      "Epoch [1016/1500]\n",
      "Train Loss: 2748.7386\n",
      "Val Loss: 3901.4197, MAE: 3901.9194, NMAE: 59.4003, R^2: 0.2257\n",
      "Epoch [1017/1500]\n",
      "Train Loss: 2784.9281\n",
      "Val Loss: 3880.2057, MAE: 3880.7053, NMAE: 59.0773, R^2: 0.2278\n",
      "Epoch [1018/1500]\n",
      "Train Loss: 2838.8514\n",
      "Val Loss: 3841.5116, MAE: 3842.0112, NMAE: 58.4883, R^2: 0.2361\n",
      "Epoch [1019/1500]\n",
      "Train Loss: 2794.9959\n",
      "Val Loss: 3824.2919, MAE: 3824.7917, NMAE: 58.2262, R^2: 0.2409\n",
      "Epoch [1020/1500]\n",
      "Train Loss: 2772.6905\n",
      "Val Loss: 3853.1238, MAE: 3853.6235, NMAE: 58.6651, R^2: 0.2362\n",
      "Epoch [1021/1500]\n",
      "Train Loss: 2811.5498\n",
      "Val Loss: 3884.3542, MAE: 3884.8542, NMAE: 59.1405, R^2: 0.2307\n",
      "Epoch [1022/1500]\n",
      "Train Loss: 2819.8266\n",
      "Val Loss: 3848.8203, MAE: 3849.3203, NMAE: 58.5996, R^2: 0.2369\n",
      "Epoch [1023/1500]\n",
      "Train Loss: 2839.7803\n",
      "Val Loss: 3813.0630, MAE: 3813.5627, NMAE: 58.0552, R^2: 0.2567\n",
      "Epoch [1024/1500]\n",
      "Train Loss: 2864.3614\n",
      "Val Loss: 3827.2160, MAE: 3827.7158, NMAE: 58.2707, R^2: 0.2548\n",
      "Epoch [1025/1500]\n",
      "Train Loss: 2833.5205\n",
      "Val Loss: 3884.2049, MAE: 3884.7048, NMAE: 59.1382, R^2: 0.2157\n",
      "Epoch [1026/1500]\n",
      "Train Loss: 2751.4094\n",
      "Val Loss: 3921.6707, MAE: 3922.1707, NMAE: 59.7086, R^2: 0.2192\n",
      "Epoch [1027/1500]\n",
      "Train Loss: 2799.9642\n",
      "Val Loss: 3943.3677, MAE: 3943.8677, NMAE: 60.0389, R^2: 0.1975\n",
      "Epoch [1028/1500]\n",
      "Train Loss: 2772.5514\n",
      "Val Loss: 3924.2757, MAE: 3924.7756, NMAE: 59.7482, R^2: 0.2037\n",
      "Epoch [1029/1500]\n",
      "Train Loss: 2810.3614\n",
      "Val Loss: 3964.8468, MAE: 3965.3462, NMAE: 60.3659, R^2: 0.2069\n",
      "Epoch [1030/1500]\n",
      "Train Loss: 2809.7130\n",
      "Val Loss: 3915.1839, MAE: 3915.6836, NMAE: 59.6098, R^2: 0.2102\n",
      "Epoch [1031/1500]\n",
      "Train Loss: 2807.5353\n",
      "Val Loss: 4006.4968, MAE: 4006.9968, NMAE: 60.9999, R^2: 0.1965\n",
      "Epoch [1032/1500]\n",
      "Train Loss: 2831.9846\n",
      "Val Loss: 4004.5648, MAE: 4005.0649, NMAE: 60.9705, R^2: 0.1732\n",
      "Epoch [1033/1500]\n",
      "Train Loss: 2835.0990\n",
      "Val Loss: 4019.7918, MAE: 4020.2915, NMAE: 61.2023, R^2: 0.1739\n",
      "Epoch [1034/1500]\n",
      "Train Loss: 2832.6276\n",
      "Val Loss: 3989.8711, MAE: 3990.3711, NMAE: 60.7468, R^2: 0.1820\n",
      "Epoch [1035/1500]\n",
      "Train Loss: 2860.9700\n",
      "Val Loss: 3961.8155, MAE: 3962.3154, NMAE: 60.3197, R^2: 0.1935\n",
      "Epoch [1036/1500]\n",
      "Train Loss: 2848.0182\n",
      "Val Loss: 3987.2578, MAE: 3987.7578, NMAE: 60.7070, R^2: 0.1759\n",
      "Epoch [1037/1500]\n",
      "Train Loss: 2786.7515\n",
      "Val Loss: 3915.6660, MAE: 3916.1660, NMAE: 59.6172, R^2: 0.2053\n",
      "Epoch [1038/1500]\n",
      "Train Loss: 2841.4999\n",
      "Val Loss: 3846.2293, MAE: 3846.7292, NMAE: 58.5601, R^2: 0.2249\n",
      "Epoch [1039/1500]\n",
      "Train Loss: 2789.9576\n",
      "Val Loss: 3884.7022, MAE: 3885.2024, NMAE: 59.1458, R^2: 0.2081\n",
      "Epoch [1040/1500]\n",
      "Train Loss: 2718.8946\n",
      "Val Loss: 3897.6140, MAE: 3898.1135, NMAE: 59.3424, R^2: 0.1996\n",
      "Epoch [1041/1500]\n",
      "Train Loss: 2802.8766\n",
      "Val Loss: 3884.8586, MAE: 3885.3586, NMAE: 59.1482, R^2: 0.2243\n",
      "Epoch [1042/1500]\n",
      "Train Loss: 2781.3375\n",
      "Val Loss: 3895.0656, MAE: 3895.5654, NMAE: 59.3036, R^2: 0.2219\n",
      "Epoch [1043/1500]\n",
      "Train Loss: 2796.0351\n",
      "Val Loss: 3952.2505, MAE: 3952.7502, NMAE: 60.1741, R^2: 0.2061\n",
      "Epoch [1044/1500]\n",
      "Train Loss: 2754.3136\n",
      "Val Loss: 3933.0742, MAE: 3933.5742, NMAE: 59.8822, R^2: 0.2001\n",
      "Epoch [1045/1500]\n",
      "Train Loss: 2795.8966\n",
      "Val Loss: 3857.3269, MAE: 3857.8271, NMAE: 58.7291, R^2: 0.2240\n",
      "Epoch [1046/1500]\n",
      "Train Loss: 2773.6263\n",
      "Val Loss: 3939.4061, MAE: 3939.9058, NMAE: 59.9786, R^2: 0.2070\n",
      "Epoch [1047/1500]\n",
      "Train Loss: 2748.8184\n",
      "Val Loss: 3904.5577, MAE: 3905.0574, NMAE: 59.4481, R^2: 0.2157\n",
      "Epoch [1048/1500]\n",
      "Train Loss: 2758.1245\n",
      "Val Loss: 3897.6941, MAE: 3898.1941, NMAE: 59.3436, R^2: 0.2217\n",
      "Epoch [1049/1500]\n",
      "Train Loss: 2824.4063\n",
      "Val Loss: 3963.7123, MAE: 3964.2124, NMAE: 60.3486, R^2: 0.2076\n",
      "Epoch [1050/1500]\n",
      "Train Loss: 2810.4991\n",
      "Val Loss: 4101.9323, MAE: 4102.4321, NMAE: 62.4528, R^2: 0.1734\n",
      "Epoch [1051/1500]\n",
      "Train Loss: 2878.2044\n",
      "Val Loss: 4001.1702, MAE: 4001.6699, NMAE: 60.9188, R^2: 0.1923\n",
      "Epoch [1052/1500]\n",
      "Train Loss: 2800.7771\n",
      "Val Loss: 4007.1574, MAE: 4007.6575, NMAE: 61.0100, R^2: 0.1846\n",
      "Epoch [1053/1500]\n",
      "Train Loss: 2812.0025\n",
      "Val Loss: 3959.2514, MAE: 3959.7517, NMAE: 60.2807, R^2: 0.1954\n",
      "Epoch [1054/1500]\n",
      "Train Loss: 2810.9707\n",
      "Val Loss: 3918.8516, MAE: 3919.3518, NMAE: 59.6657, R^2: 0.2100\n",
      "Epoch [1055/1500]\n",
      "Train Loss: 2808.2665\n",
      "Val Loss: 3974.3142, MAE: 3974.8142, NMAE: 60.5100, R^2: 0.1802\n",
      "Epoch [1056/1500]\n",
      "Train Loss: 2807.8677\n",
      "Val Loss: 4000.8693, MAE: 4001.3691, NMAE: 60.9143, R^2: 0.1826\n",
      "Epoch [1057/1500]\n",
      "Train Loss: 2777.3142\n",
      "Val Loss: 3971.6109, MAE: 3972.1108, NMAE: 60.4688, R^2: 0.1865\n",
      "Epoch [1058/1500]\n",
      "Train Loss: 2751.5289\n",
      "Val Loss: 3997.3375, MAE: 3997.8372, NMAE: 60.8605, R^2: 0.1805\n",
      "Epoch [1059/1500]\n",
      "Train Loss: 2835.5416\n",
      "Val Loss: 3972.3138, MAE: 3972.8137, NMAE: 60.4795, R^2: 0.1787\n",
      "Epoch [1060/1500]\n",
      "Train Loss: 2819.9796\n",
      "Val Loss: 3982.4786, MAE: 3982.9783, NMAE: 60.6343, R^2: 0.1702\n",
      "Epoch [1061/1500]\n",
      "Train Loss: 2787.2877\n",
      "Val Loss: 4022.9034, MAE: 4023.4033, NMAE: 61.2497, R^2: 0.1772\n",
      "Epoch [1062/1500]\n",
      "Train Loss: 2866.2420\n",
      "Val Loss: 4054.5257, MAE: 4055.0254, NMAE: 61.7311, R^2: 0.1648\n",
      "Epoch [1063/1500]\n",
      "Train Loss: 2807.8970\n",
      "Val Loss: 4030.8374, MAE: 4031.3374, NMAE: 61.3705, R^2: 0.1590\n",
      "Epoch [1064/1500]\n",
      "Train Loss: 2792.8315\n",
      "Val Loss: 3978.1571, MAE: 3978.6570, NMAE: 60.5685, R^2: 0.1961\n",
      "Epoch [1065/1500]\n",
      "Train Loss: 2838.6725\n",
      "Val Loss: 4009.4618, MAE: 4009.9619, NMAE: 61.0451, R^2: 0.1871\n",
      "Epoch [1066/1500]\n",
      "Train Loss: 2815.0247\n",
      "Val Loss: 3974.3039, MAE: 3974.8037, NMAE: 60.5098, R^2: 0.2006\n",
      "Epoch [1067/1500]\n",
      "Train Loss: 2812.9136\n",
      "Val Loss: 3883.3541, MAE: 3883.8538, NMAE: 59.1253, R^2: 0.2224\n",
      "Epoch [1068/1500]\n",
      "Train Loss: 2849.7335\n",
      "Val Loss: 3958.6405, MAE: 3959.1401, NMAE: 60.2714, R^2: 0.1853\n",
      "Epoch [1069/1500]\n",
      "Train Loss: 2855.8694\n",
      "Val Loss: 3935.6964, MAE: 3936.1963, NMAE: 59.9221, R^2: 0.1851\n",
      "Epoch [1070/1500]\n",
      "Train Loss: 2852.5793\n",
      "Val Loss: 3887.8912, MAE: 3888.3909, NMAE: 59.1943, R^2: 0.2258\n",
      "Epoch [1071/1500]\n",
      "Train Loss: 2905.0672\n",
      "Val Loss: 3881.6811, MAE: 3882.1812, NMAE: 59.0998, R^2: 0.2207\n",
      "Epoch [1072/1500]\n",
      "Train Loss: 2805.6303\n",
      "Val Loss: 3870.1199, MAE: 3870.6199, NMAE: 58.9238, R^2: 0.2234\n",
      "Epoch [1073/1500]\n",
      "Train Loss: 2865.3925\n",
      "Val Loss: 3839.3898, MAE: 3839.8896, NMAE: 58.4560, R^2: 0.2297\n",
      "Epoch [1074/1500]\n",
      "Train Loss: 2824.1099\n",
      "Val Loss: 3855.5525, MAE: 3856.0525, NMAE: 58.7020, R^2: 0.2391\n",
      "Epoch [1075/1500]\n",
      "Train Loss: 2815.0855\n",
      "Val Loss: 3945.5050, MAE: 3946.0051, NMAE: 60.0714, R^2: 0.2068\n",
      "Epoch [1076/1500]\n",
      "Train Loss: 2882.4158\n",
      "Val Loss: 3985.8892, MAE: 3986.3894, NMAE: 60.6862, R^2: 0.1941\n",
      "Epoch [1077/1500]\n",
      "Train Loss: 2893.5268\n",
      "Val Loss: 3936.6294, MAE: 3937.1292, NMAE: 59.9363, R^2: 0.2112\n",
      "Epoch [1078/1500]\n",
      "Train Loss: 2845.1387\n",
      "Val Loss: 3906.1859, MAE: 3906.6860, NMAE: 59.4729, R^2: 0.2090\n",
      "Epoch [1079/1500]\n",
      "Train Loss: 2858.6306\n",
      "Val Loss: 3878.6673, MAE: 3879.1672, NMAE: 59.0539, R^2: 0.2279\n",
      "Epoch [1080/1500]\n",
      "Train Loss: 2905.6418\n",
      "Val Loss: 3934.9106, MAE: 3935.4106, NMAE: 59.9101, R^2: 0.2087\n",
      "Epoch [1081/1500]\n",
      "Train Loss: 2853.6195\n",
      "Val Loss: 3942.7948, MAE: 3943.2947, NMAE: 60.0302, R^2: 0.1956\n",
      "Epoch [1082/1500]\n",
      "Train Loss: 2855.3026\n",
      "Val Loss: 3974.4046, MAE: 3974.9043, NMAE: 60.5114, R^2: 0.1865\n",
      "Epoch [1083/1500]\n",
      "Train Loss: 2850.2750\n",
      "Val Loss: 3957.4668, MAE: 3957.9666, NMAE: 60.2535, R^2: 0.1978\n",
      "Epoch [1084/1500]\n",
      "Train Loss: 2824.2401\n",
      "Val Loss: 3989.1383, MAE: 3989.6382, NMAE: 60.7357, R^2: 0.1811\n",
      "Epoch [1085/1500]\n",
      "Train Loss: 2863.0222\n",
      "Val Loss: 3997.2139, MAE: 3997.7136, NMAE: 60.8586, R^2: 0.1937\n",
      "Epoch [1086/1500]\n",
      "Train Loss: 2886.4092\n",
      "Val Loss: 3913.6034, MAE: 3914.1035, NMAE: 59.5858, R^2: 0.2053\n",
      "Epoch [1087/1500]\n",
      "Train Loss: 2915.4200\n",
      "Val Loss: 3924.1294, MAE: 3924.6294, NMAE: 59.7460, R^2: 0.2171\n",
      "Epoch [1088/1500]\n",
      "Train Loss: 2876.0088\n",
      "Val Loss: 3937.7970, MAE: 3938.2966, NMAE: 59.9541, R^2: 0.2080\n",
      "Epoch [1089/1500]\n",
      "Train Loss: 2898.1070\n",
      "Val Loss: 3955.5575, MAE: 3956.0574, NMAE: 60.2245, R^2: 0.2021\n",
      "Epoch [1090/1500]\n",
      "Train Loss: 2850.4964\n",
      "Val Loss: 4005.3964, MAE: 4005.8960, NMAE: 60.9832, R^2: 0.1983\n",
      "Epoch [1091/1500]\n",
      "Train Loss: 2905.0260\n",
      "Val Loss: 3951.5861, MAE: 3952.0859, NMAE: 60.1640, R^2: 0.1962\n",
      "Epoch [1092/1500]\n",
      "Train Loss: 2898.9152\n",
      "Val Loss: 3997.2256, MAE: 3997.7256, NMAE: 60.8588, R^2: 0.1903\n",
      "Epoch [1093/1500]\n",
      "Train Loss: 2877.1726\n",
      "Val Loss: 4048.3798, MAE: 4048.8796, NMAE: 61.6375, R^2: 0.1678\n",
      "Epoch [1094/1500]\n",
      "Train Loss: 2860.5433\n",
      "Val Loss: 4039.3123, MAE: 4039.8120, NMAE: 61.4995, R^2: 0.1701\n",
      "Epoch [1095/1500]\n",
      "Train Loss: 2881.4364\n",
      "Val Loss: 3978.6270, MAE: 3979.1265, NMAE: 60.5756, R^2: 0.1847\n",
      "Epoch [1096/1500]\n",
      "Train Loss: 2815.2076\n",
      "Val Loss: 3983.6504, MAE: 3984.1504, NMAE: 60.6521, R^2: 0.1919\n",
      "Epoch [1097/1500]\n",
      "Train Loss: 2859.0637\n",
      "Val Loss: 3949.7873, MAE: 3950.2874, NMAE: 60.1366, R^2: 0.2062\n",
      "Epoch [1098/1500]\n",
      "Train Loss: 2844.9882\n",
      "Val Loss: 3956.6244, MAE: 3957.1240, NMAE: 60.2407, R^2: 0.1855\n",
      "Epoch [1099/1500]\n",
      "Train Loss: 2862.7311\n",
      "Val Loss: 3987.1487, MAE: 3987.6487, NMAE: 60.7054, R^2: 0.1850\n",
      "Epoch [1100/1500]\n",
      "Train Loss: 2903.1490\n",
      "Val Loss: 3903.1278, MAE: 3903.6277, NMAE: 59.4263, R^2: 0.2302\n",
      "Epoch [1101/1500]\n",
      "Train Loss: 2891.5737\n",
      "Val Loss: 3975.0539, MAE: 3975.5535, NMAE: 60.5212, R^2: 0.2158\n",
      "Epoch [1102/1500]\n",
      "Train Loss: 2890.5120\n",
      "Val Loss: 3949.4357, MAE: 3949.9355, NMAE: 60.1313, R^2: 0.1963\n",
      "Epoch [1103/1500]\n",
      "Train Loss: 2892.7886\n",
      "Val Loss: 3986.4382, MAE: 3986.9380, NMAE: 60.6946, R^2: 0.1923\n",
      "Epoch [1104/1500]\n",
      "Train Loss: 2855.1145\n",
      "Val Loss: 3994.3207, MAE: 3994.8208, NMAE: 60.8146, R^2: 0.1942\n",
      "Epoch [1105/1500]\n",
      "Train Loss: 2860.4269\n",
      "Val Loss: 3913.9655, MAE: 3914.4653, NMAE: 59.5913, R^2: 0.2064\n",
      "Epoch [1106/1500]\n",
      "Train Loss: 2769.7656\n",
      "Val Loss: 3989.2134, MAE: 3989.7136, NMAE: 60.7368, R^2: 0.1961\n",
      "Epoch [1107/1500]\n",
      "Train Loss: 2849.6738\n",
      "Val Loss: 3898.7626, MAE: 3899.2625, NMAE: 59.3598, R^2: 0.2104\n",
      "Epoch [1108/1500]\n",
      "Train Loss: 2939.8041\n",
      "Val Loss: 3935.6928, MAE: 3936.1926, NMAE: 59.9220, R^2: 0.2169\n",
      "Epoch [1109/1500]\n",
      "Train Loss: 2873.4799\n",
      "Val Loss: 3929.5947, MAE: 3930.0947, NMAE: 59.8292, R^2: 0.2166\n",
      "Epoch [1110/1500]\n",
      "Train Loss: 2952.9829\n",
      "Val Loss: 3920.0648, MAE: 3920.5647, NMAE: 59.6841, R^2: 0.2179\n",
      "Epoch [1111/1500]\n",
      "Train Loss: 2923.6514\n",
      "Val Loss: 3900.5837, MAE: 3901.0837, NMAE: 59.3876, R^2: 0.2162\n",
      "Epoch [1112/1500]\n",
      "Train Loss: 2820.9307\n",
      "Val Loss: 3929.8389, MAE: 3930.3389, NMAE: 59.8329, R^2: 0.2065\n",
      "Epoch [1113/1500]\n",
      "Train Loss: 2941.5056\n",
      "Val Loss: 3824.7430, MAE: 3825.2429, NMAE: 58.2330, R^2: 0.2445\n",
      "Epoch [1114/1500]\n",
      "Train Loss: 2874.7328\n",
      "Val Loss: 3843.3695, MAE: 3843.8694, NMAE: 58.5166, R^2: 0.2450\n",
      "Epoch [1115/1500]\n",
      "Train Loss: 2998.7583\n",
      "Val Loss: 3873.6081, MAE: 3874.1082, NMAE: 58.9769, R^2: 0.2328\n",
      "Epoch [1116/1500]\n",
      "Train Loss: 2937.1836\n",
      "Val Loss: 3865.6467, MAE: 3866.1467, NMAE: 58.8557, R^2: 0.2435\n",
      "Epoch [1117/1500]\n",
      "Train Loss: 2931.4166\n",
      "Val Loss: 3880.0391, MAE: 3880.5388, NMAE: 59.0748, R^2: 0.2195\n",
      "Epoch [1118/1500]\n",
      "Train Loss: 2935.1635\n",
      "Val Loss: 3865.3361, MAE: 3865.8359, NMAE: 58.8510, R^2: 0.2302\n",
      "Epoch [1119/1500]\n",
      "Train Loss: 2950.9084\n",
      "Val Loss: 4070.2966, MAE: 4070.7964, NMAE: 61.9712, R^2: 0.1623\n",
      "Epoch [1120/1500]\n",
      "Train Loss: 2847.4494\n",
      "Val Loss: 3972.2802, MAE: 3972.7798, NMAE: 60.4790, R^2: 0.1939\n",
      "Epoch [1121/1500]\n",
      "Train Loss: 2878.6470\n",
      "Val Loss: 3928.4447, MAE: 3928.9448, NMAE: 59.8117, R^2: 0.2099\n",
      "Epoch [1122/1500]\n",
      "Train Loss: 2912.9243\n",
      "Val Loss: 3901.2604, MAE: 3901.7605, NMAE: 59.3979, R^2: 0.2153\n",
      "Epoch [1123/1500]\n",
      "Train Loss: 3010.1309\n",
      "Val Loss: 3953.4273, MAE: 3953.9272, NMAE: 60.1920, R^2: 0.1982\n",
      "Epoch [1124/1500]\n",
      "Train Loss: 2944.6448\n",
      "Val Loss: 3972.3921, MAE: 3972.8918, NMAE: 60.4807, R^2: 0.1915\n",
      "Epoch [1125/1500]\n",
      "Train Loss: 2937.4889\n",
      "Val Loss: 3913.6555, MAE: 3914.1555, NMAE: 59.5866, R^2: 0.2221\n",
      "Epoch [1126/1500]\n",
      "Train Loss: 2903.1254\n",
      "Val Loss: 3922.9174, MAE: 3923.4175, NMAE: 59.7276, R^2: 0.2200\n",
      "Epoch [1127/1500]\n",
      "Train Loss: 2918.5090\n",
      "Val Loss: 3913.8946, MAE: 3914.3945, NMAE: 59.5902, R^2: 0.2266\n",
      "Epoch [1128/1500]\n",
      "Train Loss: 2899.1240\n",
      "Val Loss: 3946.7734, MAE: 3947.2732, NMAE: 60.0907, R^2: 0.2201\n",
      "Epoch [1129/1500]\n",
      "Train Loss: 2803.4525\n",
      "Val Loss: 3969.4074, MAE: 3969.9072, NMAE: 60.4353, R^2: 0.1918\n",
      "Epoch [1130/1500]\n",
      "Train Loss: 2985.7252\n",
      "Val Loss: 4040.1116, MAE: 4040.6116, NMAE: 61.5117, R^2: 0.1793\n",
      "Epoch [1131/1500]\n",
      "Train Loss: 2869.0665\n",
      "Val Loss: 3932.3633, MAE: 3932.8635, NMAE: 59.8714, R^2: 0.2213\n",
      "Epoch [1132/1500]\n",
      "Train Loss: 2869.8678\n",
      "Val Loss: 3935.6054, MAE: 3936.1052, NMAE: 59.9207, R^2: 0.2113\n",
      "Epoch [1133/1500]\n",
      "Train Loss: 2913.6831\n",
      "Val Loss: 3957.3475, MAE: 3957.8474, NMAE: 60.2517, R^2: 0.2146\n",
      "Epoch [1134/1500]\n",
      "Train Loss: 2882.3852\n",
      "Val Loss: 3895.8659, MAE: 3896.3660, NMAE: 59.3158, R^2: 0.2306\n",
      "Epoch [1135/1500]\n",
      "Train Loss: 2887.6683\n",
      "Val Loss: 3887.7797, MAE: 3888.2795, NMAE: 59.1926, R^2: 0.2259\n",
      "Epoch [1136/1500]\n",
      "Train Loss: 2843.2246\n",
      "Val Loss: 4040.2702, MAE: 4040.7700, NMAE: 61.5141, R^2: 0.1778\n",
      "Epoch [1137/1500]\n",
      "Train Loss: 2774.6281\n",
      "Val Loss: 3944.7718, MAE: 3945.2717, NMAE: 60.0603, R^2: 0.2083\n",
      "Epoch [1138/1500]\n",
      "Train Loss: 2919.2011\n",
      "Val Loss: 3933.9572, MAE: 3934.4570, NMAE: 59.8956, R^2: 0.2415\n",
      "Epoch [1139/1500]\n",
      "Train Loss: 2903.0922\n",
      "Val Loss: 3879.9153, MAE: 3880.4153, NMAE: 59.0729, R^2: 0.2434\n",
      "Epoch [1140/1500]\n",
      "Train Loss: 2866.5808\n",
      "Val Loss: 3921.0465, MAE: 3921.5466, NMAE: 59.6991, R^2: 0.2338\n",
      "Epoch [1141/1500]\n",
      "Train Loss: 2907.7462\n",
      "Val Loss: 3908.9795, MAE: 3909.4795, NMAE: 59.5154, R^2: 0.2305\n",
      "Epoch [1142/1500]\n",
      "Train Loss: 2864.0879\n",
      "Val Loss: 3878.7669, MAE: 3879.2666, NMAE: 59.0554, R^2: 0.2293\n",
      "Epoch [1143/1500]\n",
      "Train Loss: 2915.6539\n",
      "Val Loss: 3858.2089, MAE: 3858.7085, NMAE: 58.7425, R^2: 0.2407\n",
      "Epoch [1144/1500]\n",
      "Train Loss: 2866.8015\n",
      "Val Loss: 3789.9800, MAE: 3790.4800, NMAE: 57.7038, R^2: 0.2777\n",
      "Epoch [1145/1500]\n",
      "Train Loss: 2850.3589\n",
      "Val Loss: 3751.9769, MAE: 3752.4766, NMAE: 57.1253, R^2: 0.2770\n",
      "Epoch [1146/1500]\n",
      "Train Loss: 2856.8122\n",
      "Val Loss: 3866.1549, MAE: 3866.6548, NMAE: 58.8634, R^2: 0.2321\n",
      "Epoch [1147/1500]\n",
      "Train Loss: 2878.8940\n",
      "Val Loss: 3901.7420, MAE: 3902.2419, NMAE: 59.4052, R^2: 0.2307\n",
      "Epoch [1148/1500]\n",
      "Train Loss: 2892.3271\n",
      "Val Loss: 3829.1358, MAE: 3829.6357, NMAE: 58.2999, R^2: 0.2517\n",
      "Epoch [1149/1500]\n",
      "Train Loss: 2885.2033\n",
      "Val Loss: 3771.8570, MAE: 3772.3567, NMAE: 57.4279, R^2: 0.2710\n",
      "Epoch [1150/1500]\n",
      "Train Loss: 2973.5944\n",
      "Val Loss: 3810.5210, MAE: 3811.0210, NMAE: 58.0165, R^2: 0.2588\n",
      "Epoch [1151/1500]\n",
      "Train Loss: 2859.2289\n",
      "Val Loss: 3888.5675, MAE: 3889.0671, NMAE: 59.2046, R^2: 0.2389\n",
      "Epoch [1152/1500]\n",
      "Train Loss: 2912.1040\n",
      "Val Loss: 3898.4803, MAE: 3898.9802, NMAE: 59.3555, R^2: 0.2338\n",
      "Epoch [1153/1500]\n",
      "Train Loss: 2858.4398\n",
      "Val Loss: 3921.0580, MAE: 3921.5581, NMAE: 59.6993, R^2: 0.2304\n",
      "Epoch [1154/1500]\n",
      "Train Loss: 2867.0998\n",
      "Val Loss: 3837.4652, MAE: 3837.9648, NMAE: 58.4267, R^2: 0.2583\n",
      "Epoch [1155/1500]\n",
      "Train Loss: 2885.0104\n",
      "Val Loss: 3849.2194, MAE: 3849.7192, NMAE: 58.6056, R^2: 0.2542\n",
      "Epoch [1156/1500]\n",
      "Train Loss: 2889.5737\n",
      "Val Loss: 3916.1136, MAE: 3916.6133, NMAE: 59.6240, R^2: 0.2343\n",
      "Epoch [1157/1500]\n",
      "Train Loss: 2856.9546\n",
      "Val Loss: 3808.7123, MAE: 3809.2122, NMAE: 57.9890, R^2: 0.2549\n",
      "Epoch [1158/1500]\n",
      "Train Loss: 2837.0867\n",
      "Val Loss: 3893.4508, MAE: 3893.9507, NMAE: 59.2790, R^2: 0.2322\n",
      "Epoch [1159/1500]\n",
      "Train Loss: 2773.7792\n",
      "Val Loss: 3779.4949, MAE: 3779.9949, NMAE: 57.5442, R^2: 0.2706\n",
      "Epoch [1160/1500]\n",
      "Train Loss: 2838.2070\n",
      "Val Loss: 3822.2208, MAE: 3822.7209, NMAE: 58.1946, R^2: 0.2406\n",
      "Epoch [1161/1500]\n",
      "Train Loss: 2834.1728\n",
      "Val Loss: 3803.7433, MAE: 3804.2429, NMAE: 57.9133, R^2: 0.2694\n",
      "Epoch [1162/1500]\n",
      "Train Loss: 2868.5896\n",
      "Val Loss: 3880.2567, MAE: 3880.7563, NMAE: 59.0781, R^2: 0.2396\n",
      "Epoch [1163/1500]\n",
      "Train Loss: 2889.1214\n",
      "Val Loss: 3844.1540, MAE: 3844.6538, NMAE: 58.5285, R^2: 0.2403\n",
      "Epoch [1164/1500]\n",
      "Train Loss: 2839.6413\n",
      "Val Loss: 3910.4221, MAE: 3910.9219, NMAE: 59.5373, R^2: 0.2239\n",
      "Epoch [1165/1500]\n",
      "Train Loss: 2829.0354\n",
      "Val Loss: 3989.1956, MAE: 3989.6956, NMAE: 60.7365, R^2: 0.2124\n",
      "Epoch [1166/1500]\n",
      "Train Loss: 2807.5000\n",
      "Val Loss: 3904.8130, MAE: 3905.3127, NMAE: 59.4520, R^2: 0.2270\n",
      "Epoch [1167/1500]\n",
      "Train Loss: 2842.5294\n",
      "Val Loss: 3895.1337, MAE: 3895.6335, NMAE: 59.3046, R^2: 0.2388\n",
      "Epoch [1168/1500]\n",
      "Train Loss: 2865.6952\n",
      "Val Loss: 3883.3625, MAE: 3883.8621, NMAE: 59.1254, R^2: 0.2437\n",
      "Epoch [1169/1500]\n",
      "Train Loss: 2819.2982\n",
      "Val Loss: 3941.3144, MAE: 3941.8142, NMAE: 60.0076, R^2: 0.2122\n",
      "Epoch [1170/1500]\n",
      "Train Loss: 2946.8159\n",
      "Val Loss: 3981.6390, MAE: 3982.1389, NMAE: 60.6215, R^2: 0.2002\n",
      "Epoch [1171/1500]\n",
      "Train Loss: 2933.8214\n",
      "Val Loss: 3892.5300, MAE: 3893.0298, NMAE: 59.2650, R^2: 0.2175\n",
      "Epoch [1172/1500]\n",
      "Train Loss: 2853.9780\n",
      "Val Loss: 3897.2833, MAE: 3897.7830, NMAE: 59.3373, R^2: 0.2238\n",
      "Epoch [1173/1500]\n",
      "Train Loss: 2876.2663\n",
      "Val Loss: 3889.7079, MAE: 3890.2078, NMAE: 59.2220, R^2: 0.2274\n",
      "Epoch [1174/1500]\n",
      "Train Loss: 2873.0912\n",
      "Val Loss: 3912.9198, MAE: 3913.4197, NMAE: 59.5754, R^2: 0.2315\n",
      "Epoch [1175/1500]\n",
      "Train Loss: 2873.4430\n",
      "Val Loss: 3978.2874, MAE: 3978.7871, NMAE: 60.5705, R^2: 0.2026\n",
      "Epoch [1176/1500]\n",
      "Train Loss: 2824.4993\n",
      "Val Loss: 3999.3090, MAE: 3999.8088, NMAE: 60.8905, R^2: 0.2126\n",
      "Epoch [1177/1500]\n",
      "Train Loss: 2857.1083\n",
      "Val Loss: 3880.5392, MAE: 3881.0391, NMAE: 59.0824, R^2: 0.2385\n",
      "Epoch [1178/1500]\n",
      "Train Loss: 2841.8176\n",
      "Val Loss: 3881.6254, MAE: 3882.1255, NMAE: 59.0990, R^2: 0.2375\n",
      "Epoch [1179/1500]\n",
      "Train Loss: 2788.8748\n",
      "Val Loss: 3909.6416, MAE: 3910.1416, NMAE: 59.5255, R^2: 0.2375\n",
      "Epoch [1180/1500]\n",
      "Train Loss: 2866.9878\n",
      "Val Loss: 4072.1470, MAE: 4072.6470, NMAE: 61.9993, R^2: 0.2071\n",
      "Epoch [1181/1500]\n",
      "Train Loss: 2886.0610\n",
      "Val Loss: 3915.2159, MAE: 3915.7158, NMAE: 59.6103, R^2: 0.2459\n",
      "Epoch [1182/1500]\n",
      "Train Loss: 2925.1143\n",
      "Val Loss: 3897.6588, MAE: 3898.1587, NMAE: 59.3430, R^2: 0.2420\n",
      "Epoch [1183/1500]\n",
      "Train Loss: 2942.9739\n",
      "Val Loss: 3945.7901, MAE: 3946.2896, NMAE: 60.0758, R^2: 0.2354\n",
      "Epoch [1184/1500]\n",
      "Train Loss: 2846.9489\n",
      "Val Loss: 3968.9961, MAE: 3969.4956, NMAE: 60.4290, R^2: 0.2183\n",
      "Epoch [1185/1500]\n",
      "Train Loss: 2919.4990\n",
      "Val Loss: 3953.4411, MAE: 3953.9412, NMAE: 60.1922, R^2: 0.2300\n",
      "Epoch [1186/1500]\n",
      "Train Loss: 2895.0100\n",
      "Val Loss: 3989.4977, MAE: 3989.9978, NMAE: 60.7411, R^2: 0.2315\n",
      "Epoch [1187/1500]\n",
      "Train Loss: 2938.8485\n",
      "Val Loss: 4025.9621, MAE: 4026.4617, NMAE: 61.2962, R^2: 0.2044\n",
      "Epoch [1188/1500]\n",
      "Train Loss: 2929.4818\n",
      "Val Loss: 3966.7342, MAE: 3967.2341, NMAE: 60.3946, R^2: 0.2156\n",
      "Epoch [1189/1500]\n",
      "Train Loss: 2954.2475\n",
      "Val Loss: 3962.5648, MAE: 3963.0649, NMAE: 60.3311, R^2: 0.2314\n",
      "Epoch [1190/1500]\n",
      "Train Loss: 2914.2329\n",
      "Val Loss: 3945.2248, MAE: 3945.7246, NMAE: 60.0672, R^2: 0.2276\n",
      "Epoch [1191/1500]\n",
      "Train Loss: 2909.8623\n",
      "Val Loss: 3987.9691, MAE: 3988.4690, NMAE: 60.7179, R^2: 0.2042\n",
      "Epoch [1192/1500]\n",
      "Train Loss: 2891.3217\n",
      "Val Loss: 4025.3438, MAE: 4025.8442, NMAE: 61.2868, R^2: 0.2077\n",
      "Epoch [1193/1500]\n",
      "Train Loss: 2863.6558\n",
      "Val Loss: 4019.0115, MAE: 4019.5112, NMAE: 61.1904, R^2: 0.2145\n",
      "Epoch [1194/1500]\n",
      "Train Loss: 2914.4167\n",
      "Val Loss: 3876.5653, MAE: 3877.0649, NMAE: 59.0219, R^2: 0.2396\n",
      "Epoch [1195/1500]\n",
      "Train Loss: 2959.3416\n",
      "Val Loss: 3990.9413, MAE: 3991.4409, NMAE: 60.7631, R^2: 0.2019\n",
      "Epoch [1196/1500]\n",
      "Train Loss: 2937.0290\n",
      "Val Loss: 3864.1200, MAE: 3864.6199, NMAE: 58.8325, R^2: 0.2448\n",
      "Epoch [1197/1500]\n",
      "Train Loss: 2929.3911\n",
      "Val Loss: 3873.8511, MAE: 3874.3508, NMAE: 58.9806, R^2: 0.2403\n",
      "Epoch [1198/1500]\n",
      "Train Loss: 2880.2255\n",
      "Val Loss: 3935.5834, MAE: 3936.0833, NMAE: 59.9204, R^2: 0.2239\n",
      "Epoch [1199/1500]\n",
      "Train Loss: 2907.0760\n",
      "Val Loss: 3940.2420, MAE: 3940.7422, NMAE: 59.9913, R^2: 0.2034\n",
      "Epoch [1200/1500]\n",
      "Train Loss: 2935.0285\n",
      "Val Loss: 3879.4853, MAE: 3879.9854, NMAE: 59.0664, R^2: 0.2223\n",
      "Epoch [1201/1500]\n",
      "Train Loss: 2979.6437\n",
      "Val Loss: 3844.8467, MAE: 3845.3467, NMAE: 58.5391, R^2: 0.2207\n",
      "Epoch [1202/1500]\n",
      "Train Loss: 2954.0762\n",
      "Val Loss: 3833.1251, MAE: 3833.6250, NMAE: 58.3606, R^2: 0.2413\n",
      "Epoch [1203/1500]\n",
      "Train Loss: 2867.2489\n",
      "Val Loss: 3920.1015, MAE: 3920.6013, NMAE: 59.6847, R^2: 0.2215\n",
      "Epoch [1204/1500]\n",
      "Train Loss: 2889.0816\n",
      "Val Loss: 4005.1269, MAE: 4005.6272, NMAE: 60.9791, R^2: 0.1909\n",
      "Epoch [1205/1500]\n",
      "Train Loss: 2942.2421\n",
      "Val Loss: 3927.2786, MAE: 3927.7783, NMAE: 59.7940, R^2: 0.2211\n",
      "Epoch [1206/1500]\n",
      "Train Loss: 2984.5556\n",
      "Val Loss: 3973.3476, MAE: 3973.8474, NMAE: 60.4953, R^2: 0.1963\n",
      "Epoch [1207/1500]\n",
      "Train Loss: 2852.9446\n",
      "Val Loss: 3886.3245, MAE: 3886.8247, NMAE: 59.1705, R^2: 0.2312\n",
      "Epoch [1208/1500]\n",
      "Train Loss: 2932.6034\n",
      "Val Loss: 3887.6288, MAE: 3888.1287, NMAE: 59.1904, R^2: 0.2355\n",
      "Epoch [1209/1500]\n",
      "Train Loss: 2881.5212\n",
      "Val Loss: 3895.0913, MAE: 3895.5913, NMAE: 59.3040, R^2: 0.2191\n",
      "Epoch [1210/1500]\n",
      "Train Loss: 2878.7927\n",
      "Val Loss: 3907.6573, MAE: 3908.1572, NMAE: 59.4953, R^2: 0.2131\n",
      "Epoch [1211/1500]\n",
      "Train Loss: 2922.4336\n",
      "Val Loss: 3861.3545, MAE: 3861.8542, NMAE: 58.7904, R^2: 0.2347\n",
      "Epoch [1212/1500]\n",
      "Train Loss: 2998.0853\n",
      "Val Loss: 3866.6639, MAE: 3867.1636, NMAE: 58.8712, R^2: 0.2370\n",
      "Epoch [1213/1500]\n",
      "Train Loss: 2967.4628\n",
      "Val Loss: 3826.3948, MAE: 3826.8948, NMAE: 58.2582, R^2: 0.2668\n",
      "Epoch [1214/1500]\n",
      "Train Loss: 2959.3212\n",
      "Val Loss: 3817.1273, MAE: 3817.6272, NMAE: 58.1171, R^2: 0.2637\n",
      "Epoch [1215/1500]\n",
      "Train Loss: 2932.1921\n",
      "Val Loss: 3826.4065, MAE: 3826.9062, NMAE: 58.2583, R^2: 0.2552\n",
      "Epoch [1216/1500]\n",
      "Train Loss: 2920.6075\n",
      "Val Loss: 3806.7313, MAE: 3807.2312, NMAE: 57.9588, R^2: 0.2704\n",
      "Epoch [1217/1500]\n",
      "Train Loss: 2966.2076\n",
      "Val Loss: 3791.5829, MAE: 3792.0828, NMAE: 57.7282, R^2: 0.2591\n",
      "Epoch [1218/1500]\n",
      "Train Loss: 2895.4950\n",
      "Val Loss: 3846.8788, MAE: 3847.3787, NMAE: 58.5700, R^2: 0.2558\n",
      "Epoch [1219/1500]\n",
      "Train Loss: 2883.6779\n",
      "Val Loss: 3786.4282, MAE: 3786.9280, NMAE: 57.6497, R^2: 0.2714\n",
      "Epoch [1220/1500]\n",
      "Train Loss: 2903.1546\n",
      "Val Loss: 3837.9707, MAE: 3838.4705, NMAE: 58.4344, R^2: 0.2677\n",
      "Epoch [1221/1500]\n",
      "Train Loss: 2901.6529\n",
      "Val Loss: 3789.0749, MAE: 3789.5750, NMAE: 57.6900, R^2: 0.2634\n",
      "Epoch [1222/1500]\n",
      "Train Loss: 2908.9513\n",
      "Val Loss: 3853.9835, MAE: 3854.4832, NMAE: 58.6782, R^2: 0.2419\n",
      "Epoch [1223/1500]\n",
      "Train Loss: 2955.4087\n",
      "Val Loss: 3882.7937, MAE: 3883.2932, NMAE: 59.1167, R^2: 0.2253\n",
      "Epoch [1224/1500]\n",
      "Train Loss: 2910.0127\n",
      "Val Loss: 3851.6402, MAE: 3852.1401, NMAE: 58.6425, R^2: 0.2474\n",
      "Epoch [1225/1500]\n",
      "Train Loss: 2932.8225\n",
      "Val Loss: 3838.5491, MAE: 3839.0491, NMAE: 58.4432, R^2: 0.2615\n",
      "Epoch [1226/1500]\n",
      "Train Loss: 2988.9717\n",
      "Val Loss: 3890.8853, MAE: 3891.3853, NMAE: 59.2399, R^2: 0.2534\n",
      "Epoch [1227/1500]\n",
      "Train Loss: 2922.4323\n",
      "Val Loss: 3930.3328, MAE: 3930.8328, NMAE: 59.8405, R^2: 0.2241\n",
      "Epoch [1228/1500]\n",
      "Train Loss: 2946.5977\n",
      "Val Loss: 3877.3525, MAE: 3877.8523, NMAE: 59.0339, R^2: 0.2543\n",
      "Epoch [1229/1500]\n",
      "Train Loss: 2932.2516\n",
      "Val Loss: 3857.1915, MAE: 3857.6909, NMAE: 58.7270, R^2: 0.2640\n",
      "Epoch [1230/1500]\n",
      "Train Loss: 2922.9094\n",
      "Val Loss: 3922.4745, MAE: 3922.9744, NMAE: 59.7208, R^2: 0.2283\n",
      "Epoch [1231/1500]\n",
      "Train Loss: 2940.4362\n",
      "Val Loss: 3963.9342, MAE: 3964.4341, NMAE: 60.3520, R^2: 0.2116\n",
      "Epoch [1232/1500]\n",
      "Train Loss: 2903.8079\n",
      "Val Loss: 3924.1808, MAE: 3924.6804, NMAE: 59.7468, R^2: 0.2205\n",
      "Epoch [1233/1500]\n",
      "Train Loss: 2939.4508\n",
      "Val Loss: 3900.3950, MAE: 3900.8948, NMAE: 59.3847, R^2: 0.2298\n",
      "Epoch [1234/1500]\n",
      "Train Loss: 2966.6918\n",
      "Val Loss: 3861.6414, MAE: 3862.1411, NMAE: 58.7947, R^2: 0.2382\n",
      "Epoch [1235/1500]\n",
      "Train Loss: 2936.4383\n",
      "Val Loss: 3917.4818, MAE: 3917.9817, NMAE: 59.6448, R^2: 0.2313\n",
      "Epoch [1236/1500]\n",
      "Train Loss: 2953.2325\n",
      "Val Loss: 3963.9813, MAE: 3964.4810, NMAE: 60.3527, R^2: 0.1990\n",
      "Epoch [1237/1500]\n",
      "Train Loss: 2920.6094\n",
      "Val Loss: 3995.3338, MAE: 3995.8335, NMAE: 60.8300, R^2: 0.1850\n",
      "Epoch [1238/1500]\n",
      "Train Loss: 2977.6671\n",
      "Val Loss: 4019.9909, MAE: 4020.4910, NMAE: 61.2053, R^2: 0.1915\n",
      "Epoch [1239/1500]\n",
      "Train Loss: 3036.7850\n",
      "Val Loss: 4020.1412, MAE: 4020.6409, NMAE: 61.2076, R^2: 0.1908\n",
      "Epoch [1240/1500]\n",
      "Train Loss: 3017.5530\n",
      "Val Loss: 4032.4880, MAE: 4032.9880, NMAE: 61.3956, R^2: 0.2032\n",
      "Epoch [1241/1500]\n",
      "Train Loss: 3012.0071\n",
      "Val Loss: 3973.2472, MAE: 3973.7471, NMAE: 60.4938, R^2: 0.1989\n",
      "Epoch [1242/1500]\n",
      "Train Loss: 2965.8992\n",
      "Val Loss: 3950.6973, MAE: 3951.1973, NMAE: 60.1505, R^2: 0.2095\n",
      "Epoch [1243/1500]\n",
      "Train Loss: 3003.3333\n",
      "Val Loss: 4004.4587, MAE: 4004.9587, NMAE: 60.9689, R^2: 0.1893\n",
      "Epoch [1244/1500]\n",
      "Train Loss: 3037.5688\n",
      "Val Loss: 3976.0064, MAE: 3976.5061, NMAE: 60.5358, R^2: 0.2029\n",
      "Epoch [1245/1500]\n",
      "Train Loss: 2960.1358\n",
      "Val Loss: 3936.8735, MAE: 3937.3733, NMAE: 59.9400, R^2: 0.2171\n",
      "Epoch [1246/1500]\n",
      "Train Loss: 2980.6783\n",
      "Val Loss: 4031.5492, MAE: 4032.0493, NMAE: 61.3813, R^2: 0.1819\n",
      "Epoch [1247/1500]\n",
      "Train Loss: 2957.0900\n",
      "Val Loss: 4031.5009, MAE: 4032.0010, NMAE: 61.3806, R^2: 0.1883\n",
      "Epoch [1248/1500]\n",
      "Train Loss: 2922.6031\n",
      "Val Loss: 4049.4643, MAE: 4049.9641, NMAE: 61.6540, R^2: 0.1931\n",
      "Epoch [1249/1500]\n",
      "Train Loss: 2929.5424\n",
      "Val Loss: 3992.0935, MAE: 3992.5930, NMAE: 60.7806, R^2: 0.1929\n",
      "Epoch [1250/1500]\n",
      "Train Loss: 2995.8395\n",
      "Val Loss: 3998.9457, MAE: 3999.4456, NMAE: 60.8850, R^2: 0.1915\n",
      "Epoch [1251/1500]\n",
      "Train Loss: 2963.9744\n",
      "Val Loss: 4015.1508, MAE: 4015.6506, NMAE: 61.1317, R^2: 0.1864\n",
      "Epoch [1252/1500]\n",
      "Train Loss: 2986.4864\n",
      "Val Loss: 3970.6137, MAE: 3971.1135, NMAE: 60.4537, R^2: 0.2231\n",
      "Epoch [1253/1500]\n",
      "Train Loss: 3010.5072\n",
      "Val Loss: 3985.6002, MAE: 3986.0999, NMAE: 60.6818, R^2: 0.2002\n",
      "Epoch [1254/1500]\n",
      "Train Loss: 2993.4442\n",
      "Val Loss: 3955.5936, MAE: 3956.0938, NMAE: 60.2250, R^2: 0.1861\n",
      "Epoch [1255/1500]\n",
      "Train Loss: 3014.7366\n",
      "Val Loss: 4004.0738, MAE: 4004.5737, NMAE: 60.9630, R^2: 0.1686\n",
      "Epoch [1256/1500]\n",
      "Train Loss: 3000.2451\n",
      "Val Loss: 3942.4559, MAE: 3942.9558, NMAE: 60.0250, R^2: 0.1993\n",
      "Epoch [1257/1500]\n",
      "Train Loss: 2952.1893\n",
      "Val Loss: 3978.7289, MAE: 3979.2285, NMAE: 60.5772, R^2: 0.2133\n",
      "Epoch [1258/1500]\n",
      "Train Loss: 2970.2139\n",
      "Val Loss: 3959.2891, MAE: 3959.7886, NMAE: 60.2813, R^2: 0.2125\n",
      "Epoch [1259/1500]\n",
      "Train Loss: 2954.6039\n",
      "Val Loss: 3959.3476, MAE: 3959.8474, NMAE: 60.2822, R^2: 0.1930\n",
      "Epoch [1260/1500]\n",
      "Train Loss: 2992.2674\n",
      "Val Loss: 4008.6920, MAE: 4009.1917, NMAE: 61.0333, R^2: 0.1811\n",
      "Epoch [1261/1500]\n",
      "Train Loss: 2981.3308\n",
      "Val Loss: 3978.2237, MAE: 3978.7236, NMAE: 60.5695, R^2: 0.1913\n",
      "Epoch [1262/1500]\n",
      "Train Loss: 2958.3340\n",
      "Val Loss: 3967.8324, MAE: 3968.3325, NMAE: 60.4113, R^2: 0.2061\n",
      "Epoch [1263/1500]\n",
      "Train Loss: 2971.7808\n",
      "Val Loss: 3958.7975, MAE: 3959.2974, NMAE: 60.2738, R^2: 0.1970\n",
      "Epoch [1264/1500]\n",
      "Train Loss: 2995.1900\n",
      "Val Loss: 4004.4194, MAE: 4004.9192, NMAE: 60.9683, R^2: 0.1851\n",
      "Epoch [1265/1500]\n",
      "Train Loss: 2954.6661\n",
      "Val Loss: 3999.2300, MAE: 3999.7297, NMAE: 60.8893, R^2: 0.1906\n",
      "Epoch [1266/1500]\n",
      "Train Loss: 2967.0737\n",
      "Val Loss: 3916.0262, MAE: 3916.5259, NMAE: 59.6227, R^2: 0.2132\n",
      "Epoch [1267/1500]\n",
      "Train Loss: 2970.3626\n",
      "Val Loss: 3923.3177, MAE: 3923.8179, NMAE: 59.7337, R^2: 0.2179\n",
      "Epoch [1268/1500]\n",
      "Train Loss: 2967.8482\n",
      "Val Loss: 3916.1732, MAE: 3916.6731, NMAE: 59.6249, R^2: 0.2106\n",
      "Epoch [1269/1500]\n",
      "Train Loss: 2957.9262\n",
      "Val Loss: 3922.9998, MAE: 3923.4998, NMAE: 59.7288, R^2: 0.2064\n",
      "Epoch [1270/1500]\n",
      "Train Loss: 2977.3695\n",
      "Val Loss: 3889.1038, MAE: 3889.6038, NMAE: 59.2128, R^2: 0.2194\n",
      "Epoch [1271/1500]\n",
      "Train Loss: 2982.6753\n",
      "Val Loss: 3916.4077, MAE: 3916.9075, NMAE: 59.6285, R^2: 0.2098\n",
      "Epoch [1272/1500]\n",
      "Train Loss: 3068.6612\n",
      "Val Loss: 3913.5110, MAE: 3914.0110, NMAE: 59.5844, R^2: 0.2170\n",
      "Epoch [1273/1500]\n",
      "Train Loss: 3052.6192\n",
      "Val Loss: 3952.1226, MAE: 3952.6226, NMAE: 60.1722, R^2: 0.1991\n",
      "Epoch [1274/1500]\n",
      "Train Loss: 3052.9216\n",
      "Val Loss: 3945.3700, MAE: 3945.8699, NMAE: 60.0694, R^2: 0.1972\n",
      "Epoch [1275/1500]\n",
      "Train Loss: 3099.1333\n",
      "Val Loss: 3918.5189, MAE: 3919.0188, NMAE: 59.6606, R^2: 0.2134\n",
      "Epoch [1276/1500]\n",
      "Train Loss: 2977.9732\n",
      "Val Loss: 3885.9106, MAE: 3886.4106, NMAE: 59.1642, R^2: 0.2352\n",
      "Epoch [1277/1500]\n",
      "Train Loss: 2990.0399\n",
      "Val Loss: 3908.6089, MAE: 3909.1084, NMAE: 59.5097, R^2: 0.2112\n",
      "Epoch [1278/1500]\n",
      "Train Loss: 2984.6968\n",
      "Val Loss: 3877.3888, MAE: 3877.8887, NMAE: 59.0345, R^2: 0.2206\n",
      "Epoch [1279/1500]\n",
      "Train Loss: 3008.0376\n",
      "Val Loss: 3936.6720, MAE: 3937.1719, NMAE: 59.9370, R^2: 0.2189\n",
      "Epoch [1280/1500]\n",
      "Train Loss: 3012.8818\n",
      "Val Loss: 3844.8279, MAE: 3845.3276, NMAE: 58.5388, R^2: 0.2355\n",
      "Epoch [1281/1500]\n",
      "Train Loss: 3019.0096\n",
      "Val Loss: 3855.5632, MAE: 3856.0627, NMAE: 58.7022, R^2: 0.2432\n",
      "Epoch [1282/1500]\n",
      "Train Loss: 3040.7797\n",
      "Val Loss: 3867.2057, MAE: 3867.7058, NMAE: 58.8794, R^2: 0.2355\n",
      "Epoch [1283/1500]\n",
      "Train Loss: 3039.9506\n",
      "Val Loss: 3849.8357, MAE: 3850.3357, NMAE: 58.6150, R^2: 0.2291\n",
      "Epoch [1284/1500]\n",
      "Train Loss: 3025.8309\n",
      "Val Loss: 3871.1398, MAE: 3871.6396, NMAE: 58.9393, R^2: 0.2378\n",
      "Epoch [1285/1500]\n",
      "Train Loss: 3000.7968\n",
      "Val Loss: 3913.2714, MAE: 3913.7710, NMAE: 59.5807, R^2: 0.2126\n",
      "Epoch [1286/1500]\n",
      "Train Loss: 3008.7441\n",
      "Val Loss: 3938.6050, MAE: 3939.1047, NMAE: 59.9664, R^2: 0.2127\n",
      "Epoch [1287/1500]\n",
      "Train Loss: 3035.5937\n",
      "Val Loss: 3924.4958, MAE: 3924.9954, NMAE: 59.7516, R^2: 0.2072\n",
      "Epoch [1288/1500]\n",
      "Train Loss: 3046.9252\n",
      "Val Loss: 3913.3071, MAE: 3913.8069, NMAE: 59.5813, R^2: 0.2105\n",
      "Epoch [1289/1500]\n",
      "Train Loss: 2986.7023\n",
      "Val Loss: 3950.6833, MAE: 3951.1831, NMAE: 60.1503, R^2: 0.1911\n",
      "Epoch [1290/1500]\n",
      "Train Loss: 3029.7311\n",
      "Val Loss: 3993.9446, MAE: 3994.4441, NMAE: 60.8088, R^2: 0.1800\n",
      "Epoch [1291/1500]\n",
      "Train Loss: 3030.3997\n",
      "Val Loss: 3983.7847, MAE: 3984.2847, NMAE: 60.6542, R^2: 0.2118\n",
      "Epoch [1292/1500]\n",
      "Train Loss: 3009.0719\n",
      "Val Loss: 4019.5845, MAE: 4020.0847, NMAE: 61.1992, R^2: 0.1949\n",
      "Epoch [1293/1500]\n",
      "Train Loss: 3094.2342\n",
      "Val Loss: 3973.4959, MAE: 3973.9954, NMAE: 60.4975, R^2: 0.1984\n",
      "Epoch [1294/1500]\n",
      "Train Loss: 3083.7717\n",
      "Val Loss: 3997.0784, MAE: 3997.5784, NMAE: 60.8565, R^2: 0.1912\n",
      "Epoch [1295/1500]\n",
      "Train Loss: 3091.8810\n",
      "Val Loss: 3914.9406, MAE: 3915.4404, NMAE: 59.6061, R^2: 0.2321\n",
      "Epoch [1296/1500]\n",
      "Train Loss: 3172.2532\n",
      "Val Loss: 3912.6890, MAE: 3913.1890, NMAE: 59.5719, R^2: 0.2243\n",
      "Epoch [1297/1500]\n",
      "Train Loss: 3111.2438\n",
      "Val Loss: 4000.0769, MAE: 4000.5767, NMAE: 60.9022, R^2: 0.2184\n",
      "Epoch [1298/1500]\n",
      "Train Loss: 3028.3580\n",
      "Val Loss: 3920.8245, MAE: 3921.3247, NMAE: 59.6957, R^2: 0.2158\n",
      "Epoch [1299/1500]\n",
      "Train Loss: 3102.6947\n",
      "Val Loss: 3976.0390, MAE: 3976.5388, NMAE: 60.5363, R^2: 0.2149\n",
      "Epoch [1300/1500]\n",
      "Train Loss: 3044.2375\n",
      "Val Loss: 3958.9352, MAE: 3959.4351, NMAE: 60.2759, R^2: 0.2098\n",
      "Epoch [1301/1500]\n",
      "Train Loss: 3045.2545\n",
      "Val Loss: 3970.8602, MAE: 3971.3601, NMAE: 60.4574, R^2: 0.2081\n",
      "Epoch [1302/1500]\n",
      "Train Loss: 3032.4485\n",
      "Val Loss: 3955.0419, MAE: 3955.5415, NMAE: 60.2166, R^2: 0.1968\n",
      "Epoch [1303/1500]\n",
      "Train Loss: 3082.1276\n",
      "Val Loss: 3924.8712, MAE: 3925.3711, NMAE: 59.7573, R^2: 0.2380\n",
      "Epoch [1304/1500]\n",
      "Train Loss: 3064.6528\n",
      "Val Loss: 3927.4689, MAE: 3927.9688, NMAE: 59.7969, R^2: 0.2161\n",
      "Epoch [1305/1500]\n",
      "Train Loss: 3022.9456\n",
      "Val Loss: 4040.1485, MAE: 4040.6482, NMAE: 61.5122, R^2: 0.1940\n",
      "Epoch [1306/1500]\n",
      "Train Loss: 3051.9275\n",
      "Val Loss: 4021.1774, MAE: 4021.6772, NMAE: 61.2234, R^2: 0.1877\n",
      "Epoch [1307/1500]\n",
      "Train Loss: 3057.4117\n",
      "Val Loss: 4044.5209, MAE: 4045.0208, NMAE: 61.5788, R^2: 0.1798\n",
      "Epoch [1308/1500]\n",
      "Train Loss: 3000.7294\n",
      "Val Loss: 3992.9553, MAE: 3993.4556, NMAE: 60.7938, R^2: 0.1978\n",
      "Epoch [1309/1500]\n",
      "Train Loss: 3077.3272\n",
      "Val Loss: 3989.8976, MAE: 3990.3977, NMAE: 60.7472, R^2: 0.2037\n",
      "Epoch [1310/1500]\n",
      "Train Loss: 2975.5542\n",
      "Val Loss: 3887.1285, MAE: 3887.6284, NMAE: 59.1827, R^2: 0.2338\n",
      "Epoch [1311/1500]\n",
      "Train Loss: 3036.8259\n",
      "Val Loss: 3909.6752, MAE: 3910.1753, NMAE: 59.5260, R^2: 0.2243\n",
      "Epoch [1312/1500]\n",
      "Train Loss: 2976.1228\n",
      "Val Loss: 3973.4862, MAE: 3973.9858, NMAE: 60.4974, R^2: 0.2135\n",
      "Epoch [1313/1500]\n",
      "Train Loss: 2933.7485\n",
      "Val Loss: 4030.3619, MAE: 4030.8621, NMAE: 61.3632, R^2: 0.1854\n",
      "Epoch [1314/1500]\n",
      "Train Loss: 2999.8428\n",
      "Val Loss: 4040.4167, MAE: 4040.9167, NMAE: 61.5163, R^2: 0.1709\n",
      "Epoch [1315/1500]\n",
      "Train Loss: 2981.7719\n",
      "Val Loss: 4084.9345, MAE: 4085.4346, NMAE: 62.1940, R^2: 0.1659\n",
      "Epoch [1316/1500]\n",
      "Train Loss: 3009.2590\n",
      "Val Loss: 3990.6736, MAE: 3991.1733, NMAE: 60.7590, R^2: 0.1930\n",
      "Epoch [1317/1500]\n",
      "Train Loss: 3035.0517\n",
      "Val Loss: 3990.3110, MAE: 3990.8110, NMAE: 60.7535, R^2: 0.2000\n",
      "Epoch [1318/1500]\n",
      "Train Loss: 2967.2379\n",
      "Val Loss: 4070.5122, MAE: 4071.0120, NMAE: 61.9744, R^2: 0.1751\n",
      "Epoch [1319/1500]\n",
      "Train Loss: 3047.4617\n",
      "Val Loss: 4054.2579, MAE: 4054.7578, NMAE: 61.7270, R^2: 0.1760\n",
      "Epoch [1320/1500]\n",
      "Train Loss: 3091.5698\n",
      "Val Loss: 4094.0838, MAE: 4094.5835, NMAE: 62.3333, R^2: 0.1730\n",
      "Epoch [1321/1500]\n",
      "Train Loss: 3048.2138\n",
      "Val Loss: 4230.7565, MAE: 4231.2568, NMAE: 64.4139, R^2: 0.1309\n",
      "Epoch [1322/1500]\n",
      "Train Loss: 3046.1657\n",
      "Val Loss: 4136.8389, MAE: 4137.3389, NMAE: 62.9842, R^2: 0.1338\n",
      "Epoch [1323/1500]\n",
      "Train Loss: 3022.5382\n",
      "Val Loss: 4206.4672, MAE: 4206.9668, NMAE: 64.0441, R^2: 0.1456\n",
      "Epoch [1324/1500]\n",
      "Train Loss: 3100.5028\n",
      "Val Loss: 4160.2539, MAE: 4160.7534, NMAE: 63.3406, R^2: 0.1638\n",
      "Epoch [1325/1500]\n",
      "Train Loss: 3090.0343\n",
      "Val Loss: 4112.7868, MAE: 4113.2866, NMAE: 62.6180, R^2: 0.1520\n",
      "Epoch [1326/1500]\n",
      "Train Loss: 3029.2502\n",
      "Val Loss: 4113.7136, MAE: 4114.2134, NMAE: 62.6321, R^2: 0.1614\n",
      "Epoch [1327/1500]\n",
      "Train Loss: 2995.8364\n",
      "Val Loss: 4117.5411, MAE: 4118.0410, NMAE: 62.6904, R^2: 0.1571\n",
      "Epoch [1328/1500]\n",
      "Train Loss: 2971.5067\n",
      "Val Loss: 4114.7988, MAE: 4115.2988, NMAE: 62.6486, R^2: 0.1587\n",
      "Epoch [1329/1500]\n",
      "Train Loss: 3047.3706\n",
      "Val Loss: 4077.0578, MAE: 4077.5576, NMAE: 62.0741, R^2: 0.1588\n",
      "Epoch [1330/1500]\n",
      "Train Loss: 3052.7397\n",
      "Val Loss: 4136.1586, MAE: 4136.6582, NMAE: 62.9738, R^2: 0.1568\n",
      "Epoch [1331/1500]\n",
      "Train Loss: 2953.1203\n",
      "Val Loss: 4076.3261, MAE: 4076.8262, NMAE: 62.0630, R^2: 0.1814\n",
      "Epoch [1332/1500]\n",
      "Train Loss: 3018.6748\n",
      "Val Loss: 4110.9176, MAE: 4111.4175, NMAE: 62.5896, R^2: 0.1839\n",
      "Epoch [1333/1500]\n",
      "Train Loss: 3043.8893\n",
      "Val Loss: 4023.9633, MAE: 4024.4629, NMAE: 61.2658, R^2: 0.1848\n",
      "Epoch [1334/1500]\n",
      "Train Loss: 3032.3131\n",
      "Val Loss: 4100.4325, MAE: 4100.9326, NMAE: 62.4299, R^2: 0.1823\n",
      "Epoch [1335/1500]\n",
      "Train Loss: 3081.5753\n",
      "Val Loss: 4011.0769, MAE: 4011.5769, NMAE: 61.0696, R^2: 0.1928\n",
      "Epoch [1336/1500]\n",
      "Train Loss: 3017.7542\n",
      "Val Loss: 3947.1353, MAE: 3947.6350, NMAE: 60.0962, R^2: 0.2217\n",
      "Epoch [1337/1500]\n",
      "Train Loss: 3101.4836\n",
      "Val Loss: 3973.4641, MAE: 3973.9636, NMAE: 60.4970, R^2: 0.1960\n",
      "Epoch [1338/1500]\n",
      "Train Loss: 2977.5662\n",
      "Val Loss: 3960.6270, MAE: 3961.1270, NMAE: 60.3016, R^2: 0.2140\n",
      "Epoch [1339/1500]\n",
      "Train Loss: 2906.9302\n",
      "Val Loss: 4014.3757, MAE: 4014.8755, NMAE: 61.1199, R^2: 0.1796\n",
      "Epoch [1340/1500]\n",
      "Train Loss: 3025.3777\n",
      "Val Loss: 3992.9741, MAE: 3993.4741, NMAE: 60.7941, R^2: 0.1993\n",
      "Epoch [1341/1500]\n",
      "Train Loss: 3065.7893\n",
      "Val Loss: 4055.9728, MAE: 4056.4727, NMAE: 61.7531, R^2: 0.1871\n",
      "Epoch [1342/1500]\n",
      "Train Loss: 2950.7931\n",
      "Val Loss: 4046.8434, MAE: 4047.3435, NMAE: 61.6141, R^2: 0.1771\n",
      "Epoch [1343/1500]\n",
      "Train Loss: 3076.8148\n",
      "Val Loss: 4086.0711, MAE: 4086.5710, NMAE: 62.2113, R^2: 0.1734\n",
      "Epoch [1344/1500]\n",
      "Train Loss: 3028.6048\n",
      "Val Loss: 4098.2361, MAE: 4098.7363, NMAE: 62.3965, R^2: 0.1765\n",
      "Epoch [1345/1500]\n",
      "Train Loss: 3009.7664\n",
      "Val Loss: 4145.5546, MAE: 4146.0547, NMAE: 63.1169, R^2: 0.1345\n",
      "Epoch [1346/1500]\n",
      "Train Loss: 3041.9129\n",
      "Val Loss: 4101.7255, MAE: 4102.2251, NMAE: 62.4496, R^2: 0.1290\n",
      "Epoch [1347/1500]\n",
      "Train Loss: 3004.3170\n",
      "Val Loss: 4114.4945, MAE: 4114.9946, NMAE: 62.6440, R^2: 0.1316\n",
      "Epoch [1348/1500]\n",
      "Train Loss: 3041.8422\n",
      "Val Loss: 4058.8508, MAE: 4059.3508, NMAE: 61.7969, R^2: 0.1650\n",
      "Epoch [1349/1500]\n",
      "Train Loss: 3003.7829\n",
      "Val Loss: 4055.4115, MAE: 4055.9116, NMAE: 61.7446, R^2: 0.1667\n",
      "Epoch [1350/1500]\n",
      "Train Loss: 2971.7368\n",
      "Val Loss: 4032.9064, MAE: 4033.4065, NMAE: 61.4020, R^2: 0.1748\n",
      "Epoch [1351/1500]\n",
      "Train Loss: 2955.7860\n",
      "Val Loss: 4005.0367, MAE: 4005.5366, NMAE: 60.9777, R^2: 0.1848\n",
      "Epoch [1352/1500]\n",
      "Train Loss: 2950.6060\n",
      "Val Loss: 4063.6591, MAE: 4064.1592, NMAE: 61.8701, R^2: 0.1711\n",
      "Epoch [1353/1500]\n",
      "Train Loss: 2970.5917\n",
      "Val Loss: 4071.0503, MAE: 4071.5498, NMAE: 61.9826, R^2: 0.1760\n",
      "Epoch [1354/1500]\n",
      "Train Loss: 3038.5082\n",
      "Val Loss: 4005.5922, MAE: 4006.0920, NMAE: 60.9861, R^2: 0.1958\n",
      "Epoch [1355/1500]\n",
      "Train Loss: 2993.6629\n",
      "Val Loss: 3994.2776, MAE: 3994.7776, NMAE: 60.8139, R^2: 0.1947\n",
      "Epoch [1356/1500]\n",
      "Train Loss: 3064.1321\n",
      "Val Loss: 4045.3967, MAE: 4045.8965, NMAE: 61.5921, R^2: 0.1686\n",
      "Epoch [1357/1500]\n",
      "Train Loss: 3006.6596\n",
      "Val Loss: 3992.9242, MAE: 3993.4238, NMAE: 60.7933, R^2: 0.1825\n",
      "Epoch [1358/1500]\n",
      "Train Loss: 3159.1813\n",
      "Val Loss: 4054.5712, MAE: 4055.0713, NMAE: 61.7318, R^2: 0.1822\n",
      "Epoch [1359/1500]\n",
      "Train Loss: 3066.8318\n",
      "Val Loss: 3999.2285, MAE: 3999.7283, NMAE: 60.8893, R^2: 0.2153\n",
      "Epoch [1360/1500]\n",
      "Train Loss: 3062.4622\n",
      "Val Loss: 4170.9334, MAE: 4171.4336, NMAE: 63.5032, R^2: 0.1782\n",
      "Epoch [1361/1500]\n",
      "Train Loss: 3146.6896\n",
      "Val Loss: 4118.3272, MAE: 4118.8267, NMAE: 62.7023, R^2: 0.1683\n",
      "Epoch [1362/1500]\n",
      "Train Loss: 3053.0362\n",
      "Val Loss: 4052.6571, MAE: 4053.1567, NMAE: 61.7026, R^2: 0.1604\n",
      "Epoch [1363/1500]\n",
      "Train Loss: 3010.8461\n",
      "Val Loss: 4059.5196, MAE: 4060.0193, NMAE: 61.8071, R^2: 0.1811\n",
      "Epoch [1364/1500]\n",
      "Train Loss: 3036.3898\n",
      "Val Loss: 4026.9131, MAE: 4027.4128, NMAE: 61.3107, R^2: 0.1868\n",
      "Epoch [1365/1500]\n",
      "Train Loss: 3063.3894\n",
      "Val Loss: 4035.0944, MAE: 4035.5940, NMAE: 61.4353, R^2: 0.1746\n",
      "Epoch [1366/1500]\n",
      "Train Loss: 3108.3007\n",
      "Val Loss: 4016.2650, MAE: 4016.7651, NMAE: 61.1486, R^2: 0.1769\n",
      "Epoch [1367/1500]\n",
      "Train Loss: 3045.6494\n",
      "Val Loss: 4071.4064, MAE: 4071.9062, NMAE: 61.9881, R^2: 0.1612\n",
      "Epoch [1368/1500]\n",
      "Train Loss: 2988.7641\n",
      "Val Loss: 3955.4980, MAE: 3955.9978, NMAE: 60.2235, R^2: 0.2104\n",
      "Epoch [1369/1500]\n",
      "Train Loss: 3123.2681\n",
      "Val Loss: 4035.1453, MAE: 4035.6455, NMAE: 61.4361, R^2: 0.1896\n",
      "Epoch [1370/1500]\n",
      "Train Loss: 3037.6722\n",
      "Val Loss: 3935.4683, MAE: 3935.9683, NMAE: 59.9186, R^2: 0.2313\n",
      "Epoch [1371/1500]\n",
      "Train Loss: 3059.8286\n",
      "Val Loss: 3911.9495, MAE: 3912.4492, NMAE: 59.5606, R^2: 0.2331\n",
      "Epoch [1372/1500]\n",
      "Train Loss: 3018.0160\n",
      "Val Loss: 3948.9588, MAE: 3949.4587, NMAE: 60.1240, R^2: 0.2411\n",
      "Epoch [1373/1500]\n",
      "Train Loss: 3022.1330\n",
      "Val Loss: 3994.4116, MAE: 3994.9114, NMAE: 60.8159, R^2: 0.2145\n",
      "Epoch [1374/1500]\n",
      "Train Loss: 3101.1472\n",
      "Val Loss: 3960.3661, MAE: 3960.8657, NMAE: 60.2977, R^2: 0.2257\n",
      "Epoch [1375/1500]\n",
      "Train Loss: 3099.3075\n",
      "Val Loss: 3963.2197, MAE: 3963.7195, NMAE: 60.3411, R^2: 0.2187\n",
      "Epoch [1376/1500]\n",
      "Train Loss: 3042.3328\n",
      "Val Loss: 3969.0849, MAE: 3969.5847, NMAE: 60.4304, R^2: 0.2059\n",
      "Epoch [1377/1500]\n",
      "Train Loss: 3061.3474\n",
      "Val Loss: 3915.2643, MAE: 3915.7642, NMAE: 59.6111, R^2: 0.2305\n",
      "Epoch [1378/1500]\n",
      "Train Loss: 2988.4756\n",
      "Val Loss: 3895.3749, MAE: 3895.8745, NMAE: 59.3083, R^2: 0.2152\n",
      "Epoch [1379/1500]\n",
      "Train Loss: 3054.3041\n",
      "Val Loss: 3922.5142, MAE: 3923.0142, NMAE: 59.7214, R^2: 0.2181\n",
      "Epoch [1380/1500]\n",
      "Train Loss: 2898.1545\n",
      "Val Loss: 3976.3959, MAE: 3976.8958, NMAE: 60.5417, R^2: 0.1983\n",
      "Epoch [1381/1500]\n",
      "Train Loss: 2999.9256\n",
      "Val Loss: 4041.7035, MAE: 4042.2031, NMAE: 61.5359, R^2: 0.1923\n",
      "Epoch [1382/1500]\n",
      "Train Loss: 2961.5920\n",
      "Val Loss: 4018.0255, MAE: 4018.5256, NMAE: 61.1754, R^2: 0.1935\n",
      "Epoch [1383/1500]\n",
      "Train Loss: 2975.1893\n",
      "Val Loss: 4089.7065, MAE: 4090.2065, NMAE: 62.2667, R^2: 0.1714\n",
      "Epoch [1384/1500]\n",
      "Train Loss: 2960.1691\n",
      "Val Loss: 3995.0074, MAE: 3995.5071, NMAE: 60.8250, R^2: 0.2083\n",
      "Epoch [1385/1500]\n",
      "Train Loss: 2939.8907\n",
      "Val Loss: 3926.2466, MAE: 3926.7466, NMAE: 59.7782, R^2: 0.2252\n",
      "Epoch [1386/1500]\n",
      "Train Loss: 3053.1143\n",
      "Val Loss: 4051.9742, MAE: 4052.4741, NMAE: 61.6922, R^2: 0.1999\n",
      "Epoch [1387/1500]\n",
      "Train Loss: 2983.1092\n",
      "Val Loss: 3896.3542, MAE: 3896.8542, NMAE: 59.3232, R^2: 0.2334\n",
      "Epoch [1388/1500]\n",
      "Train Loss: 2991.0201\n",
      "Val Loss: 3917.1735, MAE: 3917.6736, NMAE: 59.6401, R^2: 0.2356\n",
      "Epoch [1389/1500]\n",
      "Train Loss: 2992.9711\n",
      "Val Loss: 4020.4529, MAE: 4020.9526, NMAE: 61.2124, R^2: 0.2141\n",
      "Epoch [1390/1500]\n",
      "Train Loss: 2991.8700\n",
      "Val Loss: 3926.0479, MAE: 3926.5476, NMAE: 59.7752, R^2: 0.2427\n",
      "Epoch [1391/1500]\n",
      "Train Loss: 2970.2958\n",
      "Val Loss: 3976.1911, MAE: 3976.6909, NMAE: 60.5386, R^2: 0.1972\n",
      "Epoch [1392/1500]\n",
      "Train Loss: 3024.1386\n",
      "Val Loss: 3918.0395, MAE: 3918.5393, NMAE: 59.6533, R^2: 0.2303\n",
      "Epoch [1393/1500]\n",
      "Train Loss: 2957.1290\n",
      "Val Loss: 3915.5681, MAE: 3916.0676, NMAE: 59.6157, R^2: 0.2235\n",
      "Epoch [1394/1500]\n",
      "Train Loss: 2909.7255\n",
      "Val Loss: 3889.1406, MAE: 3889.6404, NMAE: 59.2134, R^2: 0.2251\n",
      "Epoch [1395/1500]\n",
      "Train Loss: 2947.4433\n",
      "Val Loss: 3875.8323, MAE: 3876.3320, NMAE: 59.0108, R^2: 0.2482\n",
      "Epoch [1396/1500]\n",
      "Train Loss: 3033.7507\n",
      "Val Loss: 3868.4528, MAE: 3868.9526, NMAE: 58.8984, R^2: 0.2508\n",
      "Epoch [1397/1500]\n",
      "Train Loss: 2933.8149\n",
      "Val Loss: 3782.8239, MAE: 3783.3237, NMAE: 57.5949, R^2: 0.2602\n",
      "Epoch [1398/1500]\n",
      "Train Loss: 3000.6484\n",
      "Val Loss: 3840.0659, MAE: 3840.5657, NMAE: 58.4663, R^2: 0.2796\n",
      "Epoch [1399/1500]\n",
      "Train Loss: 3000.8048\n",
      "Val Loss: 3880.7245, MAE: 3881.2239, NMAE: 59.0852, R^2: 0.2562\n",
      "Epoch [1400/1500]\n",
      "Train Loss: 2958.1106\n",
      "Val Loss: 3898.3881, MAE: 3898.8877, NMAE: 59.3541, R^2: 0.2415\n",
      "Epoch [1401/1500]\n",
      "Train Loss: 3004.3145\n",
      "Val Loss: 3948.0698, MAE: 3948.5696, NMAE: 60.1105, R^2: 0.2245\n",
      "Epoch [1402/1500]\n",
      "Train Loss: 3004.5362\n",
      "Val Loss: 3980.0004, MAE: 3980.5002, NMAE: 60.5966, R^2: 0.2226\n",
      "Epoch [1403/1500]\n",
      "Train Loss: 2945.3418\n",
      "Val Loss: 4042.3353, MAE: 4042.8354, NMAE: 61.5455, R^2: 0.2049\n",
      "Epoch [1404/1500]\n",
      "Train Loss: 2994.1246\n",
      "Val Loss: 4060.1747, MAE: 4060.6746, NMAE: 61.8171, R^2: 0.2129\n",
      "Epoch [1405/1500]\n",
      "Train Loss: 3029.0000\n",
      "Val Loss: 4149.7854, MAE: 4150.2852, NMAE: 63.1813, R^2: 0.1937\n",
      "Epoch [1406/1500]\n",
      "Train Loss: 3004.3508\n",
      "Val Loss: 4028.5959, MAE: 4029.0957, NMAE: 61.3363, R^2: 0.2356\n",
      "Epoch [1407/1500]\n",
      "Train Loss: 2960.8865\n",
      "Val Loss: 4020.0894, MAE: 4020.5894, NMAE: 61.2068, R^2: 0.2280\n",
      "Epoch [1408/1500]\n",
      "Train Loss: 2988.1491\n",
      "Val Loss: 4079.0624, MAE: 4079.5623, NMAE: 62.1046, R^2: 0.2230\n",
      "Epoch [1409/1500]\n",
      "Train Loss: 2921.9375\n",
      "Val Loss: 3961.5927, MAE: 3962.0925, NMAE: 60.3163, R^2: 0.2443\n",
      "Epoch [1410/1500]\n",
      "Train Loss: 2979.7040\n",
      "Val Loss: 3893.1614, MAE: 3893.6611, NMAE: 59.2746, R^2: 0.2542\n",
      "Epoch [1411/1500]\n",
      "Train Loss: 3000.0109\n",
      "Val Loss: 3945.7475, MAE: 3946.2473, NMAE: 60.0751, R^2: 0.2427\n",
      "Epoch [1412/1500]\n",
      "Train Loss: 2983.2663\n",
      "Val Loss: 4053.5028, MAE: 4054.0022, NMAE: 61.7155, R^2: 0.1986\n",
      "Epoch [1413/1500]\n",
      "Train Loss: 2999.3835\n",
      "Val Loss: 4139.5881, MAE: 4140.0884, NMAE: 63.0260, R^2: 0.1881\n",
      "Epoch [1414/1500]\n",
      "Train Loss: 2970.2366\n",
      "Val Loss: 4065.8464, MAE: 4066.3462, NMAE: 61.9034, R^2: 0.2034\n",
      "Epoch [1415/1500]\n",
      "Train Loss: 2987.1274\n",
      "Val Loss: 4028.5541, MAE: 4029.0537, NMAE: 61.3357, R^2: 0.1895\n",
      "Epoch [1416/1500]\n",
      "Train Loss: 2972.7413\n",
      "Val Loss: 4158.2767, MAE: 4158.7769, NMAE: 63.3105, R^2: 0.1966\n",
      "Epoch [1417/1500]\n",
      "Train Loss: 2976.7383\n",
      "Val Loss: 4000.2639, MAE: 4000.7637, NMAE: 60.9050, R^2: 0.2059\n",
      "Epoch [1418/1500]\n",
      "Train Loss: 2953.5229\n",
      "Val Loss: 4051.1020, MAE: 4051.6018, NMAE: 61.6790, R^2: 0.2159\n",
      "Epoch [1419/1500]\n",
      "Train Loss: 2956.7674\n",
      "Val Loss: 4098.5329, MAE: 4099.0327, NMAE: 62.4010, R^2: 0.2106\n",
      "Epoch [1420/1500]\n",
      "Train Loss: 3038.3447\n",
      "Val Loss: 4042.0623, MAE: 4042.5623, NMAE: 61.5413, R^2: 0.2031\n",
      "Epoch [1421/1500]\n",
      "Train Loss: 3011.1575\n",
      "Val Loss: 3994.9601, MAE: 3995.4597, NMAE: 60.8243, R^2: 0.2182\n",
      "Epoch [1422/1500]\n",
      "Train Loss: 2929.9791\n",
      "Val Loss: 3956.5453, MAE: 3957.0454, NMAE: 60.2395, R^2: 0.2356\n",
      "Epoch [1423/1500]\n",
      "Train Loss: 2969.1751\n",
      "Val Loss: 4033.8477, MAE: 4034.3477, NMAE: 61.4163, R^2: 0.2072\n",
      "Epoch [1424/1500]\n",
      "Train Loss: 2936.2215\n",
      "Val Loss: 4095.3153, MAE: 4095.8152, NMAE: 62.3520, R^2: 0.2038\n",
      "Epoch [1425/1500]\n",
      "Train Loss: 2992.9414\n",
      "Val Loss: 4057.6072, MAE: 4058.1077, NMAE: 61.7780, R^2: 0.1994\n",
      "Epoch [1426/1500]\n",
      "Train Loss: 3026.5631\n",
      "Val Loss: 4069.8824, MAE: 4070.3821, NMAE: 61.9649, R^2: 0.2063\n",
      "Epoch [1427/1500]\n",
      "Train Loss: 2939.8639\n",
      "Val Loss: 3946.0754, MAE: 3946.5752, NMAE: 60.0801, R^2: 0.2292\n",
      "Epoch [1428/1500]\n",
      "Train Loss: 3010.4621\n",
      "Val Loss: 4131.4485, MAE: 4131.9487, NMAE: 62.9021, R^2: 0.1729\n",
      "Epoch [1429/1500]\n",
      "Train Loss: 2961.8910\n",
      "Val Loss: 4171.3714, MAE: 4171.8711, NMAE: 63.5099, R^2: 0.1656\n",
      "Epoch [1430/1500]\n",
      "Train Loss: 2993.2639\n",
      "Val Loss: 4085.0011, MAE: 4085.5007, NMAE: 62.1950, R^2: 0.2033\n",
      "Epoch [1431/1500]\n",
      "Train Loss: 2975.5786\n",
      "Val Loss: 4073.9976, MAE: 4074.4976, NMAE: 62.0275, R^2: 0.1862\n",
      "Epoch [1432/1500]\n",
      "Train Loss: 2970.9862\n",
      "Val Loss: 4119.6666, MAE: 4120.1665, NMAE: 62.7227, R^2: 0.1772\n",
      "Epoch [1433/1500]\n",
      "Train Loss: 3051.6610\n",
      "Val Loss: 4065.7340, MAE: 4066.2341, NMAE: 61.9017, R^2: 0.2137\n",
      "Epoch [1434/1500]\n",
      "Train Loss: 3106.4747\n",
      "Val Loss: 3979.2423, MAE: 3979.7422, NMAE: 60.5850, R^2: 0.2217\n",
      "Epoch [1435/1500]\n",
      "Train Loss: 3090.3824\n",
      "Val Loss: 3953.9592, MAE: 3954.4587, NMAE: 60.2001, R^2: 0.2454\n",
      "Epoch [1436/1500]\n",
      "Train Loss: 3053.2608\n",
      "Val Loss: 4007.0203, MAE: 4007.5205, NMAE: 61.0079, R^2: 0.2133\n",
      "Epoch [1437/1500]\n",
      "Train Loss: 3039.9501\n",
      "Val Loss: 3947.7494, MAE: 3948.2493, NMAE: 60.1056, R^2: 0.2431\n",
      "Epoch [1438/1500]\n",
      "Train Loss: 2971.8176\n",
      "Val Loss: 3943.9255, MAE: 3944.4253, NMAE: 60.0474, R^2: 0.2184\n",
      "Epoch [1439/1500]\n",
      "Train Loss: 3051.3527\n",
      "Val Loss: 4056.3299, MAE: 4056.8293, NMAE: 61.7585, R^2: 0.2173\n",
      "Epoch [1440/1500]\n",
      "Train Loss: 3110.8076\n",
      "Val Loss: 3954.1317, MAE: 3954.6318, NMAE: 60.2028, R^2: 0.2330\n",
      "Epoch [1441/1500]\n",
      "Train Loss: 3015.1500\n",
      "Val Loss: 3971.6507, MAE: 3972.1509, NMAE: 60.4695, R^2: 0.2438\n",
      "Epoch [1442/1500]\n",
      "Train Loss: 3078.8599\n",
      "Val Loss: 3959.7799, MAE: 3960.2795, NMAE: 60.2887, R^2: 0.2323\n",
      "Epoch [1443/1500]\n",
      "Train Loss: 3028.5610\n",
      "Val Loss: 3954.1180, MAE: 3954.6179, NMAE: 60.2025, R^2: 0.2380\n",
      "Epoch [1444/1500]\n",
      "Train Loss: 3018.2913\n",
      "Val Loss: 3958.0459, MAE: 3958.5457, NMAE: 60.2623, R^2: 0.2326\n",
      "Epoch [1445/1500]\n",
      "Train Loss: 2985.4512\n",
      "Val Loss: 3993.9354, MAE: 3994.4353, NMAE: 60.8087, R^2: 0.2093\n",
      "Epoch [1446/1500]\n",
      "Train Loss: 3050.8299\n",
      "Val Loss: 4012.7665, MAE: 4013.2661, NMAE: 61.0954, R^2: 0.2110\n",
      "Epoch [1447/1500]\n",
      "Train Loss: 2987.2117\n",
      "Val Loss: 4024.7040, MAE: 4025.2036, NMAE: 61.2771, R^2: 0.1952\n",
      "Epoch [1448/1500]\n",
      "Train Loss: 3036.3386\n",
      "Val Loss: 4044.4222, MAE: 4044.9224, NMAE: 61.5773, R^2: 0.2186\n",
      "Epoch [1449/1500]\n",
      "Train Loss: 3059.8314\n",
      "Val Loss: 4013.6818, MAE: 4014.1816, NMAE: 61.1093, R^2: 0.2165\n",
      "Epoch [1450/1500]\n",
      "Train Loss: 3031.0633\n",
      "Val Loss: 3950.4967, MAE: 3950.9963, NMAE: 60.1474, R^2: 0.2270\n",
      "Epoch [1451/1500]\n",
      "Train Loss: 3076.1874\n",
      "Val Loss: 3905.9387, MAE: 3906.4387, NMAE: 59.4691, R^2: 0.2416\n",
      "Epoch [1452/1500]\n",
      "Train Loss: 3071.7074\n",
      "Val Loss: 3946.3321, MAE: 3946.8318, NMAE: 60.0840, R^2: 0.2140\n",
      "Epoch [1453/1500]\n",
      "Train Loss: 3017.0768\n",
      "Val Loss: 3969.1999, MAE: 3969.6997, NMAE: 60.4321, R^2: 0.2245\n",
      "Epoch [1454/1500]\n",
      "Train Loss: 3018.4416\n",
      "Val Loss: 3968.8693, MAE: 3969.3691, NMAE: 60.4271, R^2: 0.2304\n",
      "Epoch [1455/1500]\n",
      "Train Loss: 3038.7730\n",
      "Val Loss: 4008.1863, MAE: 4008.6860, NMAE: 61.0256, R^2: 0.2339\n",
      "Epoch [1456/1500]\n",
      "Train Loss: 3028.7943\n",
      "Val Loss: 3980.6612, MAE: 3981.1614, NMAE: 60.6066, R^2: 0.2210\n",
      "Epoch [1457/1500]\n",
      "Train Loss: 3065.7408\n",
      "Val Loss: 3925.2826, MAE: 3925.7825, NMAE: 59.7636, R^2: 0.2432\n",
      "Epoch [1458/1500]\n",
      "Train Loss: 3047.1359\n",
      "Val Loss: 3879.4456, MAE: 3879.9458, NMAE: 59.0658, R^2: 0.2542\n",
      "Epoch [1459/1500]\n",
      "Train Loss: 3025.3400\n",
      "Val Loss: 3945.1134, MAE: 3945.6138, NMAE: 60.0655, R^2: 0.2466\n",
      "Epoch [1460/1500]\n",
      "Train Loss: 3010.2064\n",
      "Val Loss: 3839.2011, MAE: 3839.7012, NMAE: 58.4531, R^2: 0.2607\n",
      "Epoch [1461/1500]\n",
      "Train Loss: 2947.2885\n",
      "Val Loss: 3779.6246, MAE: 3780.1243, NMAE: 57.5462, R^2: 0.2689\n",
      "Epoch [1462/1500]\n",
      "Train Loss: 3018.1397\n",
      "Val Loss: 3873.4193, MAE: 3873.9192, NMAE: 58.9740, R^2: 0.2421\n",
      "Epoch [1463/1500]\n",
      "Train Loss: 3051.4813\n",
      "Val Loss: 3892.8162, MAE: 3893.3159, NMAE: 59.2693, R^2: 0.2514\n",
      "Epoch [1464/1500]\n",
      "Train Loss: 2981.6547\n",
      "Val Loss: 3830.1965, MAE: 3830.6963, NMAE: 58.3160, R^2: 0.2724\n",
      "Epoch [1465/1500]\n",
      "Train Loss: 2993.2466\n",
      "Val Loss: 3814.1710, MAE: 3814.6709, NMAE: 58.0721, R^2: 0.2737\n",
      "Epoch [1466/1500]\n",
      "Train Loss: 2994.7226\n",
      "Val Loss: 3789.5227, MAE: 3790.0229, NMAE: 57.6969, R^2: 0.2737\n",
      "Epoch [1467/1500]\n",
      "Train Loss: 2996.6112\n",
      "Val Loss: 3855.4641, MAE: 3855.9641, NMAE: 58.7007, R^2: 0.2574\n",
      "Epoch [1468/1500]\n",
      "Train Loss: 2972.9078\n",
      "Val Loss: 3894.0880, MAE: 3894.5881, NMAE: 59.2887, R^2: 0.2449\n",
      "Epoch [1469/1500]\n",
      "Train Loss: 2914.8196\n",
      "Val Loss: 3860.5291, MAE: 3861.0291, NMAE: 58.7778, R^2: 0.2535\n",
      "Epoch [1470/1500]\n",
      "Train Loss: 2953.5770\n",
      "Val Loss: 3914.2796, MAE: 3914.7798, NMAE: 59.5961, R^2: 0.2198\n",
      "Epoch [1471/1500]\n",
      "Train Loss: 2999.5274\n",
      "Val Loss: 3867.4658, MAE: 3867.9661, NMAE: 58.8834, R^2: 0.2413\n",
      "Epoch [1472/1500]\n",
      "Train Loss: 3001.0200\n",
      "Val Loss: 3849.2832, MAE: 3849.7830, NMAE: 58.6066, R^2: 0.2353\n",
      "Epoch [1473/1500]\n",
      "Train Loss: 3004.3421\n",
      "Val Loss: 3869.5050, MAE: 3870.0046, NMAE: 58.9144, R^2: 0.2265\n",
      "Epoch [1474/1500]\n",
      "Train Loss: 2963.7871\n",
      "Val Loss: 3894.5680, MAE: 3895.0681, NMAE: 59.2960, R^2: 0.2177\n",
      "Epoch [1475/1500]\n",
      "Train Loss: 3021.8445\n",
      "Val Loss: 3944.7735, MAE: 3945.2737, NMAE: 60.0603, R^2: 0.2254\n",
      "Epoch [1476/1500]\n",
      "Train Loss: 2950.4375\n",
      "Val Loss: 3936.4820, MAE: 3936.9822, NMAE: 59.9341, R^2: 0.2277\n",
      "Epoch [1477/1500]\n",
      "Train Loss: 3008.4353\n",
      "Val Loss: 3908.8783, MAE: 3909.3779, NMAE: 59.5138, R^2: 0.2462\n",
      "Epoch [1478/1500]\n",
      "Train Loss: 2974.9484\n",
      "Val Loss: 3968.3140, MAE: 3968.8137, NMAE: 60.4186, R^2: 0.2233\n",
      "Epoch [1479/1500]\n",
      "Train Loss: 3020.7398\n",
      "Val Loss: 3906.0412, MAE: 3906.5413, NMAE: 59.4707, R^2: 0.2357\n",
      "Epoch [1480/1500]\n",
      "Train Loss: 3036.0957\n",
      "Val Loss: 3961.3942, MAE: 3961.8943, NMAE: 60.3133, R^2: 0.2083\n",
      "Epoch [1481/1500]\n",
      "Train Loss: 2991.8146\n",
      "Val Loss: 3891.2552, MAE: 3891.7549, NMAE: 59.2456, R^2: 0.2474\n",
      "Epoch [1482/1500]\n",
      "Train Loss: 2986.8617\n",
      "Val Loss: 3857.6931, MAE: 3858.1931, NMAE: 58.7346, R^2: 0.2420\n",
      "Epoch [1483/1500]\n",
      "Train Loss: 2964.4767\n",
      "Val Loss: 3877.5372, MAE: 3878.0369, NMAE: 59.0367, R^2: 0.2496\n",
      "Epoch [1484/1500]\n",
      "Train Loss: 3027.3247\n",
      "Val Loss: 3807.6079, MAE: 3808.1079, NMAE: 57.9722, R^2: 0.2615\n",
      "Epoch [1485/1500]\n",
      "Train Loss: 3084.2777\n",
      "Val Loss: 3924.1466, MAE: 3924.6465, NMAE: 59.7463, R^2: 0.2221\n",
      "Epoch [1486/1500]\n",
      "Train Loss: 2960.8837\n",
      "Val Loss: 3876.6574, MAE: 3877.1572, NMAE: 59.0233, R^2: 0.2329\n",
      "Epoch [1487/1500]\n",
      "Train Loss: 2996.1383\n",
      "Val Loss: 3862.2866, MAE: 3862.7866, NMAE: 58.8046, R^2: 0.2503\n",
      "Epoch [1488/1500]\n",
      "Train Loss: 2996.4899\n",
      "Val Loss: 3898.5063, MAE: 3899.0059, NMAE: 59.3559, R^2: 0.2133\n",
      "Epoch [1489/1500]\n",
      "Train Loss: 3054.4833\n",
      "Val Loss: 3803.5162, MAE: 3804.0159, NMAE: 57.9099, R^2: 0.2542\n",
      "Epoch [1490/1500]\n",
      "Train Loss: 2985.5442\n",
      "Val Loss: 3826.1010, MAE: 3826.6006, NMAE: 58.2537, R^2: 0.2556\n",
      "Epoch [1491/1500]\n",
      "Train Loss: 2988.9879\n",
      "Val Loss: 3863.7466, MAE: 3864.2461, NMAE: 58.8268, R^2: 0.2546\n",
      "Epoch [1492/1500]\n",
      "Train Loss: 2988.8137\n",
      "Val Loss: 3903.5841, MAE: 3904.0837, NMAE: 59.4332, R^2: 0.2314\n",
      "Epoch [1493/1500]\n",
      "Train Loss: 2923.6793\n",
      "Val Loss: 3858.1247, MAE: 3858.6243, NMAE: 58.7412, R^2: 0.2544\n",
      "Epoch [1494/1500]\n",
      "Train Loss: 3026.0977\n",
      "Val Loss: 3896.0619, MAE: 3896.5618, NMAE: 59.3187, R^2: 0.2380\n",
      "Epoch [1495/1500]\n",
      "Train Loss: 3017.2725\n",
      "Val Loss: 3833.0236, MAE: 3833.5237, NMAE: 58.3591, R^2: 0.2619\n",
      "Epoch [1496/1500]\n",
      "Train Loss: 3015.0940\n",
      "Val Loss: 3885.7852, MAE: 3886.2852, NMAE: 59.1623, R^2: 0.2522\n",
      "Epoch [1497/1500]\n",
      "Train Loss: 2965.9162\n",
      "Val Loss: 3844.9276, MAE: 3845.4272, NMAE: 58.5403, R^2: 0.2533\n",
      "Epoch [1498/1500]\n",
      "Train Loss: 3041.0968\n",
      "Val Loss: 3862.2878, MAE: 3862.7876, NMAE: 58.8046, R^2: 0.2447\n",
      "Epoch [1499/1500]\n",
      "Train Loss: 3053.7486\n",
      "Val Loss: 3816.4642, MAE: 3816.9641, NMAE: 58.1070, R^2: 0.2585\n",
      "Epoch [1500/1500]\n",
      "Train Loss: 3029.0819\n",
      "Val Loss: 3800.6556, MAE: 3801.1555, NMAE: 57.8663, R^2: 0.2656\n",
      "Final Model saved with best validation loss: 2571688.2563\n",
      "MAE: 3801.1555, NMAE: 57.8663, R^2: 0.2656\n",
      "Epoch [1/1500]\n",
      "Train Loss: 5930.7846\n",
      "Val Loss: 5057.6477, MAE: 5058.1479, NMAE: 77.0020, R^2: -0.0725\n",
      "Epoch [2/1500]\n",
      "Train Loss: 5231.8501\n",
      "Val Loss: 5087.4678, MAE: 5087.9678, NMAE: 77.4559, R^2: -0.0198\n",
      "Epoch [3/1500]\n",
      "Train Loss: 5359.4398\n",
      "Val Loss: 5075.8777, MAE: 5076.3779, NMAE: 77.2795, R^2: -0.0290\n",
      "Epoch [4/1500]\n",
      "Train Loss: 5227.6076\n",
      "Val Loss: 5089.9671, MAE: 5090.4673, NMAE: 77.4940, R^2: -0.0182\n",
      "Epoch [5/1500]\n",
      "Train Loss: 5226.2895\n",
      "Val Loss: 5091.1463, MAE: 5091.6465, NMAE: 77.5119, R^2: -0.0175\n",
      "Epoch [6/1500]\n",
      "Train Loss: 5226.6811\n",
      "Val Loss: 5090.1692, MAE: 5090.6694, NMAE: 77.4971, R^2: -0.0181\n",
      "Epoch [7/1500]\n",
      "Train Loss: 5226.1422\n",
      "Val Loss: 5090.0266, MAE: 5090.5269, NMAE: 77.4949, R^2: -0.0182\n",
      "Epoch [8/1500]\n",
      "Train Loss: 5226.5636\n",
      "Val Loss: 5089.7831, MAE: 5090.2827, NMAE: 77.4912, R^2: -0.0184\n",
      "Epoch [9/1500]\n",
      "Train Loss: 5226.2179\n",
      "Val Loss: 5089.4659, MAE: 5089.9658, NMAE: 77.4863, R^2: -0.0186\n",
      "Epoch [10/1500]\n",
      "Train Loss: 5226.5707\n",
      "Val Loss: 5089.4141, MAE: 5089.9141, NMAE: 77.4856, R^2: -0.0187\n",
      "Epoch [11/1500]\n",
      "Train Loss: 5226.4577\n",
      "Val Loss: 5089.4591, MAE: 5089.9590, NMAE: 77.4862, R^2: -0.0186\n",
      "Epoch [12/1500]\n",
      "Train Loss: 5226.5236\n",
      "Val Loss: 5089.3247, MAE: 5089.8242, NMAE: 77.4842, R^2: -0.0187\n",
      "Epoch [13/1500]\n",
      "Train Loss: 5226.5755\n",
      "Val Loss: 5089.5417, MAE: 5090.0420, NMAE: 77.4875, R^2: -0.0186\n",
      "Epoch [14/1500]\n",
      "Train Loss: 5226.4658\n",
      "Val Loss: 5089.3713, MAE: 5089.8711, NMAE: 77.4849, R^2: -0.0187\n",
      "Epoch [15/1500]\n",
      "Train Loss: 5226.5162\n",
      "Val Loss: 5089.6702, MAE: 5090.1699, NMAE: 77.4894, R^2: -0.0185\n",
      "Epoch [16/1500]\n",
      "Train Loss: 5226.3803\n",
      "Val Loss: 5089.3140, MAE: 5089.8145, NMAE: 77.4840, R^2: -0.0187\n",
      "Epoch [17/1500]\n",
      "Train Loss: 5226.4709\n",
      "Val Loss: 5089.6493, MAE: 5090.1489, NMAE: 77.4891, R^2: -0.0185\n",
      "Epoch [18/1500]\n",
      "Train Loss: 5226.9559\n",
      "Val Loss: 5088.8212, MAE: 5089.3213, NMAE: 77.4765, R^2: -0.0190\n",
      "Epoch [19/1500]\n",
      "Train Loss: 5226.4809\n",
      "Val Loss: 5089.4892, MAE: 5089.9893, NMAE: 77.4867, R^2: -0.0186\n",
      "Epoch [20/1500]\n",
      "Train Loss: 5236.6368\n",
      "Val Loss: 5001.8232, MAE: 5002.3232, NMAE: 76.1521, R^2: 0.0073\n",
      "Epoch [21/1500]\n",
      "Train Loss: 5008.7746\n",
      "Val Loss: 4858.1092, MAE: 4858.6094, NMAE: 73.9643, R^2: 0.0831\n",
      "Epoch [22/1500]\n",
      "Train Loss: 4832.9753\n",
      "Val Loss: 5119.2937, MAE: 5119.7935, NMAE: 77.9404, R^2: 0.0613\n",
      "Epoch [23/1500]\n",
      "Train Loss: 4789.0041\n",
      "Val Loss: 4710.9778, MAE: 4711.4771, NMAE: 71.7245, R^2: 0.1426\n",
      "Epoch [24/1500]\n",
      "Train Loss: 4731.4206\n",
      "Val Loss: 4641.9257, MAE: 4642.4253, NMAE: 70.6733, R^2: 0.1571\n",
      "Epoch [25/1500]\n",
      "Train Loss: 4689.7553\n",
      "Val Loss: 4883.2280, MAE: 4883.7280, NMAE: 74.3467, R^2: 0.0920\n",
      "Epoch [26/1500]\n",
      "Train Loss: 4573.9647\n",
      "Val Loss: 4762.3121, MAE: 4762.8120, NMAE: 72.5060, R^2: 0.1311\n",
      "Epoch [27/1500]\n",
      "Train Loss: 4576.6792\n",
      "Val Loss: 4823.7942, MAE: 4824.2944, NMAE: 73.4419, R^2: 0.0969\n",
      "Epoch [28/1500]\n",
      "Train Loss: 4487.2444\n",
      "Val Loss: 4473.8916, MAE: 4474.3911, NMAE: 68.1152, R^2: 0.1714\n",
      "Epoch [29/1500]\n",
      "Train Loss: 4352.0042\n",
      "Val Loss: 4551.2549, MAE: 4551.7544, NMAE: 69.2930, R^2: 0.1608\n",
      "Epoch [30/1500]\n",
      "Train Loss: 4351.5222\n",
      "Val Loss: 4429.4117, MAE: 4429.9111, NMAE: 67.4381, R^2: 0.1768\n",
      "Epoch [31/1500]\n",
      "Train Loss: 4422.1443\n",
      "Val Loss: 4398.5616, MAE: 4399.0615, NMAE: 66.9685, R^2: 0.1732\n",
      "Epoch [32/1500]\n",
      "Train Loss: 4214.1763\n",
      "Val Loss: 4448.3331, MAE: 4448.8330, NMAE: 67.7262, R^2: 0.1435\n",
      "Epoch [33/1500]\n",
      "Train Loss: 4188.4695\n",
      "Val Loss: 4462.3115, MAE: 4462.8110, NMAE: 67.9389, R^2: 0.1545\n",
      "Epoch [34/1500]\n",
      "Train Loss: 4192.0569\n",
      "Val Loss: 4365.1409, MAE: 4365.6406, NMAE: 66.4597, R^2: 0.1724\n",
      "Epoch [35/1500]\n",
      "Train Loss: 4200.6216\n",
      "Val Loss: 4395.9164, MAE: 4396.4155, NMAE: 66.9282, R^2: 0.1603\n",
      "Epoch [36/1500]\n",
      "Train Loss: 4124.3612\n",
      "Val Loss: 4537.7664, MAE: 4538.2661, NMAE: 69.0876, R^2: 0.0906\n",
      "Epoch [37/1500]\n",
      "Train Loss: 4142.9410\n",
      "Val Loss: 4327.1135, MAE: 4327.6133, NMAE: 65.8808, R^2: 0.1516\n",
      "Epoch [38/1500]\n",
      "Train Loss: 4030.2837\n",
      "Val Loss: 4365.7450, MAE: 4366.2446, NMAE: 66.4689, R^2: 0.1406\n",
      "Epoch [39/1500]\n",
      "Train Loss: 3969.5715\n",
      "Val Loss: 4370.9499, MAE: 4371.4497, NMAE: 66.5481, R^2: 0.1742\n",
      "Epoch [40/1500]\n",
      "Train Loss: 3898.8834\n",
      "Val Loss: 4237.4839, MAE: 4237.9839, NMAE: 64.5163, R^2: 0.2033\n",
      "Epoch [41/1500]\n",
      "Train Loss: 3842.4988\n",
      "Val Loss: 4544.4744, MAE: 4544.9741, NMAE: 69.1897, R^2: 0.0863\n",
      "Epoch [42/1500]\n",
      "Train Loss: 3788.8592\n",
      "Val Loss: 4166.2936, MAE: 4166.7935, NMAE: 63.4326, R^2: 0.2076\n",
      "Epoch [43/1500]\n",
      "Train Loss: 3668.7895\n",
      "Val Loss: 4075.4653, MAE: 4075.9656, NMAE: 62.0499, R^2: 0.2245\n",
      "Epoch [44/1500]\n",
      "Train Loss: 3586.1622\n",
      "Val Loss: 4054.2929, MAE: 4054.7927, NMAE: 61.7275, R^2: 0.2378\n",
      "Epoch [45/1500]\n",
      "Train Loss: 3659.9153\n",
      "Val Loss: 4064.1891, MAE: 4064.6887, NMAE: 61.8782, R^2: 0.2569\n",
      "Epoch [46/1500]\n",
      "Train Loss: 3454.0378\n",
      "Val Loss: 4045.0711, MAE: 4045.5710, NMAE: 61.5872, R^2: 0.2525\n",
      "Epoch [47/1500]\n",
      "Train Loss: 3446.5870\n",
      "Val Loss: 4040.4602, MAE: 4040.9604, NMAE: 61.5170, R^2: 0.2342\n",
      "Epoch [48/1500]\n",
      "Train Loss: 3337.3146\n",
      "Val Loss: 4102.4846, MAE: 4102.9844, NMAE: 62.4612, R^2: 0.2158\n",
      "Epoch [49/1500]\n",
      "Train Loss: 3250.5635\n",
      "Val Loss: 4050.9162, MAE: 4051.4160, NMAE: 61.6761, R^2: 0.1845\n",
      "Epoch [50/1500]\n",
      "Train Loss: 3192.6336\n",
      "Val Loss: 4060.8301, MAE: 4061.3296, NMAE: 61.8271, R^2: 0.1728\n",
      "Epoch [51/1500]\n",
      "Train Loss: 3070.8353\n",
      "Val Loss: 4038.5144, MAE: 4039.0142, NMAE: 61.4873, R^2: 0.1846\n",
      "Epoch [52/1500]\n",
      "Train Loss: 3007.1468\n",
      "Val Loss: 4071.7051, MAE: 4072.2046, NMAE: 61.9926, R^2: 0.1809\n",
      "Epoch [53/1500]\n",
      "Train Loss: 2948.7029\n",
      "Val Loss: 4002.7669, MAE: 4003.2666, NMAE: 60.9431, R^2: 0.1960\n",
      "Epoch [54/1500]\n",
      "Train Loss: 2844.7823\n",
      "Val Loss: 4030.4414, MAE: 4030.9412, NMAE: 61.3644, R^2: 0.1965\n",
      "Epoch [55/1500]\n",
      "Train Loss: 2802.4782\n",
      "Val Loss: 3989.6647, MAE: 3990.1646, NMAE: 60.7437, R^2: 0.2334\n",
      "Epoch [56/1500]\n",
      "Train Loss: 2828.9315\n",
      "Val Loss: 4014.7104, MAE: 4015.2102, NMAE: 61.1250, R^2: 0.2105\n",
      "Epoch [57/1500]\n",
      "Train Loss: 2745.7062\n",
      "Val Loss: 4017.4243, MAE: 4017.9241, NMAE: 61.1663, R^2: 0.1835\n",
      "Epoch [58/1500]\n",
      "Train Loss: 2710.2969\n",
      "Val Loss: 3997.1994, MAE: 3997.6992, NMAE: 60.8584, R^2: 0.2164\n",
      "Epoch [59/1500]\n",
      "Train Loss: 2618.9837\n",
      "Val Loss: 4014.9843, MAE: 4015.4841, NMAE: 61.1291, R^2: 0.2022\n",
      "Epoch [60/1500]\n",
      "Train Loss: 2634.2880\n",
      "Val Loss: 4307.7177, MAE: 4308.2173, NMAE: 65.5855, R^2: 0.1133\n",
      "Epoch [61/1500]\n",
      "Train Loss: 2623.3164\n",
      "Val Loss: 4056.8859, MAE: 4057.3857, NMAE: 61.7670, R^2: 0.1633\n",
      "Epoch [62/1500]\n",
      "Train Loss: 2523.7738\n",
      "Val Loss: 4186.1956, MAE: 4186.6953, NMAE: 63.7355, R^2: 0.1663\n",
      "Epoch [63/1500]\n",
      "Train Loss: 2550.6137\n",
      "Val Loss: 3842.9124, MAE: 3843.4124, NMAE: 58.5096, R^2: 0.2322\n",
      "Epoch [64/1500]\n",
      "Train Loss: 2599.1963\n",
      "Val Loss: 4093.8297, MAE: 4094.3296, NMAE: 62.3294, R^2: 0.1684\n",
      "Epoch [65/1500]\n",
      "Train Loss: 2544.3296\n",
      "Val Loss: 4014.7259, MAE: 4015.2258, NMAE: 61.1252, R^2: 0.1874\n"
     ]
    }
   ],
   "source": [
    "# bidirectional\n",
    "\n",
    "for key in x_dict.keys():\n",
    "    if key == 'original':\n",
    "        continue\n",
    "\n",
    "    # ====================\n",
    "    # z-정규화 데이터\n",
    "    # ====================\n",
    "    x_train_z_selected = x_train_z[x_dict[key]]\n",
    "    x_test_z_selected = x_test_z[x_dict[key]]\n",
    "\n",
    "    # GRU 모델 학습\n",
    "    lstm_model = GRU(input_dim=x_test_z_selected.shape[1], hidden_dim=256,num_layers=4, bidirectional=True)\n",
    "    save_dir = os.path.join(ipynb_path, f'notebooks/yg/TEST_bidirectional_smoothL1_useRelu/{key}_GRU256_3_z/')\n",
    "    train_model(save_dir, lstm_model, x_train_z_selected, y_train, x_test_z_selected, y_test,1500, criterion_type='SmoothL1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i'm not sure if this is right. \n",
    "#it just average convergence.\n",
    "#i think it's better to throw it away and start from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
